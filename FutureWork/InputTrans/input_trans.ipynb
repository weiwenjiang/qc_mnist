{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% Input size is 4\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "\n",
    "# \n",
    "# n_input = 4\n",
    "# n_output = math.log2(n_input)\n",
    "# batch_size=256\n",
    "# \n",
    "# inputs=[]\n",
    "# targets=[]\n",
    "# \n",
    "# alpha = 0\n",
    "# beta = 0\n",
    "# while alpha<np.pi:    \n",
    "#     while beta<np.pi:        \n",
    "#         q_00 = (1-np.power(np.sin(alpha/2),2))*(1-np.power(np.sin(beta/2),2))\n",
    "#         q_01 = (1-np.power(np.sin(alpha/2),2))*(np.power(np.sin(beta/2),2))\n",
    "#         q_10 = (np.power(np.sin(alpha/2),2))*(1-np.power(np.sin(beta/2),2))\n",
    "#         q_11 = (np.power(np.sin(alpha/2),2))*(np.power(np.sin(beta/2),2))\n",
    "#         # print(alpha,beta,\":\",[q_00,q_01,q_10,q_11])\n",
    "#         inputs.append([q_00,q_01,q_10,q_11])\n",
    "#         targets.append([alpha,beta])\n",
    "#         beta+=0.05\n",
    "#     alpha+=0.05\n",
    "#     beta=0\n",
    "# \n",
    "# \n",
    "# t_inputs = torch.tensor(inputs)\n",
    "# t_targets = torch.tensor(targets)\n",
    "\n",
    "# print(t_inputs.shape)\n",
    "# print(t_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch \n",
    "\n",
    "# \n",
    "# n_input = 8\n",
    "# n_output = math.log2(n_input)\n",
    "# batch_size=256\n",
    "# \n",
    "# inputs=[]\n",
    "# targets=[]\n",
    "# \n",
    "# alpha = 0\n",
    "# beta = 0\n",
    "# gamma = 0\n",
    "# while alpha<np.pi:    \n",
    "#     while beta<np.pi:\n",
    "#         while gamma<np.pi:\n",
    "#             p0=np.power(np.sin(alpha/2),2)\n",
    "#             p1=np.power(np.sin(beta/2),2)\n",
    "#             p2=np.power(np.sin(gamma/2),2)\n",
    "#             q_000 = (1-p0)*(1-p1)*(1-p2)\n",
    "#             q_001 = (1-p0)*(1-p1)*p2\n",
    "#             q_010 = (1-p0)*p1*(1-p2)\n",
    "#             q_011 = (1-p0)*p1*p2\n",
    "#             q_100 = p0*(1-p1)*(1-p2)\n",
    "#             q_101 = p0*(1-p1)*p2\n",
    "#             q_110 = p0*p1*(1-p2)\n",
    "#             q_111 = p0*p1*p2\n",
    "#             # print(alpha,beta,\":\",[q_00,q_01,q_10,q_11])\n",
    "#             inputs.append([q_000,q_001,q_010,q_011,q_100,q_101,q_110,q_111])            \n",
    "#             targets.append([alpha,beta,gamma])            \n",
    "#             gamma+=0.5\n",
    "#         beta+=0.5\n",
    "#         gamma=0\n",
    "#     alpha+=0.5\n",
    "#     beta=0\n",
    "# \n",
    "# t_inputs = torch.tensor(inputs)\n",
    "# t_targets = torch.tensor(targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Input size is 8\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch \n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import functools\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# save_path = \"./model/\"+os.path.basename(sys.argv[0])+\"_\"+time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "save_path = \"./model/qc_input\"\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "qc_milestones=[1000]\n",
    "qc_resume_path = \"./model/qc_input/quantum_input_best.pth.tar\"\n",
    "\n",
    "\n",
    "n_input = 16\n",
    "n_output = int(math.log2(n_input))\n",
    "batch_size=256\n",
    "gap = 0.5\n",
    "inputs=[]\n",
    "targets=[]\n",
    "\n",
    "alpha = 0\n",
    "beta = 0\n",
    "gamma = 0\n",
    "theta = 0\n",
    "while alpha<np.pi:    \n",
    "    while beta<np.pi:\n",
    "        while gamma<np.pi:\n",
    "            while theta<np.pi:\n",
    "                p0=np.power(np.sin(alpha/2),2)\n",
    "                p1=np.power(np.sin(beta/2),2)\n",
    "                p2=np.power(np.sin(gamma/2),2)\n",
    "                p3=np.power(np.sin(theta/2),2)\n",
    "                q_0000 = (1-p0)*(1-p1)*(1-p2)*(1-p3)\n",
    "                q_0001 = (1-p0)*(1-p1)*(1-p2)*p3\n",
    "                q_0010 = (1-p0)*(1-p1)*p2*(1-p3)\n",
    "                q_0011 = (1-p0)*(1-p1)*p2*p3\n",
    "                q_0100 = (1-p0)*p1*(1-p2)*(1-p3)\n",
    "                q_0101 = (1-p0)*p1*(1-p2)*p3\n",
    "                q_0110 = (1-p0)*p1*p2*(1-p3)\n",
    "                q_0111 = (1-p0)*p1*p2*p3\n",
    "                q_1000 = p0*(1-p1)*(1-p2)*(1-p3)\n",
    "                q_1001 = p0*(1-p1)*(1-p2)*p3\n",
    "                q_1010 = p0*(1-p1)*p2*(1-p3)\n",
    "                q_1011 = p0*(1-p1)*p2*p3\n",
    "                q_1100 = p0*p1*(1-p2)*(1-p3)\n",
    "                q_1101 = p0*p1*(1-p2)*p3\n",
    "                q_1110 = p0*p1*p2*(1-p3)\n",
    "                q_1111 = p0*p1*p2*p3\n",
    "                # print(alpha,beta,\":\",[q_00,q_01,q_10,q_11])\n",
    "                inputs.append([q_0000,q_0001,q_0010,q_0011,q_0100,q_0101,q_0110,q_0111,q_1000,q_1001,q_1010,q_1011,q_1100,q_1101,q_1110,q_1111])            \n",
    "                targets.append([alpha,beta,gamma,theta])\n",
    "                theta+=gap\n",
    "            gamma+=gap\n",
    "            theta=0\n",
    "        beta+=gap\n",
    "        gamma=0\n",
    "    alpha+=gap\n",
    "    beta=0\n",
    "\n",
    "t_inputs = torch.tensor(inputs)\n",
    "t_targets = torch.tensor(targets)\n",
    "\n",
    "\n",
    "\n",
    "def qcgate_to_state(rotate_gate):\n",
    "    alpha = rotate_gate[0]\n",
    "    beta = rotate_gate[1]\n",
    "    gamma = rotate_gate[2]\n",
    "    theta = rotate_gate[3]\n",
    "    \n",
    "    p0=np.power(np.sin(alpha/2),2)\n",
    "    p1=np.power(np.sin(beta/2),2)\n",
    "    p2=np.power(np.sin(gamma/2),2)\n",
    "    p3=np.power(np.sin(theta/2),2)\n",
    "    \n",
    "    q_0000 = (1-p0)*(1-p1)*(1-p2)*(1-p3)\n",
    "    q_0001 = (1-p0)*(1-p1)*(1-p2)*p3\n",
    "    q_0010 = (1-p0)*(1-p1)*p2*(1-p3)\n",
    "    q_0011 = (1-p0)*(1-p1)*p2*p3\n",
    "    q_0100 = (1-p0)*p1*(1-p2)*(1-p3)\n",
    "    q_0101 = (1-p0)*p1*(1-p2)*p3\n",
    "    q_0110 = (1-p0)*p1*p2*(1-p3)\n",
    "    q_0111 = (1-p0)*p1*p2*p3\n",
    "    q_1000 = p0*(1-p1)*(1-p2)*(1-p3)\n",
    "    q_1001 = p0*(1-p1)*(1-p2)*p3\n",
    "    q_1010 = p0*(1-p1)*p2*(1-p3)\n",
    "    q_1011 = p0*(1-p1)*p2*p3\n",
    "    q_1100 = p0*p1*(1-p2)*(1-p3)\n",
    "    q_1101 = p0*p1*(1-p2)*p3\n",
    "    q_1110 = p0*p1*p2*(1-p3)\n",
    "    q_1111 = p0*p1*p2*p3\n",
    "    \n",
    "    return torch.tensor([q_0000,q_0001,q_0010,q_0011,q_0100,q_0101,q_0110,q_0111,q_1000,q_1001,q_1010,q_1011,q_1100,q_1101,q_1110,q_1111],dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Input size is 16\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n",
      "=> loading checkpoint from './model/qc_input/quantum_input_best.pth.tar'<=\n",
      "Checkpoint load successfully with loss: 0.0005786753026768565\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()                \n",
    "        self.fc1 = nn.Linear(n_input, 64)    \n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, n_output)\n",
    "        \n",
    "        # self.fc3 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window                \n",
    "        x = F.relu(self.fc1(x))        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = (self.fc3(x))\n",
    "        return x\n",
    "\n",
    "qcinput_net = Net().to(device)\n",
    "print(qcinput_net)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(qcinput_net.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(qcinput_net.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, qc_milestones, gamma=0.1)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, save_path, filename):\n",
    "    filename = os.path.join(save_path, filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        bestname = os.path.join(save_path, 'model_best.tar')\n",
    "        shutil.copyfile(filename, bestname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if os.path.isfile(qc_resume_path):\n",
    "    print(\"=> loading checkpoint from '{}'<=\".format(qc_resume_path))\n",
    "    checkpoint = torch.load(qc_resume_path, map_location=device)\n",
    "    epoch_init,best_loss = checkpoint[\"epoch\"],checkpoint[\"loss\"]\n",
    "    qcinput_net.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])    \n",
    "    scheduler.qc_milestones = Counter(qc_milestones)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    best_qcinput_net = qcinput_net\n",
    "    print(\"Checkpoint load successfully with loss: {}\".format(best_loss))\n",
    "else:\n",
    "    print(len(t_inputs))\n",
    "    best_loss = 999999\n",
    "    best_qcinput_net = copy.deepcopy(qcinput_net)\n",
    "    for epoch in range(1000):\n",
    "        for batch in range(int(len(t_inputs)/batch_size)+1):\n",
    "            input = t_inputs[batch*batch_size:min((1+batch)*batch_size,len(t_inputs))]\n",
    "            target = t_targets[batch*batch_size:min((1+batch)*batch_size,len(t_inputs))]\n",
    "            # in your training loop:\n",
    "            optimizer.zero_grad()   # zero the gradient buffers\n",
    "            output = qcinput_net(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        is_best = False\n",
    "        if loss<best_loss:\n",
    "            best_loss= loss\n",
    "            best_qcinput_net = copy.deepcopy(qcinput_net)                \n",
    "            is_best = True        \n",
    "        \n",
    "            save_checkpoint({\n",
    "              'epoch': epoch + 1,\n",
    "              'loss': best_loss, \n",
    "              'state_dict': qcinput_net.state_dict(),      \n",
    "              'optimizer' : optimizer.state_dict(),\n",
    "               'scheduler': scheduler.state_dict(),\n",
    "            }, is_best, save_path, 'quantum_input_best.pth.tar')\n",
    "    \n",
    "        \n",
    "        \n",
    "        scheduler.step()\n",
    "        if epoch%50==0:        \n",
    "            print(epoch,\":\",float(loss),float(best_loss))# Does the update\n",
    "    \n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(range(len(t_inputs)), t_targets)\n",
    "# plt.show()\n",
    "# \n",
    "# t_outputs = qcinput_net(t_inputs)\n",
    "# plt.plot(range(len(t_inputs)), t_outputs.detach())\n",
    "# plt.show()\n",
    "# \n",
    "# t_outputs = best_qcinput_net(t_inputs)\n",
    "# plt.plot(range(len(t_inputs)), t_outputs.detach())\n",
    "# plt.show()\n",
    "\n",
    "t_outputs = best_qcinput_net(t_inputs)\n",
    "diff = (t_outputs-t_targets).abs()\n",
    "plt.plot(range(len(t_inputs)), diff.detach())\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "====================================================================================================\n",
      "Training procedure for Quantum Computer:\n",
      "\tStart at: 09/02/2020 20:29:20\n",
      "\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\n",
      "\tEnjoy and Good Luck!\n",
      "====================================================================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import functools\n",
    "from collections import Counter\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "# interest_num = [0,1,2,3,4,5,6,7,8,9]\n",
    "interest_num = [3,6]\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 32\n",
    "inference_batch_size = 32\n",
    "num_f1 = 4\n",
    "num_f2 = len(interest_num)\n",
    "# num_f3 = len(interest_num)\n",
    "init_lr = 0.01\n",
    "\n",
    "\n",
    "save_to_file = False\n",
    "if save_to_file:\n",
    "    sys.stdout = open(save_path+\"/log\", 'w')\n",
    "\n",
    "resume_path = \"\"\n",
    "training = True\n",
    "max_epoch = 10\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Training procedure for Quantum Computer:\")\n",
    "print(\"\\tStart at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "print(\"\\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\")\n",
    "print(\"\\tEnjoy and Good Luck!\")\n",
    "print(\"=\"*100)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    \n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "        \n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "        \n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    \n",
    "    # print(dataset.targets.shape)\n",
    "    \n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    # print(dataset.targets.shape)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def qc_input_trans(dataset):\n",
    "    dataset.data = dataset.data\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class ToQuantumData(object):\n",
    "    def __call__(self, tensor):        \n",
    "        data = tensor                \n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len,vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = input_matrix.transpose(0,1)        \n",
    "        u,s,v = np.linalg.svd(input_matrix)    \n",
    "        output_matrix = torch.tensor(np.dot(u,v))            \n",
    "        output_data = output_matrix[:,0].view(1,img_size,img_size)\n",
    "                \n",
    "        print(output_data)\n",
    "        unitray_data = output_data.view(-1)\n",
    "        gate_data = best_qcinput_net(unitray_data).detach()\n",
    "        output_data = qcgate_to_state(gate_data).view(1,img_size,img_size)        \n",
    "        print(output_data)\n",
    "        \n",
    "        return output_data\n",
    "                \n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                transforms.ToTensor(),ToQuantumData()])\n",
    "# transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='../../pytorch/data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='../../pytorch/data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "# train_data = qc_input_trans(train_data)\n",
    "\n",
    "# imshow(torchvision.utils.make_grid(train_data[0][0]))\n",
    "# \n",
    "# sys.exit(0)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[[0.0222, 0.2594, 0.2669, 0.0074],\n",
      "         [0.0074, 0.3039, 0.5115, 0.0074],\n",
      "         [0.0222, 0.2372, 0.4892, 0.0074],\n",
      "         [0.0593, 0.3632, 0.2743, 0.0000]]])\n",
      "tensor([[[0.0362, 0.0060, 0.0913, 0.0153],\n",
      "         [0.0389, 0.0065, 0.0982, 0.0164],\n",
      "         [0.0810, 0.0135, 0.2044, 0.0341],\n",
      "         [0.0871, 0.0145, 0.2198, 0.0367]]])\n",
      "tensor([[[0.0000, 0.0965, 0.2172, 0.0000],\n",
      "         [0.0000, 0.4151, 0.3669, 0.0097],\n",
      "         [0.0145, 0.5310, 0.5407, 0.0676],\n",
      "         [0.0048, 0.1593, 0.1786, 0.0097]]])\n",
      "tensor([[[0.0328, 0.0107, 0.0593, 0.0194],\n",
      "         [0.0100, 0.0033, 0.0181, 0.0059],\n",
      "         [0.1726, 0.0565, 0.3124, 0.1023],\n",
      "         [0.0527, 0.0173, 0.0954, 0.0312]]])\n",
      "tensor([[[0.0000, 0.0407, 0.3121, 0.0204],\n",
      "         [0.0000, 0.2850, 0.2985, 0.0068],\n",
      "         [0.0068, 0.5631, 0.6038, 0.0611],\n",
      "         [0.0000, 0.1425, 0.1560, 0.0068]]])\n",
      "tensor([[[0.0174, 0.0039, 0.0546, 0.0123],\n",
      "         [0.0036, 0.0008, 0.0114, 0.0026],\n",
      "         [0.1462, 0.0329, 0.4577, 0.1029],\n",
      "         [0.0304, 0.0068, 0.0951, 0.0214]]])\n",
      "tensor([[[0.0000, 0.1412, 0.2151, 0.0202],\n",
      "         [0.0034, 0.2957, 0.5612, 0.0739],\n",
      "         [0.1008, 0.3193, 0.4806, 0.0538],\n",
      "         [0.1042, 0.3596, 0.1983, 0.0067]]])\n",
      "tensor([[[0.0175, 0.0032, 0.0520, 0.0095],\n",
      "         [0.0220, 0.0040, 0.0651, 0.0120],\n",
      "         [0.0771, 0.0141, 0.2285, 0.0419],\n",
      "         [0.0965, 0.0177, 0.2862, 0.0525]]])\n",
      "tensor([[[0.0000, 0.1380, 0.2103, 0.0066],\n",
      "         [0.0493, 0.4108, 0.2465, 0.1545],\n",
      "         [0.0822, 0.5718, 0.4765, 0.2465],\n",
      "         [0.0066, 0.1709, 0.1709, 0.0296]]])\n",
      "tensor([[[0.0124, 0.0128, 0.0238, 0.0247],\n",
      "         [0.0030, 0.0031, 0.0058, 0.0060],\n",
      "         [0.1227, 0.1276, 0.2359, 0.2452],\n",
      "         [0.0297, 0.0309, 0.0571, 0.0594]]])\n",
      "tensor([[[0.0513, 0.2053, 0.2089, 0.0440],\n",
      "         [0.0660, 0.3006, 0.5095, 0.1210],\n",
      "         [0.0073, 0.2639, 0.5279, 0.0953],\n",
      "         [0.0220, 0.3409, 0.2566, 0.0257]]])\n",
      "tensor([[[0.0177, 0.0046, 0.0954, 0.0246],\n",
      "         [0.0209, 0.0054, 0.1123, 0.0289],\n",
      "         [0.0395, 0.0102, 0.2125, 0.0548],\n",
      "         [0.0466, 0.0120, 0.2502, 0.0645]]])\n",
      "tensor([[[0.0436, 0.1999, 0.1599, 0.0000],\n",
      "         [0.0763, 0.3599, 0.4325, 0.0291],\n",
      "         [0.1345, 0.4289, 0.5089, 0.1926],\n",
      "         [0.0218, 0.1999, 0.2617, 0.0473]]])\n",
      "tensor([[[0.0167, 0.0056, 0.0365, 0.0123],\n",
      "         [0.0092, 0.0031, 0.0202, 0.0068],\n",
      "         [0.1342, 0.0452, 0.2943, 0.0991],\n",
      "         [0.0742, 0.0250, 0.1627, 0.0548]]])\n",
      "tensor([[[0.0000, 0.0301, 0.2378, 0.0636],\n",
      "         [0.0201, 0.3048, 0.3584, 0.0770],\n",
      "         [0.0904, 0.5493, 0.5560, 0.1574],\n",
      "         [0.0201, 0.2278, 0.1206, 0.0100]]])\n",
      "tensor([[[0.0102, 0.0043, 0.0319, 0.0134],\n",
      "         [0.0025, 0.0010, 0.0078, 0.0033],\n",
      "         [0.1271, 0.0534, 0.3968, 0.1667],\n",
      "         [0.0310, 0.0130, 0.0968, 0.0407]]])\n",
      "tensor([[[0.0000, 0.0216, 0.3028, 0.0562],\n",
      "         [0.0000, 0.2423, 0.4153, 0.0173],\n",
      "         [0.0043, 0.5754, 0.5191, 0.0043],\n",
      "         [0.0043, 0.1817, 0.1990, 0.0043]]])\n",
      "tensor([[[0.0219, 0.0043, 0.0820, 0.0159],\n",
      "         [0.0072, 0.0014, 0.0269, 0.0052],\n",
      "         [0.1111, 0.0216, 0.4152, 0.0807],\n",
      "         [0.0365, 0.0071, 0.1364, 0.0265]]])\n",
      "tensor([[[0.0000, 0.0135, 0.2831, 0.0404],\n",
      "         [0.0000, 0.2022, 0.4382, 0.0135],\n",
      "         [0.0000, 0.5191, 0.5798, 0.0202],\n",
      "         [0.0000, 0.2427, 0.1416, 0.0000]]])\n",
      "tensor([[[0.0167, 0.0031, 0.0714, 0.0133],\n",
      "         [0.0051, 0.0009, 0.0217, 0.0040],\n",
      "         [0.1060, 0.0197, 0.4523, 0.0840],\n",
      "         [0.0323, 0.0060, 0.1378, 0.0256]]])\n",
      "tensor([[[0.0189, 0.2128, 0.2270, 0.0047],\n",
      "         [0.0236, 0.3310, 0.5296, 0.0284],\n",
      "         [0.0331, 0.3593, 0.4917, 0.0757],\n",
      "         [0.0236, 0.2601, 0.2553, 0.0189]]])\n",
      "tensor([[[0.0300, 0.0065, 0.0904, 0.0195],\n",
      "         [0.0263, 0.0057, 0.0794, 0.0171],\n",
      "         [0.0791, 0.0171, 0.2384, 0.0514],\n",
      "         [0.0695, 0.0150, 0.2094, 0.0452]]])\n",
      "tensor([[[0.0436, 0.2617, 0.1260, 0.0000],\n",
      "         [0.0388, 0.3004, 0.5039, 0.0145],\n",
      "         [0.0000, 0.1841, 0.5572, 0.1163],\n",
      "         [0.0000, 0.2956, 0.3489, 0.0291]]])\n",
      "tensor([[[0.0134, 0.0025, 0.0707, 0.0133],\n",
      "         [0.0177, 0.0033, 0.0937, 0.0177],\n",
      "         [0.0442, 0.0083, 0.2335, 0.0441],\n",
      "         [0.0585, 0.0111, 0.3095, 0.0584]]])\n",
      "tensor([[[0.0000, 0.0415, 0.2571, 0.0166],\n",
      "         [0.0041, 0.2737, 0.4147, 0.0498],\n",
      "         [0.0166, 0.5723, 0.5391, 0.0788],\n",
      "         [0.0041, 0.1949, 0.1410, 0.0041]]])\n",
      "tensor([[[0.0195, 0.0059, 0.0596, 0.0181],\n",
      "         [0.0057, 0.0017, 0.0174, 0.0053],\n",
      "         [0.1269, 0.0385, 0.3876, 0.1177],\n",
      "         [0.0371, 0.0113, 0.1133, 0.0344]]])\n",
      "tensor([[[0.0000, 0.2346, 0.0913, 0.0000],\n",
      "         [0.0391, 0.4085, 0.2173, 0.0391],\n",
      "         [0.0435, 0.5388, 0.6040, 0.1521],\n",
      "         [0.0000, 0.1086, 0.1651, 0.0174]]])\n",
      "tensor([[[0.0199, 0.0178, 0.0201, 0.0180],\n",
      "         [0.0035, 0.0031, 0.0035, 0.0032],\n",
      "         [0.2034, 0.1821, 0.2054, 0.1840],\n",
      "         [0.0357, 0.0320, 0.0361, 0.0323]]])\n",
      "tensor([[[0.0000, 0.0895, 0.2471, 0.0085],\n",
      "         [0.0170, 0.3791, 0.3109, 0.0682],\n",
      "         [0.0511, 0.5793, 0.5239, 0.1320],\n",
      "         [0.0043, 0.1746, 0.1576, 0.0085]]])\n",
      "tensor([[[0.0215, 0.0102, 0.0415, 0.0198],\n",
      "         [0.0050, 0.0024, 0.0097, 0.0046],\n",
      "         [0.1658, 0.0791, 0.3199, 0.1526],\n",
      "         [0.0388, 0.0185, 0.0748, 0.0357]]])\n",
      "tensor([[[0.0000, 0.0095, 0.2515, 0.0712],\n",
      "         [0.0047, 0.2705, 0.3749, 0.0142],\n",
      "         [0.0854, 0.6929, 0.4603, 0.0285],\n",
      "         [0.0142, 0.1186, 0.0569, 0.0000]]])\n",
      "tensor([[[0.0351, 0.0136, 0.0526, 0.0203],\n",
      "         [0.0081, 0.0031, 0.0122, 0.0047],\n",
      "         [0.1994, 0.0770, 0.2988, 0.1154],\n",
      "         [0.0461, 0.0178, 0.0691, 0.0267]]])\n",
      "tensor([[[0.0047, 0.1542, 0.1168, 0.0000],\n",
      "         [0.0047, 0.5233, 0.4532, 0.0000],\n",
      "         [0.0000, 0.3083, 0.4625, 0.0093],\n",
      "         [0.0000, 0.2196, 0.3551, 0.0047]]])\n",
      "tensor([[[0.0317, 0.0096, 0.0525, 0.0158],\n",
      "         [0.0647, 0.0195, 0.1072, 0.0323],\n",
      "         [0.0634, 0.0191, 0.1050, 0.0317],\n",
      "         [0.1295, 0.0391, 0.2143, 0.0647]]])\n",
      "tensor([[[0.0000, 0.1840, 0.0805, 0.0000],\n",
      "         [0.0287, 0.4426, 0.3392, 0.1840],\n",
      "         [0.0747, 0.5864, 0.3392, 0.2357],\n",
      "         [0.0115, 0.2242, 0.2070, 0.0287]]])\n",
      "tensor([[[0.0089, 0.0348, 0.0087, 0.0339],\n",
      "         [0.0077, 0.0301, 0.0075, 0.0293],\n",
      "         [0.0464, 0.1816, 0.0453, 0.1770],\n",
      "         [0.0401, 0.1568, 0.0391, 0.1528]]])\n",
      "tensor([[[0.0221, 0.2688, 0.1952, 0.0037],\n",
      "         [0.0295, 0.3130, 0.5230, 0.0552],\n",
      "         [0.1473, 0.3720, 0.4383, 0.1473],\n",
      "         [0.0331, 0.2431, 0.2799, 0.0368]]])\n",
      "tensor([[[0.0226, 0.0069, 0.0594, 0.0181],\n",
      "         [0.0186, 0.0057, 0.0490, 0.0149],\n",
      "         [0.0931, 0.0284, 0.2450, 0.0748],\n",
      "         [0.0767, 0.0234, 0.2019, 0.0616]]])\n",
      "tensor([[[0.0000, 0.1637, 0.3193, 0.0409],\n",
      "         [0.0614, 0.4134, 0.2251, 0.0655],\n",
      "         [0.0778, 0.4462, 0.5649, 0.1924],\n",
      "         [0.0041, 0.1514, 0.2333, 0.0368]]])\n",
      "tensor([[[0.0200, 0.0094, 0.0610, 0.0286],\n",
      "         [0.0040, 0.0019, 0.0122, 0.0057],\n",
      "         [0.1200, 0.0563, 0.3662, 0.1717],\n",
      "         [0.0241, 0.0113, 0.0734, 0.0344]]])\n",
      "tensor([[[0.0000, 0.2033, 0.1901, 0.0000],\n",
      "         [0.0000, 0.3669, 0.2299, 0.0133],\n",
      "         [0.0088, 0.5526, 0.6366, 0.0486],\n",
      "         [0.0044, 0.1149, 0.0928, 0.0044]]])\n",
      "tensor([[[0.0401, 0.0201, 0.0427, 0.0213],\n",
      "         [0.0066, 0.0033, 0.0070, 0.0035],\n",
      "         [0.2371, 0.1187, 0.2522, 0.1262],\n",
      "         [0.0391, 0.0196, 0.0416, 0.0208]]])\n",
      "tensor([[[0.0042, 0.2288, 0.2415, 0.0000],\n",
      "         [0.0763, 0.2711, 0.1652, 0.0635],\n",
      "         [0.1313, 0.5083, 0.6481, 0.2415],\n",
      "         [0.0085, 0.1059, 0.1144, 0.0169]]])\n",
      "tensor([[[0.0084, 0.0050, 0.0166, 0.0098],\n",
      "         [0.0015, 0.0009, 0.0029, 0.0017],\n",
      "         [0.1716, 0.1011, 0.3383, 0.1994],\n",
      "         [0.0303, 0.0178, 0.0597, 0.0351]]])\n",
      "tensor([[[0.0000, 0.1233, 0.2083, 0.0000],\n",
      "         [0.0000, 0.3315, 0.3825, 0.0553],\n",
      "         [0.0213, 0.5355, 0.5780, 0.0850],\n",
      "         [0.0043, 0.1870, 0.1360, 0.0043]]])\n",
      "tensor([[[0.0265, 0.0103, 0.0562, 0.0219],\n",
      "         [0.0070, 0.0027, 0.0150, 0.0058],\n",
      "         [0.1556, 0.0605, 0.3303, 0.1285],\n",
      "         [0.0414, 0.0161, 0.0879, 0.0342]]])\n",
      "tensor([[[0.0000, 0.0602, 0.3234, 0.0527],\n",
      "         [0.0188, 0.3723, 0.2294, 0.0113],\n",
      "         [0.0677, 0.5754, 0.5416, 0.1279],\n",
      "         [0.0075, 0.1504, 0.1692, 0.0226]]])\n",
      "tensor([[[0.0160, 0.0060, 0.0363, 0.0137],\n",
      "         [0.0030, 0.0011, 0.0069, 0.0026],\n",
      "         [0.1705, 0.0644, 0.3878, 0.1464],\n",
      "         [0.0322, 0.0122, 0.0733, 0.0277]]])\n",
      "tensor([[[0.0000, 0.1881, 0.2944, 0.0164],\n",
      "         [0.0000, 0.0981, 0.5889, 0.0900],\n",
      "         [0.1145, 0.2454, 0.4662, 0.0082],\n",
      "         [0.1472, 0.4171, 0.1636, 0.0000]]])\n",
      "tensor([[[0.0170, 0.0028, 0.0636, 0.0106],\n",
      "         [0.0215, 0.0036, 0.0803, 0.0134],\n",
      "         [0.0629, 0.0105, 0.2354, 0.0392],\n",
      "         [0.0795, 0.0132, 0.2972, 0.0495]]])\n",
      "tensor([[[0.0000, 0.1908, 0.1590, 0.0000],\n",
      "         [0.0053, 0.4188, 0.2120, 0.0424],\n",
      "         [0.0106, 0.4506, 0.6467, 0.1908],\n",
      "         [0.0000, 0.1113, 0.2120, 0.0318]]])\n",
      "tensor([[[0.0132, 0.0079, 0.0305, 0.0182],\n",
      "         [0.0024, 0.0014, 0.0055, 0.0033],\n",
      "         [0.1472, 0.0879, 0.3392, 0.2026],\n",
      "         [0.0266, 0.0159, 0.0614, 0.0367]]])\n",
      "tensor([[[0.0407, 0.2123, 0.2304, 0.0271],\n",
      "         [0.0813, 0.3749, 0.5601, 0.0632],\n",
      "         [0.0090, 0.2394, 0.4382, 0.1445],\n",
      "         [0.0181, 0.2665, 0.3027, 0.0361]]])\n",
      "tensor([[[0.0201, 0.0044, 0.1103, 0.0241],\n",
      "         [0.0308, 0.0067, 0.1692, 0.0369],\n",
      "         [0.0298, 0.0065, 0.1637, 0.0357],\n",
      "         [0.0457, 0.0100, 0.2511, 0.0548]]])\n",
      "tensor([[[0.0156, 0.1765, 0.2025, 0.0675],\n",
      "         [0.0156, 0.3323, 0.5608, 0.1142],\n",
      "         [0.0571, 0.2908, 0.4673, 0.0883],\n",
      "         [0.0623, 0.3479, 0.2129, 0.0260]]])\n",
      "tensor([[[0.0183, 0.0056, 0.0802, 0.0245],\n",
      "         [0.0231, 0.0070, 0.1009, 0.0308],\n",
      "         [0.0448, 0.0137, 0.1961, 0.0598],\n",
      "         [0.0563, 0.0172, 0.2466, 0.0752]]])\n",
      "tensor([[[0.0000, 0.0540, 0.3119, 0.0180],\n",
      "         [0.0000, 0.2519, 0.2999, 0.0120],\n",
      "         [0.0000, 0.5458, 0.6477, 0.0480],\n",
      "         [0.0000, 0.1259, 0.1020, 0.0000]]])\n",
      "tensor([[[0.0211, 0.0043, 0.0687, 0.0139],\n",
      "         [0.0042, 0.0009, 0.0137, 0.0028],\n",
      "         [0.1420, 0.0288, 0.4612, 0.0936],\n",
      "         [0.0283, 0.0057, 0.0920, 0.0187]]])\n",
      "tensor([[[0.0135, 0.2064, 0.2109, 0.0090],\n",
      "         [0.0179, 0.3231, 0.4981, 0.0179],\n",
      "         [0.0404, 0.3365, 0.4981, 0.0494],\n",
      "         [0.0359, 0.3320, 0.2872, 0.0135]]])\n",
      "tensor([[[0.0224, 0.0044, 0.0585, 0.0115],\n",
      "         [0.0230, 0.0045, 0.0600, 0.0118],\n",
      "         [0.0919, 0.0181, 0.2397, 0.0472],\n",
      "         [0.0942, 0.0185, 0.2458, 0.0484]]])\n",
      "tensor([[[0.0000, 0.1587, 0.1751, 0.0000],\n",
      "         [0.0055, 0.4214, 0.5418, 0.0109],\n",
      "         [0.0055, 0.2517, 0.5035, 0.0328],\n",
      "         [0.0164, 0.3229, 0.2244, 0.0055]]])\n",
      "tensor([[[0.0330, 0.0071, 0.0830, 0.0177],\n",
      "         [0.0442, 0.0095, 0.1111, 0.0237],\n",
      "         [0.0673, 0.0144, 0.1690, 0.0361],\n",
      "         [0.0900, 0.0193, 0.2262, 0.0484]]])\n",
      "tensor([[[0.0000, 0.1519, 0.3341, 0.0121],\n",
      "         [0.0000, 0.2248, 0.5467, 0.0182],\n",
      "         [0.0425, 0.2126, 0.5042, 0.0243],\n",
      "         [0.0364, 0.3463, 0.3037, 0.0061]]])\n",
      "tensor([[[0.0098, 0.0015, 0.0996, 0.0151],\n",
      "         [0.0104, 0.0016, 0.1063, 0.0162],\n",
      "         [0.0277, 0.0042, 0.2828, 0.0430],\n",
      "         [0.0296, 0.0045, 0.3019, 0.0459]]])\n",
      "torch.Size([32, 1, 4, 4])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0])\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADOCAYAAAAnrlmOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATjUlEQVR4nO3dfYxc1XnH8d/j1wW/BGzijVm7djCOHBKIk1goiCCZREikRTWJKoTVVq5q1fmjCCK1amn+SZoqEpXaJP2jquQUhC1CElKIgVLVEIpqyh8uXvMWmwI2sb127F387sVv2H76x17ixbnPmdk7d3d8mO9Hsjxzzp6ZZ8+deXx955lzzN0FAMjPuHYHAACohgQOAJkigQNApkjgAJApEjgAZIoEDgCZaimBm9mtZvaGmW0zs3vrCgoA0JhVrQM3s/GS3pR0i6Tdkl6UtNzdtybGUHQOACO3390/emFjK2fg10va5u5vu/tpST+RtKyFxwMAlNtZ1thKAu+R1Dfs/u6iDQAwBiaM9hOY2SpJq0b7eQCg07SSwPdImjvs/pyi7QPcfbWk1RLXwAGgTq1cQnlR0kIz+7iZTZJ0p6Qn6gkLANBI5TNwdz9jZndJWi9pvKQH3H1LbZEBAJIqlxFWejIuoQBAFb3uvuTCRr6JCQCZIoEDQKZI4ACQKRI4AGRq1L/I06pLLrkk7Dt58mTYN2vWrNL2/fv3h2POnj3bfGDDdHV1lbafPn06HDNt2rSw79133y1tP3PmzMgCK0yYUH6YU7/v1KlTw77jx4+HfVXmMIpPin/nKvMnSefOnWs+sML48eNHPKbquNRrJpKav9Tx6O7uLm0/ePBgOKZKfFK112D0vkrFUfU9PG5c+blsqshj8uTJYd97770X9lWNsQxn4ACQKRI4AGSKBA4AmSKBA0CmSOAAkCkSOABk6qIvI6wqKgsys9qfKyppSpWspUrd6iwzkqqVH9ZdipeSOiZRX6pEr+5jXPV41D1Pkaq/b1TaNxrvkWguUmV6qddt3XNb5fFOnToV9o3VGlOcgQNApkjgAJApEjgAZIoEDgCZIoEDQKZI4ACQqYu+jHDKlClhX2pltJ6entL2Q4cOhWOqrvZ3zTXXlLbv2rUrHHPzzTeHfS+++GJp+69//euRBVZYuHBhaXtfX1845q677gr7Hn744bCvSozTp08P+w4fPlzaHs25JL388sthX2olxci8efPCvlTJ3Zw5c0rboxJXSdqwYUPzgRUmTpwY9qVKIK+88srS9iNHjoRjUqVzKfPnzy9t7+/vD8csXbo07Nu8eXNp+969e0cS1m9E8R04cCAcc+edd4Z9L7zwQti3devWpuNqhDNwAMgUCRwAMkUCB4BMkcABIFMkcADIFAkcADLVUhmhme2QdEzSWUln3H1JHUENlyq5ShnLldZ27txZ2n7ixIlwzMaNG8O+VKljFVE5Y6oM86GHHgr7UqVVVaTK4KLjlSo9rLoJcWTfvn2VxkWbA9f9GqyymqMUbxhe9/xJcTloavPft99+O+wbHBxsOabhovLDVGnxk08+GfYdPXq05ZiaUUcd+M3uHm/1DgAYFVxCAYBMtZrAXdLTZtZrZqvqCAgA0JxWL6F80d33mNksSc+Y2f+5+we+C1wkdpI7ANSspTNwd99T/D0g6eeSri/5mdXuvmQ0PuAEgE5mVfduM7Mpksa5+7Hi9jOSvuPu/5kYMzYbxQHAh0tv2UlwK5dQuiX9vChTmiDp4VTyBgDUq3ICd/e3JX2mxlgAACNAGSEAZIoEDgCZIoEDQKZI4ACQKRI4AGSKBA4AmSKBA0CmSOAAkCkSOABkigQOAJkigQNApurYUm1UpfZLTO1XN3PmzNL2aG++Ro+XEu2/mXq8GTNmhH1HjhwpbT979uzIAitMnjy5tD21J+asWbPCvtSemFXmMLUHY/Q7V5m/1OOlRMe30eNF+3a+++674Zgq85d6j6RWG432y0yNqfoeiWJMzV9XV1fYF+2lmdpjMyV6rtTjXXrppWHfyZMnw76qMZbhDBwAMkUCB4BMkcABIFMkcADIFAkcADJFAgeATF30ZYSpsqVUudPRo0dL26uW4qVUecxjx46FfefOnWslnN9SZePq0ZinSFTOlpIqnavyeCmpuUjNbVQuWPfc1lmWNlqi93Fq/lKleFU3Y49EJbWp9+Lx48fDvrrfwxHOwAEgUyRwAMgUCRwAMkUCB4BMkcABIFMNq1DM7AFJt0kacPdPF20zJP1U0nxJOyTd4e6HRiPAnp6esK+/vz/sW7lyZWn7z372s3DM/v37mw9smCuvvLK0fWBgIBxz9913h31r164tbX/nnXdGFlghWlQptbDXokWLwr5XXnkl7EtV10Sixbak+NP8q6++OhwzODgY9lVZjGnevHlhX+o1uHz58tL2X/ziF+GYXbt2NR9Y4fOf/3zYl6pQmTRpUml7apGzV199tfnAhvnkJz9Z2p56j9x0001h35YtW0rb33zzzZEFVli8eHFp+86dO8MxN9xwQ9iXeo/09fU1H1gDzZyBPyjp1gva7pX0rLsvlPRscR8AMIYaJnB33yDp4AXNyyStKW6vkXR7zXEBABqoeg282933Frf3SequKR4AQJNa/iamu7uZhV+LMrNVkla1+jwAgA+qegbeb2azJan4O/wkwt1Xu/sSd19S8bkAACWqJvAnJK0obq+Q9Hg94QAAmtVMGeGPJS2VdIWZ7Zb0LUn3SXrEzFZK2inpjtEKsOr+i+vXry9tjxa5akUUYyq+devWhX2pPR2riBZPSi0IdOrUqbCv7oV6UntiRqI9T6s+XkqqVDA1T08//XRpe9Vy1cjWrVvDvrr3xKzqV7/6VWl7qsxxw4YNYV9qIakq3njjjdL21PF94YUXwr7Uvqd1apjA3b28mFX6cs2xAABGgG9iAkCmSOAAkCkSOABkigQOAJkigQNApmw0SobCJ0t8YxMAEOot+zIkZ+AAkCkSOABkigQOAJkigQNApkjgAJApEjgAZIoEDgCZIoEDQKZI4ACQKRI4AGSKBA4AmSKBA0CmGm6p1m5dXV1h3+nTp8O+KVOmlLafOHEiHJPawzJl3LjyfwcnTZoUjknFHo07efLkyAIrTJw4sbQ99ftOnz497Evt91dlDqP4pHg/z2nTpoVjUvOU2uMwcumll4Z9qT0do98rNSbVF4lef1J6f8to79DUnqdV90ONXtOp18vUqVPDvuh9XGX+JGnChPJUGL3+pOq5KfWYI8UZOABkigQOAJkigQNApkjgAJApEjgAZIoEDgCZalhGaGYPSLpN0oC7f7po+7akP5P0TvFj33T3/xiNAFOlOlXK4FJlRlXLCKNSrVQJV9W+Kqo8XqrUqe74UvMePdfg4GA4pmqpWyRVepqai+j3qnv+qv6+VV/vVUTvu9RcpMpV6z7GVeYiVa46VnsNN3MG/qCkW0vav+/ui4s/o5K8AQCxhgnc3TdIOjgGsQAARqCVa+B3mdmrZvaAmV0e/ZCZrTKzTWa2qYXnAgBcoGoC/xdJCyQtlrRX0j9GP+juq919ibsvqfhcAIASlRK4u/e7+1l3Pyfph5KurzcsAEAjlRK4mc0edverkn5ZTzgAgGY1U0b4Y0lLJV1hZrslfUvSUjNbLMkl7ZD09VGMsZKxKuOR4tXqFixYEI7Zvn172HfVVVeVtr/22msjC6wwc+bM0vbDhw+HYz73uc+FfVu2bAn7Dhw40Hxghblz54Z9UYzLli0Lx2zevDnsS8UeufHGG8O+Xbt2hX3RcdyxY0c4JtUX+dSnPhX2HTwY1x/cdNNNpe3btm0Lx6TmNuUTn/hEafu+ffvCMbfcckvYt2lT+UdqVeZPiudwz5494Zivfe1rYd/zzz8f9r311lvNB9ZAwwTu7stLmu+vLQIAQCV8ExMAMkUCB4BMkcABIFMkcADI1EW/J+bll4df8kzubzhnzpzS9uPHj4djqu45GVW8pOJLLcZTZd/GlGihnlQMde97mZKqRIie66mnngrHpI5xFb29vWFfanG0/fv3j3hMFamqkdSiZOvXry9tr/v1J0l9fX2l7am9Izds2BD2HT16tOWYhouqwlLHat26dWFf6v1TJ87AASBTJHAAyBQJHAAyRQIHgEyRwAEgUyRwAMiUjeWiT2Y2dk8GAB8evWV7KnAGDgCZIoEDQKZI4ACQKRI4AGSKBA4AmSKBA0CmSOAAkCkSOABkigQOAJkigQNApkjgAJApEjgAZKphAjezuWb2nJltNbMtZnZP0T7DzJ4xs7eKv+PNKwEAtWu4GqGZzZY02903m9k0Sb2Sbpf0J5IOuvt9ZnavpMvd/a8bPNaIVyOcMCHedzm1ue5ll11W2p7aDDW1yW/K+PHjS9tTcztx4sSwL9qItupmwtFzpR6vp6cn7BsYGAj7UpvURlLHOJqLmTNnhmNSx7hKfKljVfdrMLUJcaRqfNOmTSttHxwcDMdUfY90dXWVtqc2UL7iiivCvkOHDpW2V32PjBtXfi6b+n1nz54d9qXeI1WOsaquRujue919c3H7mKTXJfVIWiZpTfFjazSU1AEAY2RE18DNbL6kz0raKKnb3fcWXfskddcaGQAgKf6/6wXMbKqkRyV9w92Pmtlv+tzdo8sjZrZK0qpWAwUAfFBTZ+BmNlFDyftH7v5Y0dxfXB9//zp56UUfd1/t7kvKrt8AAKprpgrFJN0v6XV3/96wrickrShur5D0eP3hAQAizVxCuVHSH0t6zcxeLtq+Kek+SY+Y2UpJOyXdMRoBDr9UMxJRZUPVx0up8qlyqhqi7n1Ko0/YUz7ykY+EfQcOHGglnN9S5ZikKi/qPsapyobUsYqqTSpWIdQumqfReI9ElVqp55o8eXLYV+U1XbdUDKMxh2UaJnB3/x9JUTRfrjccAECz2v/PGACgEhI4AGSKBA4AmSKBA0CmSOAAkKmmv4nZLlOmTAn7UosCLVq0qLS9t7c3HHPixInmAxtm4cKFpe1HjhwJxyxdujTs2759e2l7Kva6VV20qIpJkyaNOI6Pfexj4Zjjx4+HfanFkyILFiwI+/r6+sK+u+++u7R97dq14Zj+/v7mAyvMmDEj7EuVfF533XWl7S+99FI4JrXQVUp0jE+ePBmOGctS1qgsNVXue+2114Z90WJbUvUFt8pwBg4AmSKBA0CmSOAAkCkSOABkigQOAJkigQNApi76MsLUfompFb+iEqRoVbRW7Ny5s7Q9VYq3fv36sK/Kvo0p0Ry+99574Zju7niDpd27d7cc03CpYxId42g/Ryn9mqkiVSqYOlZRueDFsJpjK+OqiMr0UjFMnz497BuN9/FIVc1NdeIMHAAyRQIHgEyRwAEgUyRwAMgUCRwAMkUCB4BMWd0b6CafzGzsngwAPjx63X3JhY2cgQNApkjgAJApEjgAZIoEDgCZIoEDQKYaJnAzm2tmz5nZVjPbYmb3FO3fNrM9ZvZy8ed3Rz9cAMD7mlm27Yykv3D3zWY2TVKvmT1T9H3f3f9h9MIDAEQaJnB33ytpb3H7mJm9LqlntAMDAKSN6Bq4mc2X9FlJG4umu8zsVTN7wMwuD8asMrNNZrappUgBAB/Q9DcxzWyqpP+W9F13f8zMuiXtl+SS/k7SbHf/0waPwTcxAWDkqn8T08wmSnpU0o/c/TFJcvd+dz/r7uck/VDS9XVGCwBIa6YKxSTdL+l1d//esPbZw37sq5J+WX94AIBIw0soZvZFSc9Lek3S+5s8flPSckmLNXQJZYekrxcfeKYe6x1J728geYWGLsGAuRiOuTiPuTiv0+dinrt/9MLGMV2N8ANPbLap7JpOJ2IuzmMuzmMuzmMuyvFNTADIFAkcADLVzgS+uo3PfbFhLs5jLs5jLs5jLkq07Ro4AKA1XEIBgEy1JYGb2a1m9oaZbTOze9sRQ7sUyw4MmNkvh7XNMLNnzOyt4u/SZQk+bBIrXXbcfJhZl5n9r5m9UszF3xbtHzezjcV75admNqndsY4FMxtvZi+Z2b8X9ztyHhoZ8wRuZuMl/bOkr0i6RtJyM7tmrONoowcl3XpB272SnnX3hZKeLe53gvdXurxG0hck/XnxWujE+Tgl6Uvu/hkNfb/iVjP7gqS/19Cqn1dLOiRpZRtjHEv3SHp92P1OnYekdpyBXy9pm7u/7e6nJf1E0rI2xNEW7r5B0sELmpdJWlPcXiPp9jENqk3cfa+7by5uH9PQG7ZHHTgfPmSwuDux+OOSviTp34r2jpgLM5sj6fck/Wtx39SB89CMdiTwHkl9w+7vFsvTdg/7Fus+Sd3tDKYdLljpsiPno7hs8LKkAUnPSNou6bC7nyl+pFPeKz+Q9Fc6/83vmerMeWiIDzEvMj5UFtRRpUHFSpePSvqGux8d3tdJ81EsDrdY0hwN/U91UZtDGnNmdpukAXfvbXcsOWhmR5667ZE0d9j9OUVbJ+s3s9nuvrdYJGyg3QGNlbKVLtXB8yFJ7n7YzJ6TdIOky8xsQnH22QnvlRsl/X6xRWOXpOmS/kmdNw9NaccZ+IuSFhafKk+SdKekJ9oQx8XkCUkritsrJD3exljGTLTSpTpwPszso2Z2WXH7Ekm3aOgzgeck/UHxYx/6uXD3v3H3Oe4+X0O54b/c/Q/VYfPQrLZ8kaf41/UHksZLesDdvzvmQbSJmf1Y0lINra7WL+lbktZJekTS72hotcY73P3CDzo/dBIrXW5Uh82HmV2noQ/nxmvoxOoRd/+OmV2loQ/6Z0h6SdIfufup9kU6dsxsqaS/dPfbOnkeUvgmJgBkig8xASBTJHAAyBQJHAAyRQIHgEyRwAEgUyRwAMgUCRwAMkUCB4BM/T9/3O9Kuw3IRQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# functions to show an image\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    # print(npimg.shape)\n",
    "    # print(np.transpose(npimg, (1, 2, 0)))\n",
    "    # print(np.transpose(npimg, (1, 2, 0)).shape)\n",
    "    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    # print(npimg[0])\n",
    "    # # sys.exit(0)\n",
    "    # # image = np.asarray(npimg[0])\n",
    "    # im = Image.fromarray(image,mode=\"L\")\n",
    "    # \n",
    "    # im.save(\"32*32.jpg\",cmap=\"gray\") \n",
    "    # im = im.resize((4,4))    \n",
    "    # \n",
    "    # for i in range(4):\n",
    "    #     for j in range(4):\n",
    "    #         print(im.getpixel((i,j))/255,end=\" \")\n",
    "    #     print()\n",
    "    # plt.imshow(im,cmap='gray',)\n",
    "    # \n",
    "    # plt.show()\n",
    "    # im.save(\"4*4.jpg\",cmap=\"gray\") \n",
    "    # sys.exit(0)\n",
    "\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(data.shape)\n",
    "    print(target)\n",
    "    imshow(torchvision.utils.make_grid(data))\n",
    "    break\n",
    "    \n",
    "    # # \n",
    "    # # \n",
    "    # # input_vec = data.view(batch_size,-1)\n",
    "    # # \n",
    "    # # \n",
    "    # # sys.exit(0)\n",
    "    # \n",
    "    # input_vec = data.view(-1)\n",
    "    # vec_len = input_vec.size()[0]\n",
    "    # input_matrix = torch.zeros(vec_len,vec_len)\n",
    "    # input_matrix[0] = input_vec\n",
    "    # input_matrix = input_matrix.transpose(0,1)\n",
    "    # \n",
    "    # u,s,v = np.linalg.svd(input_matrix)    \n",
    "    # output_matrix = torch.tensor(np.dot(u,v))    \n",
    "    # \n",
    "    # output_data = output_matrix[:,0].view(img_size,img_size)\n",
    "    # \n",
    "    # imshow(torchvision.utils.make_grid(output_data))\n",
    "    # # print(output_data)\n",
    "    # \n",
    "    # sys.exit(0)    \n",
    "    # ori_img = data[0][0].numpy()\n",
    "    # u,s,v = np.linalg.svd(ori_img, full_matrices=True)\n",
    "    # print(u.shape,s.shape,v.shape)\n",
    "    # \n",
    "    # \n",
    "    # \n",
    "    # imshow(torchvision.utils.make_grid(data))\n",
    "    # sys.exit(0)\n",
    "# \n",
    "# # get some random training images\n",
    "# dataiter = iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % filtered_class[labels[j]] for j in range(batch_size)))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "========== Model Info ==========\n",
      "Net(\n",
      "  (fc1): BinaryLinear(in_features=16, out_features=4, bias=False)\n",
      "  (fc2): BinaryLinear(in_features=4, out_features=2, bias=False)\n",
      "  (qc1a): QC_Norm_Correction()\n",
      "  (qc2a): QC_Norm_Correction()\n",
      "  (qc1): QC_Norm_Real()\n",
      "  (qc2): QC_Norm_Real()\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    " \n",
    "\n",
    "class BinarizeF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cxt, input):\n",
    "        output = input.new(input.size())\n",
    "        output[input >= 0] = 1\n",
    "        output[input < 0] = -1\n",
    "        \n",
    "              \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(cxt, grad_output):\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input\n",
    "# aliases\n",
    "binarize = BinarizeF.apply\n",
    "\n",
    "\n",
    "class ClipF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = input.clone().detach()\n",
    "        # output = input.new(input.size())\n",
    "        output[input >= 1] = 1\n",
    "        output[input <= 0] = 0\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input >= 1] = 0\n",
    "        grad_input[input <= 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "# aliases\n",
    "clipfunc = ClipF.apply\n",
    "\n",
    "\n",
    "class BinaryLinear(nn.Linear):\n",
    "    \n",
    "    \n",
    "    def do_slp_via_th(self,input_ori,w_ori):\n",
    "        p = input_ori\n",
    "        d = 4*p*(1-p)\n",
    "        e = (2*p-1)\n",
    "        # e_sq = torch.tensor(1)\n",
    "        w = w_ori\n",
    "        \n",
    "        sum_of_sq = (d+e.pow(2)).sum(-1)\n",
    "        sum_of_sq = sum_of_sq.unsqueeze(-1)        \n",
    "        sum_of_sq = sum_of_sq.expand(p.shape[0], w.shape[0])\n",
    "                \n",
    "        diag_p = torch.diag_embed(e)        \n",
    "        \n",
    "        p_w = torch.matmul(w,diag_p)\n",
    "        \n",
    "        z_p_w = torch.zeros_like(p_w)        \n",
    "        shft_p_w = torch.cat((p_w, z_p_w), -1)\n",
    "        \n",
    "        sum_of_cross = torch.zeros_like(p_w)\n",
    "        length = p.shape[1]    \n",
    "        \n",
    "        for shft in range(1,length):    \n",
    "            sum_of_cross += shft_p_w[:,:,0:length]*shft_p_w[:,:,shft:length+shft]\n",
    "\n",
    "        sum_of_cross = sum_of_cross.sum(-1)\n",
    "                \n",
    "        return (sum_of_sq+2*sum_of_cross)/(length**2) \n",
    "    \n",
    "    def forward(self, input):        \n",
    "        binary_weight = binarize(self.weight)        \n",
    "        if self.bias is None:\n",
    "            return self.do_slp_via_th(input,binary_weight)\n",
    "                      \n",
    "        else:   \n",
    "            \n",
    "            bias_one  = torch.ones(input.shape[0],1)            \n",
    "            new_input = torch.cat((input, bias_one), -1)            \n",
    "            bias = clipfunc(self.bias).unsqueeze(1)            \n",
    "            new_weight = binary_weight            \n",
    "            new_weight = torch.cat((new_weight,bias),-1)                        \n",
    "            return self.do_slp_via_th(new_input,new_weight)\n",
    "            \n",
    "            \n",
    "            torch.set_printoptions(edgeitems=64)\n",
    "            # binary_bias = binarize(self.bias)/float(len(input[0].flatten())+1)\n",
    "            binary_bias = binarize(self.bias)/float(len(input[0].flatten())+1)\n",
    "            res = F.linear(input, binary_weight/float(len(input[0].flatten())+1), binary_bias)\n",
    "            return res\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Glorot initialization\n",
    "        in_features, out_features = self.weight.size()\n",
    "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "        self.weight.lr_scale = 1. / stdv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QC_Norm(nn.Module):\n",
    "    def __init__(self, num_features, momentum=0.1):        \n",
    "        super(QC_Norm, self).__init__()\n",
    "        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)        \n",
    "        self.ang_inc = Parameter(torch.ones(1)*10)\n",
    "        \n",
    "        self.momentum = momentum\n",
    "                \n",
    "        self.printed = False\n",
    "        self.x_mean_ancle=0\n",
    "        self.x_mean_rote = 0\n",
    "        self.input = 0\n",
    "        self.output = 0\n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            if not self.printed:\n",
    "                print(\"self.ang_inc\",self.ang_inc)\n",
    "                self.printed = True\n",
    "                    \n",
    "            x = x.transpose(0,1)\n",
    "  \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+self.x_running_rot.unsqueeze(-1)\n",
    "            x_1 = (x_final.cos()+1)/2\n",
    "                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:\n",
    "            self.printed = False\n",
    "            x = x.transpose(0,1)        \n",
    "            x_sum = x.sum(-1).unsqueeze(-1).expand(x.shape)\n",
    "            x_lack_sum = x_sum - x    \n",
    "            x_mean = x_lack_sum/x.shape[-1]\n",
    "            \n",
    "            \n",
    "                    \n",
    "            x_mean_ancle = (x_mean*2-1).acos()  \n",
    "            \n",
    "            ang_inc = self.ang_inc.unsqueeze(-1).expand(x_mean_ancle.shape) \n",
    "            # ang_inc = np.pi/2/(x.max(-1)[0].unsqueeze(-1).expand(x_mean_ancle.shape) -x.min(-1)[0].unsqueeze(-1).expand(x_mean_ancle.shape) )\n",
    "            x_mean_rote = (np.pi/2 - x_mean_ancle)*20 # ang_inc\n",
    "            \n",
    "            x_moving_rot = (x_mean_rote.sum(-1)/x.shape[-1])            \n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot\n",
    "                                                \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+x_mean_rote  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "      \n",
    "        return x_1\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        self.ang_inc.data.zeros_()\n",
    "        \n",
    "def print_degree(x,name=\"x\"):\n",
    "    print(name,x/np.pi*180)\n",
    "    \n",
    "    \n",
    "class QC_Norm_Real(nn.Module):\n",
    "    def __init__(self,num_features,momentum=0.1):        \n",
    "        super(QC_Norm_Real, self).__init__()        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.x_max = 0\n",
    "        self.x_min = 0\n",
    "        # print(\"Using Normal without real\")\n",
    "        \n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            x = x.transpose(0,1)\n",
    "            \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            # x_final = x_ancle+self.x_running_rot.unsqueeze(-1)  \n",
    "            x_final = ((x_ancle-self.x_min)/(self.x_max-self.x_min))*np.pi\n",
    "            \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x = x.transpose(0,1)        \n",
    "            x_ancle = (x*2-1).acos()     \n",
    "            x_rectify_ancle = (x_ancle.max(-1)[0]-x_ancle.min(-1)[0]).unsqueeze(-1).expand(x.shape)                                                                         \n",
    "            x_final = ((x_ancle-x_ancle.min(-1)[0].unsqueeze(-1))/(x_rectify_ancle))*np.pi\n",
    "            \n",
    "            x_moving_rot = x_final - x_ancle\n",
    "            \n",
    "            x_moving_rot_mean = x_moving_rot.sum(-1)/x.shape[-1] \n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot_mean      \n",
    "            \n",
    "            self.x_max = self.momentum * x_ancle.max(-1)[0].unsqueeze(-1) + \\\n",
    "                                    (1 - self.momentum) * self.x_max\n",
    "            self.x_min = self.momentum * x_ancle.min(-1)[0].unsqueeze(-1) + \\\n",
    "                                    (1 - self.momentum) * self.x_min\n",
    "            \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "            \n",
    "        return x_1\n",
    "\n",
    "\n",
    "class QC_Norm_Real_Correction(nn.Module):\n",
    "    def __init__(self,num_features,momentum=0.1):        \n",
    "        super(QC_Norm_Real_Correction, self).__init__()        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            x = x.transpose(0,1)\n",
    "            \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+self.x_running_rot.unsqueeze(-1)  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:            \n",
    "            \n",
    "            x = x.transpose(0,1)                    \n",
    "            x_ancle = (x*2-1).acos()                        \n",
    "            x_moving_rot = -1*(x_ancle.min(-1)[0])\n",
    "            \n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot                                                    \n",
    "            x_final = x_ancle+x_moving_rot.unsqueeze(-1)                                    \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "            \n",
    "        \n",
    "        return x_1\n",
    "\n",
    "class QC_Norm_Correction(nn.Module):\n",
    "    def __init__(self,num_features,momentum=0.1):        \n",
    "        super(QC_Norm_Correction, self).__init__()        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            x = x.transpose(0,1)\n",
    "            \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+self.x_running_rot.unsqueeze(-1)  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:\n",
    "            x = x.transpose(0,1)        \n",
    "            x_sum = x.sum(-1).unsqueeze(-1).expand(x.shape)                \n",
    "            x_mean = x_sum/x.shape[-1]\n",
    "                                \n",
    "            x_mean_ancle = (x_mean*2-1).acos()    \n",
    "            x_mean_rote = (np.pi/2 - x_mean_ancle) \n",
    "            \n",
    "            x_moving_rot = (x_mean_rote.sum(-1)/x.shape[-1])\n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot                                        \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+x_mean_rote  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "        \n",
    "        return x_1\n",
    "\n",
    "## Define the NN architecture\n",
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1 = BinaryLinear(img_size*img_size,num_f1,bias=False)\n",
    "        self.fc2 = BinaryLinear(num_f1,num_f2,bias=False)\n",
    "        # self.fc3 = BinaryLinear(num_f2,num_f3,bias=False)\n",
    "        # # \n",
    "        # self.qc1 = QC_Norm(num_features=num_f1)\n",
    "        # self.qc2 = QC_Norm(num_features=num_f2)\n",
    "        # self.qc3 = QC_Norm(num_features=num_f3)\n",
    "\n",
    "        self.qc1a = QC_Norm_Correction(num_features=num_f1)\n",
    "        self.qc2a = QC_Norm_Correction(num_features=num_f2)\n",
    "        # self.qc3a = QC_Norm_Correction(num_features=num_f3)\n",
    "        # \n",
    "        # \n",
    "        self.qc1 = QC_Norm_Real(num_features=num_f1)\n",
    "        self.qc2 = QC_Norm_Real(num_features=num_f2)\n",
    "        # self.qc3 = QC_Norm_Real(num_features=num_f3)\n",
    "\n",
    "\n",
    "        # self.qc1a = QC_Norm_Real_Correction(num_features=num_f1)\n",
    "        # self.qc2a = QC_Norm_Real_Correction(num_features=num_f2)\n",
    "        # self.qc3a = QC_Norm_Real_Correction(num_features=num_f3)\n",
    "        # \n",
    "    def forward(self, x, training=1):        \n",
    "        x = x.view(-1, img_size * img_size)\n",
    "        \n",
    "        if training == 1:\n",
    "            # x = binarize(x-0.0001)\n",
    "            # x = (x+1)/2\n",
    "            # \n",
    "            \n",
    "            \n",
    "            # x = self.fc1(x)        \n",
    "            # x = self.fc2(x)                           \n",
    "            # x = self.fc3(x)\n",
    "            # \n",
    "            \n",
    "            x = self.fc1(x)        \n",
    "            x = self.qc2a(self.fc2(x))                           \n",
    "            # x = self.qc3(self.qc3a(self.fc3(x)))\n",
    "            # \n",
    "            # x = self.qc1((self.fc1(x)))        \n",
    "            # x = self.qc2((self.fc2(x)))                           \n",
    "            # x = self.qc3((self.fc3(x)))\n",
    "            # \n",
    "        elif training == 2:\n",
    "            \n",
    "            # x = binarize(x-0.0001)\n",
    "            # x = (x+1)/2\n",
    "            \n",
    "            torch.set_printoptions(profile=\"full\")\n",
    "            \n",
    "            print(binarize(self.fc1.weight))\n",
    "            \n",
    "            \n",
    "                        \n",
    "            y = x[0]*binarize(self.fc1.weight[0])\n",
    "            print(y.sum()/y.shape[0])\n",
    "            torch.set_printoptions(profile=\"default\")\n",
    "            x = self.fc1(x)            \n",
    "            print(x)\n",
    "        else:\n",
    "            # x = self.qc1(self.fc1(x),training=False)\n",
    "            # x = self.qc2(self.fc2(x),training=False)\n",
    "            # x = self.qc3(self.fc3(x),training=False)\n",
    "            # \n",
    "            \n",
    "            # x = binarize(x-0.0001)\n",
    "            # x = (x+1)/2\n",
    "            # \n",
    "            x = self.fc1(x)                \n",
    "            x = self.qc2a(self.fc2(x),training=False)            \n",
    "            # x = self.qc3(self.qc3a(self.fc3(x),training=False),training=False)\n",
    "            # \n",
    "            # \n",
    "            # x = self.fc1(x)        \n",
    "            # x = self.fc2(x)                           \n",
    "            # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    epoch_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target,new_target = modify_target(target)\n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        # \n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data,True)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()    \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "                \n",
    "        if batch_idx % 100 == 0:        \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}/{} ({:.2f}%)'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss, correct, (batch_idx+1) * len(data),\n",
    "                100. * float(correct) / float(((batch_idx+1) * len(data)) )))                \n",
    "    print(\"-\"*20,\"training done, loss\",\"-\"*20)\n",
    "    print(\"Training Set: Average loss: {}\".format(round(sum(epoch_loss)/len(epoch_loss),6)))\n",
    "    \n",
    "accur=[]\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        target,new_target = modify_target(target)\n",
    "        \n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # print(\"Debug\")\n",
    "        # output = model(data,2)\n",
    "        # \n",
    "        # sys.exit(0)\n",
    "        # data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data,False)\n",
    "        test_loss += criterion(output, target) # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    a=100.*correct / len(test_loader.dataset)\n",
    "    accur.append(a)  \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * float(correct) / float(len(test_loader.dataset))))\n",
    "    \n",
    "    return float(correct) / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Training\n",
    "\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "print(\"=\"*10,\"Model Info\",\"=\"*10)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "# optimizer = torch.optim.SGD([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1, momentum=0.9)\n",
    "# \n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \\\n",
    "#         base_lr=[1e-1,1e-1,1e-1,1,1,1], \\\n",
    "#         max_lr=[1e-3,1e-3,1e-3,1e-2,1e-2,1e-2], \\\n",
    "#         step_size_up=100\n",
    "#         )\n",
    "\n",
    "milestones = [3, 5, 8]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)\n",
    "\n",
    "# \n",
    "# \n",
    "# test()\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==================== 0 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:29:22\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:29:22\n",
      "Train Epoch: 0 [0/12049 (0%)]\tLoss: 0.687131\tAccuracy: 32/32 (100.00%)\n",
      "Train Epoch: 0 [3200/12049 (27%)]\tLoss: 0.663223\tAccuracy: 3097/3232 (95.82%)\n",
      "Train Epoch: 0 [6400/12049 (53%)]\tLoss: 0.662204\tAccuracy: 6146/6432 (95.55%)\n",
      "Train Epoch: 0 [9600/12049 (80%)]\tLoss: 0.658946\tAccuracy: 9210/9632 (95.62%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.660859\n",
      "Trainign End at: 09/02/2020 20:30:01\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:30:01\n",
      "Test set: Average loss: 0.0204, Accuracy: 1883/1968 (95.68%)\n",
      "Testing End at: 09/02/2020 20:30:08\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9568089430894309. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:30:08\n",
      "============================================================\n",
      "\n",
      "==================== 1 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:30:08\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:30:08\n",
      "Train Epoch: 1 [0/12049 (0%)]\tLoss: 0.657883\tAccuracy: 32/32 (100.00%)\n",
      "Train Epoch: 1 [3200/12049 (27%)]\tLoss: 0.657317\tAccuracy: 3089/3232 (95.58%)\n",
      "Train Epoch: 1 [6400/12049 (53%)]\tLoss: 0.658449\tAccuracy: 6149/6432 (95.60%)\n",
      "Train Epoch: 1 [9600/12049 (80%)]\tLoss: 0.660884\tAccuracy: 9223/9632 (95.75%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658876\n",
      "Trainign End at: 09/02/2020 20:30:46\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:30:46\n",
      "Test set: Average loss: 0.0204, Accuracy: 1875/1968 (95.27%)\n",
      "Testing End at: 09/02/2020 20:30:52\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9527439024390244. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:30:52\n",
      "============================================================\n",
      "\n",
      "==================== 2 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:30:52\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:30:52\n",
      "Train Epoch: 2 [0/12049 (0%)]\tLoss: 0.656921\tAccuracy: 31/32 (96.88%)\n",
      "Train Epoch: 2 [3200/12049 (27%)]\tLoss: 0.659959\tAccuracy: 3116/3232 (96.41%)\n",
      "Train Epoch: 2 [6400/12049 (53%)]\tLoss: 0.664866\tAccuracy: 6192/6432 (96.27%)\n",
      "Train Epoch: 2 [9600/12049 (80%)]\tLoss: 0.661672\tAccuracy: 9231/9632 (95.84%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658792\n",
      "Trainign End at: 09/02/2020 20:31:32\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:31:32\n",
      "Test set: Average loss: 0.0204, Accuracy: 1880/1968 (95.53%)\n",
      "Testing End at: 09/02/2020 20:31:39\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9552845528455285. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:31:39\n",
      "============================================================\n",
      "\n",
      "==================== 3 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:31:39\n",
      "-------------------- learning rates --------------------\n",
      "0.001,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:31:39\n",
      "Train Epoch: 3 [0/12049 (0%)]\tLoss: 0.652789\tAccuracy: 31/32 (96.88%)\n",
      "Train Epoch: 3 [3200/12049 (27%)]\tLoss: 0.661742\tAccuracy: 3103/3232 (96.01%)\n",
      "Train Epoch: 3 [6400/12049 (53%)]\tLoss: 0.656084\tAccuracy: 6181/6432 (96.10%)\n",
      "Train Epoch: 3 [9600/12049 (80%)]\tLoss: 0.665755\tAccuracy: 9251/9632 (96.04%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658837\n",
      "Trainign End at: 09/02/2020 20:32:18\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:32:18\n",
      "Test set: Average loss: 0.0204, Accuracy: 1869/1968 (94.97%)\n",
      "Testing End at: 09/02/2020 20:32:25\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9496951219512195. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:32:25\n",
      "============================================================\n",
      "\n",
      "==================== 4 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:32:25\n",
      "-------------------- learning rates --------------------\n",
      "0.001,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:32:25\n",
      "Train Epoch: 4 [0/12049 (0%)]\tLoss: 0.660444\tAccuracy: 30/32 (93.75%)\n",
      "Train Epoch: 4 [3200/12049 (27%)]\tLoss: 0.657939\tAccuracy: 3104/3232 (96.04%)\n",
      "Train Epoch: 4 [6400/12049 (53%)]\tLoss: 0.662958\tAccuracy: 6182/6432 (96.11%)\n",
      "Train Epoch: 4 [9600/12049 (80%)]\tLoss: 0.657895\tAccuracy: 9260/9632 (96.14%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658753\n",
      "Trainign End at: 09/02/2020 20:33:05\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:33:05\n",
      "Test set: Average loss: 0.0204, Accuracy: 1859/1968 (94.46%)\n",
      "Testing End at: 09/02/2020 20:33:11\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9446138211382114. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:33:11\n",
      "============================================================\n",
      "\n",
      "==================== 5 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:33:11\n",
      "-------------------- learning rates --------------------\n",
      "0.00010000000000000002,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:33:11\n",
      "Train Epoch: 5 [0/12049 (0%)]\tLoss: 0.665920\tAccuracy: 32/32 (100.00%)\n",
      "Train Epoch: 5 [3200/12049 (27%)]\tLoss: 0.663559\tAccuracy: 3103/3232 (96.01%)\n",
      "Train Epoch: 5 [6400/12049 (53%)]\tLoss: 0.658723\tAccuracy: 6177/6432 (96.04%)\n",
      "Train Epoch: 5 [9600/12049 (80%)]\tLoss: 0.657444\tAccuracy: 9264/9632 (96.18%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658835\n",
      "Trainign End at: 09/02/2020 20:33:51\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:33:51\n",
      "Test set: Average loss: 0.0204, Accuracy: 1882/1968 (95.63%)\n",
      "Testing End at: 09/02/2020 20:33:58\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9563008130081301. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:33:58\n",
      "============================================================\n",
      "\n",
      "==================== 6 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:33:58\n",
      "-------------------- learning rates --------------------\n",
      "0.00010000000000000002,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:33:58\n",
      "Train Epoch: 6 [0/12049 (0%)]\tLoss: 0.655255\tAccuracy: 30/32 (93.75%)\n",
      "Train Epoch: 6 [3200/12049 (27%)]\tLoss: 0.655864\tAccuracy: 3108/3232 (96.16%)\n",
      "Train Epoch: 6 [6400/12049 (53%)]\tLoss: 0.660973\tAccuracy: 6167/6432 (95.88%)\n",
      "Train Epoch: 6 [9600/12049 (80%)]\tLoss: 0.660330\tAccuracy: 9220/9632 (95.72%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.659073\n",
      "Trainign End at: 09/02/2020 20:34:37\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:34:37\n",
      "Test set: Average loss: 0.0204, Accuracy: 1869/1968 (94.97%)\n",
      "Testing End at: 09/02/2020 20:34:44\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9496951219512195. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:34:44\n",
      "============================================================\n",
      "\n",
      "==================== 7 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:34:44\n",
      "-------------------- learning rates --------------------\n",
      "0.00010000000000000002,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:34:44\n",
      "Train Epoch: 7 [0/12049 (0%)]\tLoss: 0.661531\tAccuracy: 31/32 (96.88%)\n",
      "Train Epoch: 7 [3200/12049 (27%)]\tLoss: 0.651963\tAccuracy: 3121/3232 (96.57%)\n",
      "Train Epoch: 7 [6400/12049 (53%)]\tLoss: 0.650473\tAccuracy: 6201/6432 (96.41%)\n",
      "Train Epoch: 7 [9600/12049 (80%)]\tLoss: 0.654744\tAccuracy: 9265/9632 (96.19%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658725\n",
      "Trainign End at: 09/02/2020 20:35:25\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:35:25\n",
      "Test set: Average loss: 0.0204, Accuracy: 1871/1968 (95.07%)\n",
      "Testing End at: 09/02/2020 20:35:31\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9507113821138211. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:35:31\n",
      "============================================================\n",
      "\n",
      "==================== 8 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:35:31\n",
      "-------------------- learning rates --------------------\n",
      "1.0000000000000003e-05,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:35:31\n",
      "Train Epoch: 8 [0/12049 (0%)]\tLoss: 0.657051\tAccuracy: 32/32 (100.00%)\n",
      "Train Epoch: 8 [3200/12049 (27%)]\tLoss: 0.656826\tAccuracy: 3085/3232 (95.45%)\n",
      "Train Epoch: 8 [6400/12049 (53%)]\tLoss: 0.659642\tAccuracy: 6166/6432 (95.86%)\n",
      "Train Epoch: 8 [9600/12049 (80%)]\tLoss: 0.658371\tAccuracy: 9247/9632 (96.00%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.659063\n",
      "Trainign End at: 09/02/2020 20:36:11\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:36:11\n",
      "Test set: Average loss: 0.0204, Accuracy: 1857/1968 (94.36%)\n",
      "Testing End at: 09/02/2020 20:36:18\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9435975609756098. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:36:18\n",
      "============================================================\n",
      "\n",
      "==================== 9 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:36:18\n",
      "-------------------- learning rates --------------------\n",
      "1.0000000000000003e-05,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:36:18\n",
      "Train Epoch: 9 [0/12049 (0%)]\tLoss: 0.658448\tAccuracy: 31/32 (96.88%)\n",
      "Train Epoch: 9 [3200/12049 (27%)]\tLoss: 0.655546\tAccuracy: 3097/3232 (95.82%)\n",
      "Train Epoch: 9 [6400/12049 (53%)]\tLoss: 0.659567\tAccuracy: 6176/6432 (96.02%)\n",
      "Train Epoch: 9 [9600/12049 (80%)]\tLoss: 0.658872\tAccuracy: 9245/9632 (95.98%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658864\n",
      "Trainign End at: 09/02/2020 20:36:59\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:36:59\n",
      "Test set: Average loss: 0.0204, Accuracy: 1883/1968 (95.68%)\n",
      "Testing End at: 09/02/2020 20:37:06\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9568089430894309. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:37:06\n",
      "============================================================\n",
      "\n",
      "==================== 10 epoch ====================\n",
      "Epoch Start at: 09/02/2020 20:37:06\n",
      "-------------------- learning rates --------------------\n",
      "1.0000000000000003e-05,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 09/02/2020 20:37:06\n",
      "Train Epoch: 10 [0/12049 (0%)]\tLoss: 0.658550\tAccuracy: 32/32 (100.00%)\n",
      "Train Epoch: 10 [3200/12049 (27%)]\tLoss: 0.658736\tAccuracy: 3120/3232 (96.53%)\n",
      "Train Epoch: 10 [6400/12049 (53%)]\tLoss: 0.658803\tAccuracy: 6189/6432 (96.22%)\n",
      "Train Epoch: 10 [9600/12049 (80%)]\tLoss: 0.657824\tAccuracy: 9267/9632 (96.21%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.658806\n",
      "Trainign End at: 09/02/2020 20:37:47\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 09/02/2020 20:37:47\n",
      "Test set: Average loss: 0.0204, Accuracy: 1879/1968 (95.48%)\n",
      "Testing End at: 09/02/2020 20:37:54\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9568089430894309; Current accuracy 0.9547764227642277. Checkpointing\n",
      "Epoch End at: 09/02/2020 20:37:54\n",
      "============================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if os.path.isfile(resume_path):\n",
    "    print(\"=> loading checkpoint from '{}'<=\".format(resume_path))\n",
    "    checkpoint = torch.load(resume_path, map_location=device)\n",
    "    epoch_init,acc = checkpoint[\"epoch\"],checkpoint[\"acc\"]\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])    \n",
    "    scheduler.milestones = Counter(milestones)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "else:\n",
    "    epoch_init,acc = 0,0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if training:\n",
    "    for epoch in range(epoch_init, max_epoch + 1):\n",
    "        print(\"=\"*20,epoch,\"epoch\",\"=\"*20)  \n",
    "        print(\"Epoch Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "\n",
    "        print(\"-\"*20,\"learning rates\",\"-\"*20)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'],end=\",\")\n",
    "        print()    \n",
    "        \n",
    "        print(\"-\"*20,\"training\",\"-\"*20)\n",
    "        print(\"Trainign Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        train(epoch)\n",
    "        print(\"Trainign End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"-\"*20,\"testing\",\"-\"*20)\n",
    "        print(\"Testing Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "        cur_acc = test()\n",
    "        print(\"Testing End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        print()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        is_best = False\n",
    "        if cur_acc > acc:\n",
    "            is_best = True\n",
    "            acc=cur_acc\n",
    "        \n",
    "        print(\"Best accuracy: {}; Current accuracy {}. Checkpointing\".format(acc,cur_acc))\n",
    "        save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'acc': acc, \n",
    "          'state_dict': model.state_dict(),      \n",
    "          'optimizer' : optimizer.state_dict(),\n",
    "           'scheduler': scheduler.state_dict(),\n",
    "        }, is_best, save_path, 'checkpoint_{}_{}.pth.tar'.format(epoch,round(cur_acc,4)))\n",
    "        print(\"Epoch End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"=\"*60)\n",
    "        print()        \n",
    "else:    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
    "        num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "    test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "tensor([[[0.0102, 0.0120, 0.0099, 0.0116],\n",
      "         [0.0015, 0.0017, 0.0014, 0.0017],\n",
      "         [0.1945, 0.2279, 0.1883, 0.2206],\n",
      "         [0.0278, 0.0326, 0.0269, 0.0315]]])\n",
      "tensor([[ 2.4243e-02, -2.8395e-02, -2.3465e-02, -2.7485e-02, -3.4655e-03,\n",
      "         -4.0591e-03, -3.3544e-03, -3.9290e-03, -4.6121e-01, -5.4022e-01,\n",
      "         -4.4643e-01, -5.2290e-01, -6.5931e-02, -7.7225e-02, -6.3817e-02,\n",
      "         -7.4749e-02],\n",
      "        [ 2.8395e-02,  9.9921e-01, -6.5053e-04, -7.6197e-04, -9.6074e-05,\n",
      "         -1.1253e-04, -9.2994e-05, -1.0892e-04, -1.2786e-02, -1.4976e-02,\n",
      "         -1.2376e-02, -1.4496e-02, -1.8278e-03, -2.1409e-03, -1.7692e-03,\n",
      "         -2.0723e-03],\n",
      "        [ 2.3465e-02, -6.5053e-04,  9.9946e-01, -6.2968e-04, -7.9394e-05,\n",
      "         -9.2994e-05, -7.6849e-05, -9.0013e-05, -1.0566e-02, -1.2376e-02,\n",
      "         -1.0228e-02, -1.1980e-02, -1.5105e-03, -1.7692e-03, -1.4621e-03,\n",
      "         -1.7125e-03],\n",
      "        [ 2.7485e-02, -7.6197e-04, -6.2968e-04,  9.9926e-01, -9.2994e-05,\n",
      "         -1.0892e-04, -9.0013e-05, -1.0543e-04, -1.2376e-02, -1.4496e-02,\n",
      "         -1.1980e-02, -1.4032e-02, -1.7692e-03, -2.0723e-03, -1.7125e-03,\n",
      "         -2.0058e-03],\n",
      "        [ 3.4655e-03, -9.6074e-05, -7.9394e-05, -9.2994e-05,  9.9999e-01,\n",
      "         -1.3734e-05, -1.1350e-05, -1.3294e-05, -1.5605e-03, -1.8278e-03,\n",
      "         -1.5105e-03, -1.7692e-03, -2.2308e-04, -2.6129e-04, -2.1592e-04,\n",
      "         -2.5291e-04],\n",
      "        [ 4.0591e-03, -1.1253e-04, -9.2994e-05, -1.0892e-04, -1.3734e-05,\n",
      "          9.9998e-01, -1.3294e-05, -1.5571e-05, -1.8278e-03, -2.1409e-03,\n",
      "         -1.7692e-03, -2.0723e-03, -2.6129e-04, -3.0604e-04, -2.5291e-04,\n",
      "         -2.9623e-04],\n",
      "        [ 3.3544e-03, -9.2994e-05, -7.6849e-05, -9.0013e-05, -1.1350e-05,\n",
      "         -1.3294e-05,  9.9999e-01, -1.2868e-05, -1.5105e-03, -1.7692e-03,\n",
      "         -1.4621e-03, -1.7125e-03, -2.1592e-04, -2.5291e-04, -2.0900e-04,\n",
      "         -2.4480e-04],\n",
      "        [ 3.9290e-03, -1.0892e-04, -9.0013e-05, -1.0543e-04, -1.3294e-05,\n",
      "         -1.5571e-05, -1.2868e-05,  9.9998e-01, -1.7692e-03, -2.0723e-03,\n",
      "         -1.7125e-03, -2.0058e-03, -2.5291e-04, -2.9623e-04, -2.4480e-04,\n",
      "         -2.8674e-04],\n",
      "        [ 4.6121e-01, -1.2786e-02, -1.0566e-02, -1.2376e-02, -1.5605e-03,\n",
      "         -1.8278e-03, -1.5105e-03, -1.7692e-03,  7.9232e-01, -2.4326e-01,\n",
      "         -2.0103e-01, -2.3546e-01, -2.9688e-02, -3.4774e-02, -2.8737e-02,\n",
      "         -3.3659e-02],\n",
      "        [ 5.4022e-01, -1.4976e-02, -1.2376e-02, -1.4496e-02, -1.8278e-03,\n",
      "         -2.1409e-03, -1.7692e-03, -2.0723e-03, -2.4326e-01,  7.1507e-01,\n",
      "         -2.3546e-01, -2.7579e-01, -3.4774e-02, -4.0731e-02, -3.3659e-02,\n",
      "         -3.9425e-02],\n",
      "        [ 4.4643e-01, -1.2376e-02, -1.0228e-02, -1.1980e-02, -1.5105e-03,\n",
      "         -1.7692e-03, -1.4621e-03, -1.7125e-03, -2.0103e-01, -2.3546e-01,\n",
      "          8.0542e-01, -2.2791e-01, -2.8737e-02, -3.3659e-02, -2.7816e-02,\n",
      "         -3.2580e-02],\n",
      "        [ 5.2290e-01, -1.4496e-02, -1.1980e-02, -1.4032e-02, -1.7692e-03,\n",
      "         -2.0723e-03, -1.7125e-03, -2.0058e-03, -2.3546e-01, -2.7579e-01,\n",
      "         -2.2791e-01,  7.3305e-01, -3.3659e-02, -3.9425e-02, -3.2580e-02,\n",
      "         -3.8161e-02],\n",
      "        [ 6.5931e-02, -1.8278e-03, -1.5105e-03, -1.7692e-03, -2.2308e-04,\n",
      "         -2.6129e-04, -2.1592e-04, -2.5291e-04, -2.9688e-02, -3.4774e-02,\n",
      "         -2.8737e-02, -3.3659e-02,  9.9576e-01, -4.9710e-03, -4.1080e-03,\n",
      "         -4.8116e-03],\n",
      "        [ 7.7225e-02, -2.1409e-03, -1.7692e-03, -2.0723e-03, -2.6129e-04,\n",
      "         -3.0604e-04, -2.5291e-04, -2.9623e-04, -3.4774e-02, -4.0731e-02,\n",
      "         -3.3659e-02, -3.9425e-02, -4.9710e-03,  9.9418e-01, -4.8116e-03,\n",
      "         -5.6358e-03],\n",
      "        [ 6.3817e-02, -1.7692e-03, -1.4621e-03, -1.7125e-03, -2.1592e-04,\n",
      "         -2.5291e-04, -2.0900e-04, -2.4480e-04, -2.8737e-02, -3.3659e-02,\n",
      "         -2.7816e-02, -3.2580e-02, -4.1080e-03, -4.8116e-03,  9.9602e-01,\n",
      "         -4.6574e-03],\n",
      "        [ 7.4749e-02, -2.0723e-03, -1.7125e-03, -2.0058e-03, -2.5291e-04,\n",
      "         -2.9623e-04, -2.4480e-04, -2.8674e-04, -3.3659e-02, -3.9425e-02,\n",
      "         -3.2580e-02, -3.8161e-02, -4.8116e-03, -5.6358e-03, -4.6574e-03,\n",
      "          9.9454e-01]])\n",
      "torch.Size([16, 16])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for data, target in test_loader:\n",
    "    imshow(torchvision.utils.make_grid(data))\n",
    "    \n",
    "    \n",
    "    print(data[0])\n",
    "    data = data[0]\n",
    "    input_vec = data.view(-1)\n",
    "    vec_len = input_vec.size()[0]\n",
    "    input_matrix = torch.zeros(vec_len,vec_len)\n",
    "    input_matrix[0] = input_vec\n",
    "    input_matrix = input_matrix.transpose(0,1)        \n",
    "    u,s,v = np.linalg.svd(input_matrix)    \n",
    "    output_matrix = torch.tensor(np.dot(u,v))            \n",
    "    output_data = output_matrix[:,0].view(1,img_size,img_size)\n",
    "    \n",
    "    print(output_matrix)\n",
    "    print(output_matrix.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}