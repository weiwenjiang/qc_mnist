{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0.2616]])\n",
      "-1.0 tensor(0.1333)\n",
      "-0.5 tensor(0.4195)\n",
      "0.0 tensor(0.3560)\n",
      "tensor(0.2382)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../qiskit\")\n",
    "sys.path.append(\"../pytorch\")\n",
    "from qiskit_library import *\n",
    "# from mnist import *\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "import qiskit as qk\n",
    "from qiskit import Aer\n",
    "from qiskit import execute\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def do_slp_via_th(input_ori,w_ori):\n",
    "    p = input_ori\n",
    "    d = 4*p*(1-p)\n",
    "    e = (2*p-1)\n",
    "    # e_sq = torch.tensor(1)\n",
    "    w = w_ori\n",
    "    \n",
    "    sum_of_sq = (d+e.pow(2)).sum(-1)\n",
    "    sum_of_sq = sum_of_sq.unsqueeze(-1)        \n",
    "    sum_of_sq = sum_of_sq.expand(p.shape[0], w.shape[0])\n",
    "            \n",
    "    diag_p = torch.diag_embed(e)        \n",
    "    \n",
    "    p_w = torch.matmul(w,diag_p)\n",
    "    # print(diag_p)\n",
    "    # print(w)\n",
    "    # print(p_w)\n",
    "    # \n",
    "    z_p_w = torch.zeros_like(p_w)        \n",
    "    shft_p_w = torch.cat((p_w, z_p_w), -1)\n",
    "    \n",
    "    sum_of_cross = torch.zeros_like(p_w)\n",
    "    length = p.shape[1]    \n",
    "    \n",
    "    for shft in range(1,length):    \n",
    "        sum_of_cross += shft_p_w[:,:,0:length]*shft_p_w[:,:,shft:length+shft]\n",
    "\n",
    "    sum_of_cross = sum_of_cross.sum(-1)\n",
    "            \n",
    "    # print(sum_of_sq,sum_of_cross)\n",
    "    return (sum_of_sq+2*sum_of_cross)/(length**2) \n",
    "\n",
    "\n",
    "print(do_slp_via_th(torch.tensor([[0.415,0.319,0.01,0.662]]),torch.tensor([[1.0,1.0,1.0,1.0]])))\n",
    "\n",
    "def probility_perspective(input_ori):\n",
    "    prob = input_ori[0]\n",
    "    rand = []\n",
    "    for p in prob:\n",
    "        x = {}\n",
    "        x[-1] = 1-p\n",
    "        x[1] = p\n",
    "        rand.append(x)\n",
    "    \n",
    "    # p_0 = 0\n",
    "    # p_1 = 0\n",
    "    # p_2 = 0\n",
    "    # p_3 = 0\n",
    "    # p_4 = 0\n",
    "    # \n",
    "    sum_dist = {}\n",
    "    for i0 in [-1,1]:\n",
    "        for i1 in [-1,1]:\n",
    "            for i2 in [-1,1]:\n",
    "                for i3 in [-1,1]:\n",
    "                    if i0+i1+i2+i3 not in sum_dist.keys():\n",
    "                        sum_dist[i0+i1+i2+i3] = 0\n",
    "                    sum_dist[i0+i1+i2+i3] += rand[0][i0]*rand[1][i1]*rand[2][i2]*rand[3][i3]                \n",
    "    \n",
    "    square_sum = 0 \n",
    "    for k,v in sum_dist.items():\n",
    "        # print(k,v)\n",
    "        if k<=0:\n",
    "            print(k/4,v)\n",
    "            square_sum += (k/4)**2*v\n",
    "\n",
    "    print(square_sum)\n",
    "    # print(rand[0][1]*rand[1][1]*rand[2][1]*rand[3][1])        \n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "probility_perspective(torch.tensor([[0.415,0.319,0.01,0.662]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Input = [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
    "#          1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
    "#          1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
    "#          1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
    "#          1.,  1.,  1.,  1.,  1., -1., -1., -1.]\n",
    "# \n",
    "# \n",
    "# w_l1 = [         \n",
    "#     [-1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
    "#           1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.,\n",
    "#          -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
    "#           1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
    "#          -1., -1.,  1., -1.,  1., -1., -1.,  1.],\n",
    "#         [-1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
    "#           1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,\n",
    "#          -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
    "#           1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
    "#          -1.,  1., -1.,  1.,  1., -1.,  1.,  1.],\n",
    "#         [ 1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
    "#           1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
    "#          -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
    "#           1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
    "#           1., -1., -1., -1., -1., -1.,  1.,  1.],\n",
    "#         [-1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
    "#           1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
    "#          -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
    "#          -1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
    "#          -1., -1., -1., -1., -1., -1., -1.,  1.]]\n",
    "# \n",
    "# maxIndex = len(Input)\n",
    "#         \n",
    "# \n",
    "# \n",
    "# \n",
    "# q_en = qk.QuantumRegister(6,\"encoded\")\n",
    "# q_out = qk.QuantumRegister(len(w_l1),\"output\")\n",
    "# c = qk.ClassicalRegister(len(w_l1),\"reg\")\n",
    "# aux = qk.QuantumRegister(4,\"aux\")\n",
    "# \n",
    "# circuit = qk.QuantumCircuit(q_en, aux, q_out, c)\n",
    "# \n",
    "# # SLP_8_encoding(circuit, q_io, q_en, input)\n",
    "# # reset_qbits(q_io)\n",
    "# \n",
    "# \n",
    "# for idx in range(len(w_l1)):\n",
    "#     \n",
    "#     for qbit in q_en:\n",
    "#         circuit.h(qbit)\n",
    "#     circuit.barrier()    \n",
    "#     SLP_8_Uw(circuit, q_en, Input, aux)\n",
    "#     circuit.barrier()\n",
    "#     SLP_8_Uw(circuit, q_en, w_l1[idx], aux)\n",
    "#     \n",
    "#     circuit.barrier()\n",
    "#     for qbit in q_en:\n",
    "#         circuit.h(qbit)\n",
    "#         circuit.x(qbit)\n",
    "#     ccccccx(circuit,q_en,q_out[idx],aux)\n",
    "#     # ccccx(circuit, q_en[0], q_en[1], q_en[2], q_en[3], q_out[idx], aux[0], aux[1])\n",
    "#     circuit.barrier()\n",
    "#     reset_qbits(circuit,q_en)\n",
    "\n",
    "# \n",
    "# \n",
    "# # reset_qbits(q_en)\n",
    "# circuit.barrier()\n",
    "# \n",
    "# for idx in range(len(w_l1)):\n",
    "#     circuit.swap(q_en[idx],q_out[idx])\n",
    "#     \n",
    "# circuit.barrier()\n",
    "# \n",
    "# SLP_4_encoding(circuit,q_en[0:4],q_out[0:2],aux=aux)\n",
    "#  \n",
    "# print(circuit)\n",
    "# \n",
    "# \n",
    "# \n",
    "# qc_shots = 100\n",
    "# num_c_reg = len(w_l1)\n",
    "# \n",
    "# print(\"=\"*50)\n",
    "# print(\"Start simulation:\")\n",
    "# start = time.time()        \n",
    "# iters = 1\n",
    "# counts = simulate(circuit,qc_shots,iters,False)\n",
    "# \n",
    "# end = time.time()\n",
    "# qc_time = end - start\n",
    "# \n",
    "# \n",
    "# print(\"From QC:\",counts)\n",
    "# print(\"Simulation elasped time:\",qc_time)\n",
    "#     \n",
    "# def analyze(counts):\n",
    "#     mycount = {}\n",
    "#     for i in range(num_c_reg):\n",
    "#         mycount[i] = 0\n",
    "#     for k,v in counts.items():\n",
    "#         bits = len(k) \n",
    "#         for i in range(bits):            \n",
    "#             if k[bits-1-i] == \"1\":\n",
    "#                 if i in mycount.keys():\n",
    "#                     mycount[i] += v\n",
    "#                 else:\n",
    "#                     mycount[i] = v\n",
    "#     return mycount,bits\n",
    "# \n",
    "# # for k,v in counts[0].items():\n",
    "# #     print(k,v)\n",
    "# (mycount,bits) = analyze(counts[0])\n",
    "# \n",
    "# for b in range(bits):\n",
    "#     print (b,float(mycount[b])/qc_shots)\n",
    "#     \n",
    "# \n",
    "# \n",
    "# print(\"=\"*100)\n",
    "# import torch\n",
    "# print(\"Theoretic Analysis\")\n",
    "# \n",
    "# \n",
    "# test_input = (torch.tensor([Input])+1)/2\n",
    "# test_weight = torch.tensor(w_l1)\n",
    "# print(do_slp_via_th(test_input,test_weight))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# INPUTs\n",
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "IFM = tensor([[0.1098, 0.1765, 0.0510, 0.0000, 0.1333, 0.4784, 0.3608, 0.0000, 0.0000,\n",
    "         0.1922, 0.4549, 0.0980, 0.0000, 0.0706, 0.2824, 0.1137]])\n",
    "W1_0 = tensor([[-1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
    "          1., -1.]])\n",
    "W1_1 = tensor([[-1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
    "         -1., -1.]])\n",
    "W1_2 = tensor([[ 1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
    "          1.,  1.]])\n",
    "W1_3 = tensor([[ 1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1.,\n",
    "         -1.,  1.]])\n",
    "\n",
    "W1 = W1_3\n",
    "\n",
    "OFM1 = tensor([[0.0316, 0.3768, 0.3218, 0.0273]])\n",
    "\n",
    "OFM1_QC = tensor([[0.0349, 0.3748, 0.3283, 0.0280]])\n",
    "\n",
    "W2_0 =tensor([[ 1.,  1., -1.,  1.]])\n",
    "W2_1 =tensor([[-1.,  1., -1., -1.]])\n",
    "\n",
    "W2 = W2_1\n",
    "\n",
    "OFM2 = tensor([[0.3238, 0.3756]])\n",
    "\n",
    "\n",
    "test_L1 = False\n",
    "\n",
    "if test_L1:\n",
    "    input = torch.tensor(IFM[0])*2-1\n",
    "    \n",
    "    q_in = qk.QuantumRegister(16,\"io\")\n",
    "    q_enc = qk.QuantumRegister(4,\"encoder\")\n",
    "    q_out = qk.QuantumRegister(len(W1),\"output\")\n",
    "    c = qk.ClassicalRegister(len(W1),\"reg\")\n",
    "    aux = qk.QuantumRegister(4,\"aux\")\n",
    "\n",
    "    maxIndex = len(input)\n",
    "    circuit = qk.QuantumCircuit(q_in, q_enc, q_out, aux, c)\n",
    "    \n",
    "    for idx in range(len(W1)):\n",
    "        SLP_16_encoding(circuit, q_in, q_enc, input, aux)    \n",
    "        SLP_16_Uw(circuit,q_enc,W1[idx], aux)\n",
    "        circuit.barrier()\n",
    "    \n",
    "        for qbit in q_enc[0:4]:\n",
    "            circuit.h(qbit)\n",
    "            circuit.x(qbit)\n",
    "        ccccx(circuit, q_enc[0], q_enc[1], q_enc[2], q_enc[3], q_out[idx], aux[0], aux[1])\n",
    "        circuit.barrier()\n",
    "        \n",
    "        # reset_qbits(circuit,q_in)\n",
    "        # reset_qbits(circuit,q_enc)\n",
    "    \n",
    "    for idx in range(len(W1)):        \n",
    "        circuit.measure(q_out[idx],c[idx])\n",
    "\n",
    "        \n",
    "else:\n",
    "    input = torch.tensor(OFM1_QC[0])*2-1\n",
    "    \n",
    "    q_in = qk.QuantumRegister(4,\"io\")\n",
    "    q_enc = qk.QuantumRegister(2,\"encoder\")\n",
    "    q_out = qk.QuantumRegister(len(W2),\"output\")\n",
    "    c = qk.ClassicalRegister(len(W2),\"reg\")\n",
    "    aux = qk.QuantumRegister(4,\"aux\")\n",
    "\n",
    "    maxIndex = len(input)\n",
    "    circuit = qk.QuantumCircuit(q_in, q_enc, q_out, aux, c)\n",
    "\n",
    "    for idx in range(len(W2)):\n",
    "        SLP_4_encoding(circuit, q_in, q_enc, input, aux)\n",
    "        \n",
    "        SLP_4_Uw(circuit,q_enc,W2[idx], aux)\n",
    "        circuit.barrier()\n",
    "    \n",
    "        for qbit in q_enc[0:2]:\n",
    "            circuit.h(qbit)\n",
    "            circuit.x(qbit)\n",
    "        circuit.ccx(q_enc[0], q_enc[1], q_out[idx])\n",
    "        circuit.barrier()\n",
    "        \n",
    "        # reset_qbits(circuit,q_in)\n",
    "        # reset_qbits(circuit,q_enc)\n",
    "    \n",
    "    for idx in range(len(W1)):        \n",
    "        circuit.measure(q_out[idx],c[idx])\n",
    "\n",
    "\n",
    "print(circuit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "qc_shots = 10000\n",
    "num_c_reg = len(W1)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Start simulation:\")\n",
    "start = time.time()        \n",
    "iters = 1\n",
    "counts = simulate(circuit,qc_shots,iters,False)\n",
    "\n",
    "end = time.time()\n",
    "qc_time = end - start\n",
    "\n",
    "\n",
    "print(\"From QC:\",counts)\n",
    "print(\"Simulation elasped time:\",qc_time)\n",
    "    \n",
    "def analyze(counts):\n",
    "    mycount = {}\n",
    "    for i in range(num_c_reg):\n",
    "        mycount[i] = 0\n",
    "    for k,v in counts.items():\n",
    "        bits = len(k) \n",
    "        for i in range(bits):            \n",
    "            if k[bits-1-i] == \"1\":\n",
    "                if i in mycount.keys():\n",
    "                    mycount[i] += v\n",
    "                else:\n",
    "                    mycount[i] = v\n",
    "    return mycount,bits\n",
    "\n",
    "# for k,v in counts[0].items():\n",
    "#     print(k,v)\n",
    "(mycount,bits) = analyze(counts[0])\n",
    "\n",
    "for b in range(bits):\n",
    "    print (b,float(mycount[b])/qc_shots)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "import torch\n",
    "print(\"Theoretic Analysis\")\n",
    "\n",
    "\n",
    "\n",
    "test_input = IFM\n",
    "print(test_input)\n",
    "print(do_slp_via_th(test_input,W1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison Reulst:\n",
    "\n",
    "#### IFM\n",
    "\n",
    "0.1098, 0.1765, 0.0510, 0.0000,\n",
    " \n",
    "0.1333, 0.4784, 0.3608, 0.0000,\n",
    "\n",
    "0.0000, 0.1922, 0.4549, 0.0980,\n",
    " \n",
    "0.0000, 0.0706, 0.2824, 0.1137\n",
    "\n",
    "#### Layer 1:\n",
    "Theoretic_Result = [0.0316, 0.3768, 0.3218, 0.0273]\n",
    "\n",
    "Quantum_Resuts = [0.0349, 0.3748, 0.3283, 0.0280] # Shots: 10^4\n",
    "\n",
    "#### Layer 2:\n",
    "\n",
    "\n",
    "Theoretic_Result = [0.3238, 0.3756]\n",
    "\n",
    "Quantum_Resuts = [0.3140, 0.3797] # Shots: 10^4, Using Theoretic_Results in Layer 1\n",
    "\n",
    "Quantum_Resuts = [0.3215, 0.3725] # Shots: 10^4, Using Quantum_Resuts in Layer 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}