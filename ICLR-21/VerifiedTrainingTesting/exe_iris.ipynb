{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "====================================================================================================\n",
      "Training procedure for Quantum Computer:\n",
      "\tStart at: 11/11/2020 21:34:05\n",
      "\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\n",
      "\tEnjoy and Good Luck!\n",
      "====================================================================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import functools\n",
    "from collections import Counter\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "from lib_net import *\n",
    "from lib_util import *\n",
    "\n",
    "# interest_num = [0,1,2,3,4,5,6,7,8,9]\n",
    "interest_num = [0,3,6]\n",
    "img_size = 28\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 16\n",
    "inference_batch_size = 16\n",
    "num_f1 = 32\n",
    "num_f2 = len(interest_num)\n",
    "init_lr = 0.01\n",
    "\n",
    "\n",
    "save_to_file = False\n",
    "if save_to_file:\n",
    "    sys.stdout = open(save_path+\"/log\", 'w')\n",
    "save_path = \"./model/\"+os.path.basename(sys.argv[0])+\"_\"+time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "resume_path = \"\"\n",
    "training = True\n",
    "max_epoch = 10\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Training procedure for Quantum Computer:\")\n",
    "print(\"\\tStart at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "print(\"\\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\")\n",
    "print(\"\\tEnjoy and Good Luck!\")\n",
    "print(\"=\"*100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# def modify_target(target):\n",
    "#     for j in range(len(target)):\n",
    "#         for idx in range(len(interest_num)):\n",
    "#             if target[j] == interest_num[idx]:\n",
    "#                 target[j] = idx\n",
    "#                 break\n",
    "# \n",
    "#     new_target = torch.zeros(target.shape[0],2)\n",
    "# \n",
    "#     for i in range(target.shape[0]):        \n",
    "#         if target[i].item() == 0:            \n",
    "#             new_target[i] = torch.tensor([1,0]).clone()     \n",
    "#         else:\n",
    "#             new_target[i] = torch.tensor([0,1]).clone()\n",
    "# \n",
    "#     return target,new_target\n",
    "# \n",
    "# def select_num(dataset,interest_num):\n",
    "#     labels = dataset.targets #get labels\n",
    "#     labels = labels.numpy()\n",
    "#     idx = {}\n",
    "#     for num in interest_num:\n",
    "#         idx[num] = np.where(labels == num)\n",
    "#         \n",
    "#     fin_idx = idx[interest_num[0]]\n",
    "#     for i in range(1,len(interest_num)):           \n",
    "#         \n",
    "#         fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "#     \n",
    "#     fin_idx = fin_idx[0]    \n",
    "#     \n",
    "#     dataset.targets = labels[fin_idx]\n",
    "#     dataset.data = dataset.data[fin_idx]\n",
    "#     \n",
    "#     # print(dataset.targets.shape)\n",
    "#     \n",
    "#     dataset.targets,_ = modify_target(dataset.targets,interest_num)\n",
    "#     # print(dataset.targets.shape)\n",
    "#     \n",
    "#     return dataset\n",
    "# \n",
    "# \n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# dataset = pd.read_csv(\"../iris.data\")\n",
    "# dataset.columns = [\"sepal length (cm)\", \n",
    "#                    \"sepal width (cm)\", \n",
    "#                    \"petal length (cm)\", \n",
    "#                    \"petal width (cm)\", \n",
    "#                    \"species\"]\n",
    "# \n",
    "# mappings = {\n",
    "#    \"Iris-setosa\": 0,\n",
    "#    \"Iris-versicolor\": 1,\n",
    "#    \"Iris-virginica\": 2\n",
    "# }\n",
    "# dataset[\"species\"] = dataset[\"species\"].apply(lambda x: mappings[x])\n",
    "# \n",
    "# X = dataset.drop(\"species\",axis=1).values\n",
    "# y = dataset[\"species\"].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\n",
    "# \n",
    "# X_train = torch.FloatTensor(X_train)\n",
    "# y_train = torch.LongTensor(y_train)\n",
    "# \n",
    "# X_test = torch.FloatTensor(X_test)\n",
    "# y_test = torch.LongTensor(y_test)\n",
    "# \n",
    "# train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_data = torch.utils.data.TensorDataset(X_test,y_test)\n",
    "# \n",
    "# # prepare data loaders\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "#     num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "#     num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor()])\n",
    "# transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='../../pytorch/data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='../../pytorch/data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, save_path, filename):\n",
    "    filename = os.path.join(save_path, filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        bestname = os.path.join(save_path, 'model_best.tar')\n",
    "        shutil.copyfile(filename, bestname)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "28 [32, 3] True [[1, -1, 1, -1], [-1, -1]] True True False True False\n",
      "========== Model Info ==========\n",
      "Net(\n",
      "  (fc0): BinaryLinearClassic(in_features=784, out_features=32, bias=False)\n",
      "  (fc1): BinaryLinearClassic(in_features=32, out_features=3, bias=False)\n",
      "  (bn0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    epoch_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target,new_target = modify_target(target,interest_num)\n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        # \n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data,True)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()    \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "                \n",
    "        if batch_idx % 100 == 0:        \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}/{} ({:.2f}%)'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss, correct, (batch_idx+1) * len(data),\n",
    "                100. * float(correct) / float(((batch_idx+1) * len(data)) )))                \n",
    "    print(\"-\"*20,\"training done, loss\",\"-\"*20)\n",
    "    print(\"Training Set: Average loss: {}\".format(round(sum(epoch_loss)/len(epoch_loss),6)))\n",
    "    \n",
    "accur=[]\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        target,new_target = modify_target(target,interest_num)\n",
    "        \n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # print(\"Debug\")\n",
    "        # output = model(data,2)\n",
    "        # \n",
    "        # sys.exit(0)\n",
    "        # data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data,False)\n",
    "        test_loss += criterion(output, target) # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    a=100.*correct / len(test_loader.dataset)\n",
    "    accur.append(a)  \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * float(correct) / float(len(test_loader.dataset))))\n",
    "    \n",
    "    return float(correct) / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Training\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net(img_size,[num_f1,num_f2],True,[[1, -1, 1, -1], [-1, -1]],\n",
    "            True,training,False,True,False).to(\"cpu\")\n",
    "\n",
    "\n",
    "# -nn \"4, 2\" -bin -qt -c $dataset -s 4 -l 0.1 -ql 0.0001 -e 5 -m \"2, 4\"\n",
    "# def __init__(self,img_size,layers,with_norm,given_ang,train_ang,training,binary,classic,debug=\"False\"):\n",
    "\n",
    "\n",
    "print(\"=\"*10,\"Model Info\",\"=\"*10)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "# optimizer = torch.optim.SGD([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1, momentum=0.9)\n",
    "# \n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \\\n",
    "#         base_lr=[1e-1,1e-1,1e-1,1,1,1], \\\n",
    "#         max_lr=[1e-3,1e-3,1e-3,1e-2,1e-2,1e-2], \\\n",
    "#         step_size_up=100\n",
    "#         )\n",
    "\n",
    "milestones = [3, 5, 8]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)\n",
    "\n",
    "# \n",
    "# \n",
    "# test()\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==================== 0 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:34:08\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:34:08\n",
      "Train Epoch: 0 [0/17972 (0%)]\tLoss: 1.228707\tAccuracy: 5/16 (31.25%)\n",
      "Train Epoch: 0 [1600/17972 (9%)]\tLoss: 0.637241\tAccuracy: 1359/1616 (84.10%)\n",
      "Train Epoch: 0 [3200/17972 (18%)]\tLoss: 0.626339\tAccuracy: 2887/3216 (89.77%)\n",
      "Train Epoch: 0 [4800/17972 (27%)]\tLoss: 0.551445\tAccuracy: 4411/4816 (91.59%)\n",
      "Train Epoch: 0 [6400/17972 (36%)]\tLoss: 0.599876\tAccuracy: 5925/6416 (92.35%)\n",
      "Train Epoch: 0 [8000/17972 (45%)]\tLoss: 0.665225\tAccuracy: 7463/8016 (93.10%)\n",
      "Train Epoch: 0 [9600/17972 (53%)]\tLoss: 0.563726\tAccuracy: 8997/9616 (93.56%)\n",
      "Train Epoch: 0 [11200/17972 (62%)]\tLoss: 0.571002\tAccuracy: 10527/11216 (93.86%)\n",
      "Train Epoch: 0 [12800/17972 (71%)]\tLoss: 0.551570\tAccuracy: 12074/12816 (94.21%)\n",
      "Train Epoch: 0 [14400/17972 (80%)]\tLoss: 0.595407\tAccuracy: 13586/14416 (94.24%)\n",
      "Train Epoch: 0 [16000/17972 (89%)]\tLoss: 0.555246\tAccuracy: 15120/16016 (94.41%)\n",
      "Train Epoch: 0 [17600/17972 (98%)]\tLoss: 0.551445\tAccuracy: 16650/17616 (94.52%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.607426\n",
      "Trainign End at: 11/11/2020 21:34:24\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:34:24\n",
      "Test set: Average loss: 0.0354, Accuracy: 2899/2948 (98.34%)\n",
      "Testing End at: 11/11/2020 21:34:25\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9833785617367707; Current accuracy 0.9833785617367707. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:34:25\n",
      "============================================================\n",
      "\n",
      "==================== 1 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:34:25\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:34:25\n",
      "Train Epoch: 1 [0/17972 (0%)]\tLoss: 0.606510\tAccuracy: 15/16 (93.75%)\n",
      "Train Epoch: 1 [1600/17972 (9%)]\tLoss: 0.567452\tAccuracy: 1571/1616 (97.22%)\n",
      "Train Epoch: 1 [3200/17972 (18%)]\tLoss: 0.551445\tAccuracy: 3104/3216 (96.52%)\n",
      "Train Epoch: 1 [4800/17972 (27%)]\tLoss: 0.551445\tAccuracy: 4649/4816 (96.53%)\n",
      "Train Epoch: 1 [6400/17972 (36%)]\tLoss: 0.613945\tAccuracy: 6206/6416 (96.73%)\n",
      "Train Epoch: 1 [8000/17972 (45%)]\tLoss: 0.570854\tAccuracy: 7773/8016 (96.97%)\n",
      "Train Epoch: 1 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9333/9616 (97.06%)\n",
      "Train Epoch: 1 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 10881/11216 (97.01%)\n",
      "Train Epoch: 1 [12800/17972 (71%)]\tLoss: 0.613945\tAccuracy: 12403/12816 (96.78%)\n",
      "Train Epoch: 1 [14400/17972 (80%)]\tLoss: 0.588944\tAccuracy: 13933/14416 (96.65%)\n",
      "Train Epoch: 1 [16000/17972 (89%)]\tLoss: 0.646367\tAccuracy: 15482/16016 (96.67%)\n",
      "Train Epoch: 1 [17600/17972 (98%)]\tLoss: 0.551445\tAccuracy: 17030/17616 (96.67%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.58533\n",
      "Trainign End at: 11/11/2020 21:34:44\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:34:44\n",
      "Test set: Average loss: 0.0356, Accuracy: 2889/2948 (98.00%)\n",
      "Testing End at: 11/11/2020 21:34:46\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9833785617367707; Current accuracy 0.9799864314789688. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:34:46\n",
      "============================================================\n",
      "\n",
      "==================== 2 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:34:46\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:34:46\n",
      "Train Epoch: 2 [0/17972 (0%)]\tLoss: 0.551445\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 2 [1600/17972 (9%)]\tLoss: 0.551445\tAccuracy: 1561/1616 (96.60%)\n",
      "Train Epoch: 2 [3200/17972 (18%)]\tLoss: 0.563708\tAccuracy: 3111/3216 (96.74%)\n",
      "Train Epoch: 2 [4800/17972 (27%)]\tLoss: 0.551445\tAccuracy: 4649/4816 (96.53%)\n",
      "Train Epoch: 2 [6400/17972 (36%)]\tLoss: 0.551445\tAccuracy: 6204/6416 (96.70%)\n",
      "Train Epoch: 2 [8000/17972 (45%)]\tLoss: 0.551445\tAccuracy: 7747/8016 (96.64%)\n",
      "Train Epoch: 2 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9290/9616 (96.61%)\n",
      "Train Epoch: 2 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 10839/11216 (96.64%)\n",
      "Train Epoch: 2 [12800/17972 (71%)]\tLoss: 0.551445\tAccuracy: 12388/12816 (96.66%)\n",
      "Train Epoch: 2 [14400/17972 (80%)]\tLoss: 0.613945\tAccuracy: 13944/14416 (96.73%)\n",
      "Train Epoch: 2 [16000/17972 (89%)]\tLoss: 0.551445\tAccuracy: 15504/16016 (96.80%)\n",
      "Train Epoch: 2 [17600/17972 (98%)]\tLoss: 0.568926\tAccuracy: 17060/17616 (96.84%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.583423\n",
      "Trainign End at: 11/11/2020 21:35:07\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:35:07\n",
      "Test set: Average loss: 0.0352, Accuracy: 2905/2948 (98.54%)\n",
      "Testing End at: 11/11/2020 21:35:09\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9854138398914518; Current accuracy 0.9854138398914518. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:35:09\n",
      "============================================================\n",
      "\n",
      "==================== 3 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:35:09\n",
      "-------------------- learning rates --------------------\n",
      "0.001,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:35:09\n",
      "Train Epoch: 3 [0/17972 (0%)]\tLoss: 0.655501\tAccuracy: 14/16 (87.50%)\n",
      "Train Epoch: 3 [1600/17972 (9%)]\tLoss: 0.626722\tAccuracy: 1580/1616 (97.77%)\n",
      "Train Epoch: 3 [3200/17972 (18%)]\tLoss: 0.671651\tAccuracy: 3144/3216 (97.76%)\n",
      "Train Epoch: 3 [4800/17972 (27%)]\tLoss: 0.554817\tAccuracy: 4694/4816 (97.47%)\n",
      "Train Epoch: 3 [6400/17972 (36%)]\tLoss: 0.573399\tAccuracy: 6256/6416 (97.51%)\n",
      "Train Epoch: 3 [8000/17972 (45%)]\tLoss: 0.613945\tAccuracy: 7819/8016 (97.54%)\n",
      "Train Epoch: 3 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9380/9616 (97.55%)\n",
      "Train Epoch: 3 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 10949/11216 (97.62%)\n",
      "Train Epoch: 3 [12800/17972 (71%)]\tLoss: 0.724453\tAccuracy: 12508/12816 (97.60%)\n",
      "Train Epoch: 3 [14400/17972 (80%)]\tLoss: 0.551445\tAccuracy: 14074/14416 (97.63%)\n",
      "Train Epoch: 3 [16000/17972 (89%)]\tLoss: 0.551445\tAccuracy: 15634/16016 (97.61%)\n",
      "Train Epoch: 3 [17600/17972 (98%)]\tLoss: 0.551445\tAccuracy: 17201/17616 (97.64%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.575394\n",
      "Trainign End at: 11/11/2020 21:35:33\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:35:33\n",
      "Test set: Average loss: 0.0352, Accuracy: 2907/2948 (98.61%)\n",
      "Testing End at: 11/11/2020 21:35:35\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9860922659430122; Current accuracy 0.9860922659430122. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:35:35\n",
      "============================================================\n",
      "\n",
      "==================== 4 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:35:35\n",
      "-------------------- learning rates --------------------\n",
      "0.001,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:35:35\n",
      "Train Epoch: 4 [0/17972 (0%)]\tLoss: 0.551445\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 4 [1600/17972 (9%)]\tLoss: 0.551445\tAccuracy: 1589/1616 (98.33%)\n",
      "Train Epoch: 4 [3200/17972 (18%)]\tLoss: 0.551445\tAccuracy: 3155/3216 (98.10%)\n",
      "Train Epoch: 4 [4800/17972 (27%)]\tLoss: 0.551445\tAccuracy: 4730/4816 (98.21%)\n",
      "Train Epoch: 4 [6400/17972 (36%)]\tLoss: 0.653194\tAccuracy: 6296/6416 (98.13%)\n",
      "Train Epoch: 4 [8000/17972 (45%)]\tLoss: 0.551445\tAccuracy: 7859/8016 (98.04%)\n",
      "Train Epoch: 4 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9420/9616 (97.96%)\n",
      "Train Epoch: 4 [11200/17972 (62%)]\tLoss: 0.630019\tAccuracy: 10985/11216 (97.94%)\n",
      "Train Epoch: 4 [12800/17972 (71%)]\tLoss: 0.588270\tAccuracy: 12551/12816 (97.93%)\n",
      "Train Epoch: 4 [14400/17972 (80%)]\tLoss: 0.551445\tAccuracy: 14119/14416 (97.94%)\n",
      "Train Epoch: 4 [16000/17972 (89%)]\tLoss: 0.551445\tAccuracy: 15690/16016 (97.96%)\n",
      "Train Epoch: 4 [17600/17972 (98%)]\tLoss: 0.551445\tAccuracy: 17266/17616 (98.01%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.571411\n",
      "Trainign End at: 11/11/2020 21:35:54\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:35:54\n",
      "Test set: Average loss: 0.0352, Accuracy: 2907/2948 (98.61%)\n",
      "Testing End at: 11/11/2020 21:35:56\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9860922659430122; Current accuracy 0.9860922659430122. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:35:56\n",
      "============================================================\n",
      "\n",
      "==================== 5 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:35:56\n",
      "-------------------- learning rates --------------------\n",
      "0.00010000000000000002,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:35:56\n",
      "Train Epoch: 5 [0/17972 (0%)]\tLoss: 0.551445\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 5 [1600/17972 (9%)]\tLoss: 0.551445\tAccuracy: 1577/1616 (97.59%)\n",
      "Train Epoch: 5 [3200/17972 (18%)]\tLoss: 0.607657\tAccuracy: 3147/3216 (97.85%)\n",
      "Train Epoch: 5 [4800/17972 (27%)]\tLoss: 0.613945\tAccuracy: 4717/4816 (97.94%)\n",
      "Train Epoch: 5 [6400/17972 (36%)]\tLoss: 0.559479\tAccuracy: 6293/6416 (98.08%)\n",
      "Train Epoch: 5 [8000/17972 (45%)]\tLoss: 0.551445\tAccuracy: 7859/8016 (98.04%)\n",
      "Train Epoch: 5 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9440/9616 (98.17%)\n",
      "Train Epoch: 5 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 11007/11216 (98.14%)\n",
      "Train Epoch: 5 [12800/17972 (71%)]\tLoss: 0.557344\tAccuracy: 12577/12816 (98.14%)\n",
      "Train Epoch: 5 [14400/17972 (80%)]\tLoss: 0.617688\tAccuracy: 14145/14416 (98.12%)\n",
      "Train Epoch: 5 [16000/17972 (89%)]\tLoss: 0.596557\tAccuracy: 15720/16016 (98.15%)\n",
      "Train Epoch: 5 [17600/17972 (98%)]\tLoss: 0.551445\tAccuracy: 17297/17616 (98.19%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.570527\n",
      "Trainign End at: 11/11/2020 21:36:18\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:36:18\n",
      "Test set: Average loss: 0.0352, Accuracy: 2908/2948 (98.64%)\n",
      "Testing End at: 11/11/2020 21:36:20\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9864314789687924; Current accuracy 0.9864314789687924. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:36:20\n",
      "============================================================\n",
      "\n",
      "==================== 6 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:36:20\n",
      "-------------------- learning rates --------------------\n",
      "0.00010000000000000002,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:36:20\n",
      "Train Epoch: 6 [0/17972 (0%)]\tLoss: 0.551445\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 6 [1600/17972 (9%)]\tLoss: 0.611667\tAccuracy: 1587/1616 (98.21%)\n",
      "Train Epoch: 6 [3200/17972 (18%)]\tLoss: 0.551445\tAccuracy: 3154/3216 (98.07%)\n",
      "Train Epoch: 6 [4800/17972 (27%)]\tLoss: 0.584856\tAccuracy: 4729/4816 (98.19%)\n",
      "Train Epoch: 6 [6400/17972 (36%)]\tLoss: 0.551445\tAccuracy: 6301/6416 (98.21%)\n",
      "Train Epoch: 6 [8000/17972 (45%)]\tLoss: 0.650399\tAccuracy: 7870/8016 (98.18%)\n",
      "Train Epoch: 6 [9600/17972 (53%)]\tLoss: 0.588854\tAccuracy: 9434/9616 (98.11%)\n",
      "Train Epoch: 6 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 11000/11216 (98.07%)\n",
      "Train Epoch: 6 [12800/17972 (71%)]\tLoss: 0.551445\tAccuracy: 12568/12816 (98.06%)\n",
      "Train Epoch: 6 [14400/17972 (80%)]\tLoss: 0.551445\tAccuracy: 14132/14416 (98.03%)\n",
      "Train Epoch: 6 [16000/17972 (89%)]\tLoss: 0.590715\tAccuracy: 15693/16016 (97.98%)\n",
      "Train Epoch: 6 [17600/17972 (98%)]\tLoss: 0.585643\tAccuracy: 17258/17616 (97.97%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.571338\n",
      "Trainign End at: 11/11/2020 21:36:44\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:36:44\n",
      "Test set: Average loss: 0.0352, Accuracy: 2905/2948 (98.54%)\n",
      "Testing End at: 11/11/2020 21:36:46\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9864314789687924; Current accuracy 0.9854138398914518. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:36:46\n",
      "============================================================\n",
      "\n",
      "==================== 7 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:36:46\n",
      "-------------------- learning rates --------------------\n",
      "0.00010000000000000002,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:36:46\n",
      "Train Epoch: 7 [0/17972 (0%)]\tLoss: 0.551445\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 7 [1600/17972 (9%)]\tLoss: 0.551445\tAccuracy: 1585/1616 (98.08%)\n",
      "Train Epoch: 7 [3200/17972 (18%)]\tLoss: 0.570854\tAccuracy: 3151/3216 (97.98%)\n",
      "Train Epoch: 7 [4800/17972 (27%)]\tLoss: 0.570854\tAccuracy: 4708/4816 (97.76%)\n",
      "Train Epoch: 7 [6400/17972 (36%)]\tLoss: 0.551445\tAccuracy: 6275/6416 (97.80%)\n",
      "Train Epoch: 7 [8000/17972 (45%)]\tLoss: 0.563237\tAccuracy: 7846/8016 (97.88%)\n",
      "Train Epoch: 7 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9417/9616 (97.93%)\n",
      "Train Epoch: 7 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 10995/11216 (98.03%)\n",
      "Train Epoch: 7 [12800/17972 (71%)]\tLoss: 0.570650\tAccuracy: 12559/12816 (97.99%)\n",
      "Train Epoch: 7 [14400/17972 (80%)]\tLoss: 0.581104\tAccuracy: 14130/14416 (98.02%)\n",
      "Train Epoch: 7 [16000/17972 (89%)]\tLoss: 0.565969\tAccuracy: 15701/16016 (98.03%)\n",
      "Train Epoch: 7 [17600/17972 (98%)]\tLoss: 0.613945\tAccuracy: 17269/17616 (98.03%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.571156\n",
      "Trainign End at: 11/11/2020 21:37:09\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:37:09\n",
      "Test set: Average loss: 0.0352, Accuracy: 2909/2948 (98.68%)\n",
      "Testing End at: 11/11/2020 21:37:11\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9867706919945726; Current accuracy 0.9867706919945726. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:37:11\n",
      "============================================================\n",
      "\n",
      "==================== 8 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:37:11\n",
      "-------------------- learning rates --------------------\n",
      "1.0000000000000003e-05,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:37:11\n",
      "Train Epoch: 8 [0/17972 (0%)]\tLoss: 0.551445\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 8 [1600/17972 (9%)]\tLoss: 0.613945\tAccuracy: 1590/1616 (98.39%)\n",
      "Train Epoch: 8 [3200/17972 (18%)]\tLoss: 0.551445\tAccuracy: 3141/3216 (97.67%)\n",
      "Train Epoch: 8 [4800/17972 (27%)]\tLoss: 0.551445\tAccuracy: 4714/4816 (97.88%)\n",
      "Train Epoch: 8 [6400/17972 (36%)]\tLoss: 0.551445\tAccuracy: 6282/6416 (97.91%)\n",
      "Train Epoch: 8 [8000/17972 (45%)]\tLoss: 0.613945\tAccuracy: 7856/8016 (98.00%)\n",
      "Train Epoch: 8 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9427/9616 (98.03%)\n",
      "Train Epoch: 8 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 10999/11216 (98.07%)\n",
      "Train Epoch: 8 [12800/17972 (71%)]\tLoss: 0.597258\tAccuracy: 12574/12816 (98.11%)\n",
      "Train Epoch: 8 [14400/17972 (80%)]\tLoss: 0.613945\tAccuracy: 14142/14416 (98.10%)\n",
      "Train Epoch: 8 [16000/17972 (89%)]\tLoss: 0.551445\tAccuracy: 15723/16016 (98.17%)\n",
      "Train Epoch: 8 [17600/17972 (98%)]\tLoss: 0.674304\tAccuracy: 17282/17616 (98.10%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.56993\n",
      "Trainign End at: 11/11/2020 21:37:34\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:37:34\n",
      "Test set: Average loss: 0.0352, Accuracy: 2907/2948 (98.61%)\n",
      "Testing End at: 11/11/2020 21:37:36\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9867706919945726; Current accuracy 0.9860922659430122. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:37:36\n",
      "============================================================\n",
      "\n",
      "==================== 9 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:37:36\n",
      "-------------------- learning rates --------------------\n",
      "1.0000000000000003e-05,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:37:36\n",
      "Train Epoch: 9 [0/17972 (0%)]\tLoss: 0.583212\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 9 [1600/17972 (9%)]\tLoss: 0.551445\tAccuracy: 1595/1616 (98.70%)\n",
      "Train Epoch: 9 [3200/17972 (18%)]\tLoss: 0.551445\tAccuracy: 3161/3216 (98.29%)\n",
      "Train Epoch: 9 [4800/17972 (27%)]\tLoss: 0.551445\tAccuracy: 4716/4816 (97.92%)\n",
      "Train Epoch: 9 [6400/17972 (36%)]\tLoss: 0.613945\tAccuracy: 6298/6416 (98.16%)\n",
      "Train Epoch: 9 [8000/17972 (45%)]\tLoss: 0.585643\tAccuracy: 7852/8016 (97.95%)\n",
      "Train Epoch: 9 [9600/17972 (53%)]\tLoss: 0.603762\tAccuracy: 9420/9616 (97.96%)\n",
      "Train Epoch: 9 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 10988/11216 (97.97%)\n",
      "Train Epoch: 9 [12800/17972 (71%)]\tLoss: 0.556930\tAccuracy: 12562/12816 (98.02%)\n",
      "Train Epoch: 9 [14400/17972 (80%)]\tLoss: 0.551445\tAccuracy: 14141/14416 (98.09%)\n",
      "Train Epoch: 9 [16000/17972 (89%)]\tLoss: 0.551445\tAccuracy: 15705/16016 (98.06%)\n",
      "Train Epoch: 9 [17600/17972 (98%)]\tLoss: 0.551445\tAccuracy: 17278/17616 (98.08%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.571138\n",
      "Trainign End at: 11/11/2020 21:37:58\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:37:58\n",
      "Test set: Average loss: 0.0352, Accuracy: 2904/2948 (98.51%)\n",
      "Testing End at: 11/11/2020 21:38:00\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9867706919945726; Current accuracy 0.9850746268656716. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:38:00\n",
      "============================================================\n",
      "\n",
      "==================== 10 epoch ====================\n",
      "Epoch Start at: 11/11/2020 21:38:00\n",
      "-------------------- learning rates --------------------\n",
      "1.0000000000000003e-05,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 21:38:00\n",
      "Train Epoch: 10 [0/17972 (0%)]\tLoss: 0.551445\tAccuracy: 16/16 (100.00%)\n",
      "Train Epoch: 10 [1600/17972 (9%)]\tLoss: 0.551445\tAccuracy: 1589/1616 (98.33%)\n",
      "Train Epoch: 10 [3200/17972 (18%)]\tLoss: 0.551445\tAccuracy: 3156/3216 (98.13%)\n",
      "Train Epoch: 10 [4800/17972 (27%)]\tLoss: 0.613945\tAccuracy: 4725/4816 (98.11%)\n",
      "Train Epoch: 10 [6400/17972 (36%)]\tLoss: 0.564521\tAccuracy: 6299/6416 (98.18%)\n",
      "Train Epoch: 10 [8000/17972 (45%)]\tLoss: 0.551445\tAccuracy: 7865/8016 (98.12%)\n",
      "Train Epoch: 10 [9600/17972 (53%)]\tLoss: 0.551445\tAccuracy: 9429/9616 (98.06%)\n",
      "Train Epoch: 10 [11200/17972 (62%)]\tLoss: 0.551445\tAccuracy: 10995/11216 (98.03%)\n",
      "Train Epoch: 10 [12800/17972 (71%)]\tLoss: 0.551445\tAccuracy: 12565/12816 (98.04%)\n",
      "Train Epoch: 10 [14400/17972 (80%)]\tLoss: 0.551445\tAccuracy: 14135/14416 (98.05%)\n",
      "Train Epoch: 10 [16000/17972 (89%)]\tLoss: 0.551445\tAccuracy: 15712/16016 (98.10%)\n",
      "Train Epoch: 10 [17600/17972 (98%)]\tLoss: 0.577996\tAccuracy: 17271/17616 (98.04%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.57123\n",
      "Trainign End at: 11/11/2020 21:38:24\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 21:38:24\n",
      "Test set: Average loss: 0.0352, Accuracy: 2906/2948 (98.58%)\n",
      "Testing End at: 11/11/2020 21:38:26\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.9867706919945726; Current accuracy 0.985753052917232. Checkpointing\n",
      "Epoch End at: 11/11/2020 21:38:26\n",
      "============================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if os.path.isfile(resume_path):\n",
    "    print(\"=> loading checkpoint from '{}'<=\".format(resume_path))\n",
    "    checkpoint = torch.load(resume_path, map_location=device)\n",
    "    epoch_init,acc = checkpoint[\"epoch\"],checkpoint[\"acc\"]\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])    \n",
    "    scheduler.milestones = Counter(milestones)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "else:\n",
    "    epoch_init,acc = 0,0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if training:\n",
    "    for epoch in range(epoch_init, max_epoch + 1):\n",
    "        print(\"=\"*20,epoch,\"epoch\",\"=\"*20)  \n",
    "        print(\"Epoch Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "\n",
    "        print(\"-\"*20,\"learning rates\",\"-\"*20)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'],end=\",\")\n",
    "        print()    \n",
    "        \n",
    "        print(\"-\"*20,\"training\",\"-\"*20)\n",
    "        print(\"Trainign Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        train(epoch)\n",
    "        print(\"Trainign End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"-\"*20,\"testing\",\"-\"*20)\n",
    "        print(\"Testing Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "        cur_acc = test()\n",
    "        print(\"Testing End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        print()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        is_best = False\n",
    "        if cur_acc > acc:\n",
    "            is_best = True\n",
    "            acc=cur_acc\n",
    "        \n",
    "        print(\"Best accuracy: {}; Current accuracy {}. Checkpointing\".format(acc,cur_acc))\n",
    "        save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'acc': acc, \n",
    "          'state_dict': model.state_dict(),      \n",
    "          'optimizer' : optimizer.state_dict(),\n",
    "           'scheduler': scheduler.state_dict(),\n",
    "        }, is_best, save_path, 'checkpoint_{}_{}.pth.tar'.format(epoch,round(cur_acc,4)))\n",
    "        print(\"Epoch End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"=\"*60)\n",
    "        print()        \n",
    "else:    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
    "        num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "    test()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}