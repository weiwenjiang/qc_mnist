{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "====================================================================================================\n",
      "Training procedure for Quantum Computer:\n",
      "\tStart at: 11/11/2020 18:29:54\n",
      "\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\n",
      "\tEnjoy and Good Luck!\n",
      "====================================================================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import functools\n",
    "from collections import Counter\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "from lib_net import *\n",
    "from lib_util import *\n",
    "\n",
    "# interest_num = [0,1,2,3,4,5,6,7,8,9]\n",
    "interest_num = [3,6]\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 16\n",
    "inference_batch_size = 16\n",
    "num_f1 = 16\n",
    "num_f2 = len(interest_num)\n",
    "init_lr = 0.01\n",
    "\n",
    "\n",
    "save_to_file = False\n",
    "if save_to_file:\n",
    "    sys.stdout = open(save_path+\"/log\", 'w')\n",
    "save_path = \"./model/\"+os.path.basename(sys.argv[0])+\"_\"+time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "resume_path = \"\"\n",
    "training = True\n",
    "max_epoch = 10\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Training procedure for Quantum Computer:\")\n",
    "print(\"\\tStart at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "print(\"\\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\")\n",
    "print(\"\\tEnjoy and Good Luck!\")\n",
    "print(\"=\"*100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# def modify_target(target):\n",
    "#     for j in range(len(target)):\n",
    "#         for idx in range(len(interest_num)):\n",
    "#             if target[j] == interest_num[idx]:\n",
    "#                 target[j] = idx\n",
    "#                 break\n",
    "# \n",
    "#     new_target = torch.zeros(target.shape[0],2)\n",
    "# \n",
    "#     for i in range(target.shape[0]):        \n",
    "#         if target[i].item() == 0:            \n",
    "#             new_target[i] = torch.tensor([1,0]).clone()     \n",
    "#         else:\n",
    "#             new_target[i] = torch.tensor([0,1]).clone()\n",
    "# \n",
    "#     return target,new_target\n",
    "# \n",
    "# def select_num(dataset,interest_num):\n",
    "#     labels = dataset.targets #get labels\n",
    "#     labels = labels.numpy()\n",
    "#     idx = {}\n",
    "#     for num in interest_num:\n",
    "#         idx[num] = np.where(labels == num)\n",
    "#         \n",
    "#     fin_idx = idx[interest_num[0]]\n",
    "#     for i in range(1,len(interest_num)):           \n",
    "#         \n",
    "#         fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "#     \n",
    "#     fin_idx = fin_idx[0]    \n",
    "#     \n",
    "#     dataset.targets = labels[fin_idx]\n",
    "#     dataset.data = dataset.data[fin_idx]\n",
    "#     \n",
    "#     # print(dataset.targets.shape)\n",
    "#     \n",
    "#     dataset.targets,_ = modify_target(dataset.targets,interest_num)\n",
    "#     # print(dataset.targets.shape)\n",
    "#     \n",
    "#     return dataset\n",
    "# \n",
    "# \n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# dataset = pd.read_csv(\"../iris.data\")\n",
    "# dataset.columns = [\"sepal length (cm)\", \n",
    "#                    \"sepal width (cm)\", \n",
    "#                    \"petal length (cm)\", \n",
    "#                    \"petal width (cm)\", \n",
    "#                    \"species\"]\n",
    "# \n",
    "# mappings = {\n",
    "#    \"Iris-setosa\": 0,\n",
    "#    \"Iris-versicolor\": 1,\n",
    "#    \"Iris-virginica\": 2\n",
    "# }\n",
    "# dataset[\"species\"] = dataset[\"species\"].apply(lambda x: mappings[x])\n",
    "# \n",
    "# X = dataset.drop(\"species\",axis=1).values\n",
    "# y = dataset[\"species\"].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\n",
    "# \n",
    "# X_train = torch.FloatTensor(X_train)\n",
    "# y_train = torch.LongTensor(y_train)\n",
    "# \n",
    "# X_test = torch.FloatTensor(X_test)\n",
    "# y_test = torch.LongTensor(y_test)\n",
    "# \n",
    "# train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_data = torch.utils.data.TensorDataset(X_test,y_test)\n",
    "# \n",
    "# # prepare data loaders\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "#     num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "#     num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor()])\n",
    "# transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='../../pytorch/data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='../../pytorch/data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, save_path, filename):\n",
    "    filename = os.path.join(save_path, filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        bestname = os.path.join(save_path, 'model_best.tar')\n",
    "        shutil.copyfile(filename, bestname)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "4 [16, 2] True [[1, -1, 1, -1], [-1, -1]] True True False False False\n",
      "========== Model Info ==========\n",
      "Net(\n",
      "  (fc0): BinaryLinearQuantumFirstLAYER(in_features=16, out_features=16, bias=False)\n",
      "  (fc1): BinaryLinearClassic(in_features=16, out_features=2, bias=False)\n",
      "  (qca1): QC_Norm_Correction_try2()\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    epoch_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target,new_target = modify_target(target,interest_num)\n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        # \n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data,True)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()    \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "                \n",
    "        if batch_idx % 100 == 0:        \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}/{} ({:.2f}%)'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss, correct, (batch_idx+1) * len(data),\n",
    "                100. * float(correct) / float(((batch_idx+1) * len(data)) )))                \n",
    "    print(\"-\"*20,\"training done, loss\",\"-\"*20)\n",
    "    print(\"Training Set: Average loss: {}\".format(round(sum(epoch_loss)/len(epoch_loss),6)))\n",
    "    \n",
    "accur=[]\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        target,new_target = modify_target(target,interest_num)\n",
    "        \n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # print(\"Debug\")\n",
    "        # output = model(data,2)\n",
    "        # \n",
    "        # sys.exit(0)\n",
    "        # data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data,False)\n",
    "        test_loss += criterion(output, target) # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    a=100.*correct / len(test_loader.dataset)\n",
    "    accur.append(a)  \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * float(correct) / float(len(test_loader.dataset))))\n",
    "    \n",
    "    return float(correct) / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Training\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net(img_size,[num_f1,num_f2],True,[[1, -1, 1, -1], [-1, -1]],\n",
    "            True,training,False,False,False).to(\"cpu\")\n",
    "\n",
    "\n",
    "# -nn \"4, 2\" -bin -qt -c $dataset -s 4 -l 0.1 -ql 0.0001 -e 5 -m \"2, 4\"\n",
    "# def __init__(self,img_size,layers,with_norm,given_ang,train_ang,training,binary,classic,debug=\"False\"):\n",
    "\n",
    "\n",
    "print(\"=\"*10,\"Model Info\",\"=\"*10)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "# optimizer = torch.optim.SGD([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1, momentum=0.9)\n",
    "# \n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \\\n",
    "#         base_lr=[1e-1,1e-1,1e-1,1,1,1], \\\n",
    "#         max_lr=[1e-3,1e-3,1e-3,1e-2,1e-2,1e-2], \\\n",
    "#         step_size_up=100\n",
    "#         )\n",
    "\n",
    "milestones = [3, 5, 8]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)\n",
    "\n",
    "# \n",
    "# \n",
    "# test()\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==================== 0 epoch ====================\n",
      "Epoch Start at: 11/11/2020 18:29:56\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 18:29:56\n",
      "Train Epoch: 0 [0/12049 (0%)]\tLoss: 0.694402\tAccuracy: 8/16 (50.00%)\n",
      "Train Epoch: 0 [1600/12049 (13%)]\tLoss: 0.668814\tAccuracy: 803/1616 (49.69%)\n",
      "Train Epoch: 0 [3200/12049 (27%)]\tLoss: 0.678215\tAccuracy: 1654/3216 (51.43%)\n",
      "Train Epoch: 0 [4800/12049 (40%)]\tLoss: 0.669456\tAccuracy: 2429/4816 (50.44%)\n",
      "Train Epoch: 0 [6400/12049 (53%)]\tLoss: 0.678210\tAccuracy: 3184/6416 (49.63%)\n",
      "Train Epoch: 0 [8000/12049 (66%)]\tLoss: 0.698141\tAccuracy: 3956/8016 (49.35%)\n",
      "Train Epoch: 0 [9600/12049 (80%)]\tLoss: 0.673458\tAccuracy: 4735/9616 (49.24%)\n",
      "Train Epoch: 0 [11200/12049 (93%)]\tLoss: 0.677545\tAccuracy: 5517/11216 (49.19%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.674826\n",
      "Trainign End at: 11/11/2020 18:30:02\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 18:30:02\n",
      "Test set: Average loss: 0.0418, Accuracy: 958/1968 (48.68%)\n",
      "Testing End at: 11/11/2020 18:30:03\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.4867886178861789; Current accuracy 0.4867886178861789. Checkpointing\n",
      "Epoch End at: 11/11/2020 18:30:03\n",
      "============================================================\n",
      "\n",
      "==================== 1 epoch ====================\n",
      "Epoch Start at: 11/11/2020 18:30:03\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 18:30:03\n",
      "Train Epoch: 1 [0/12049 (0%)]\tLoss: 0.684462\tAccuracy: 5/16 (31.25%)\n",
      "Train Epoch: 1 [1600/12049 (13%)]\tLoss: 0.671944\tAccuracy: 778/1616 (48.14%)\n",
      "Train Epoch: 1 [3200/12049 (27%)]\tLoss: 0.671555\tAccuracy: 1545/3216 (48.04%)\n",
      "Train Epoch: 1 [4800/12049 (40%)]\tLoss: 0.664633\tAccuracy: 2304/4816 (47.84%)\n",
      "Train Epoch: 1 [6400/12049 (53%)]\tLoss: 0.667930\tAccuracy: 3114/6416 (48.53%)\n",
      "Train Epoch: 1 [8000/12049 (66%)]\tLoss: 0.683801\tAccuracy: 3908/8016 (48.75%)\n",
      "Train Epoch: 1 [9600/12049 (80%)]\tLoss: 0.687496\tAccuracy: 4714/9616 (49.02%)\n",
      "Train Epoch: 1 [11200/12049 (93%)]\tLoss: 0.675531\tAccuracy: 5494/11216 (48.98%)\n",
      "-------------------- training done, loss --------------------\n",
      "Training Set: Average loss: 0.673419\n",
      "Trainign End at: 11/11/2020 18:30:09\n",
      "------------------------------------------------------------\n",
      "\n",
      "-------------------- testing --------------------\n",
      "Testing Start at: 11/11/2020 18:30:09\n",
      "Test set: Average loss: 0.0421, Accuracy: 958/1968 (48.68%)\n",
      "Testing End at: 11/11/2020 18:30:10\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best accuracy: 0.4867886178861789; Current accuracy 0.4867886178861789. Checkpointing\n",
      "Epoch End at: 11/11/2020 18:30:10\n",
      "============================================================\n",
      "\n",
      "==================== 2 epoch ====================\n",
      "Epoch Start at: 11/11/2020 18:30:10\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 11/11/2020 18:30:10\n",
      "Train Epoch: 2 [0/12049 (0%)]\tLoss: 0.679488\tAccuracy: 7/16 (43.75%)\n",
      "Train Epoch: 2 [1600/12049 (13%)]\tLoss: 0.665248\tAccuracy: 757/1616 (46.84%)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-098a67ba971e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trainign Start at:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%m/%d/%Y %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trainign End at:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%m/%d/%Y %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6dbbd44b5384>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodify_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterest_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "if os.path.isfile(resume_path):\n",
    "    print(\"=> loading checkpoint from '{}'<=\".format(resume_path))\n",
    "    checkpoint = torch.load(resume_path, map_location=device)\n",
    "    epoch_init,acc = checkpoint[\"epoch\"],checkpoint[\"acc\"]\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])    \n",
    "    scheduler.milestones = Counter(milestones)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "else:\n",
    "    epoch_init,acc = 0,0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if training:\n",
    "    for epoch in range(epoch_init, max_epoch + 1):\n",
    "        print(\"=\"*20,epoch,\"epoch\",\"=\"*20)  \n",
    "        print(\"Epoch Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "\n",
    "        print(\"-\"*20,\"learning rates\",\"-\"*20)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'],end=\",\")\n",
    "        print()    \n",
    "        \n",
    "        print(\"-\"*20,\"training\",\"-\"*20)\n",
    "        print(\"Trainign Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        train(epoch)\n",
    "        print(\"Trainign End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"-\"*20,\"testing\",\"-\"*20)\n",
    "        print(\"Testing Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "        cur_acc = test()\n",
    "        print(\"Testing End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        print()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        is_best = False\n",
    "        if cur_acc > acc:\n",
    "            is_best = True\n",
    "            acc=cur_acc\n",
    "        \n",
    "        print(\"Best accuracy: {}; Current accuracy {}. Checkpointing\".format(acc,cur_acc))\n",
    "        save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'acc': acc, \n",
    "          'state_dict': model.state_dict(),      \n",
    "          'optimizer' : optimizer.state_dict(),\n",
    "           'scheduler': scheduler.state_dict(),\n",
    "        }, is_best, save_path, 'checkpoint_{}_{}.pth.tar'.format(epoch,round(cur_acc,4)))\n",
    "        print(\"Epoch End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"=\"*60)\n",
    "        print()        \n",
    "else:    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
    "        num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "    test()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}