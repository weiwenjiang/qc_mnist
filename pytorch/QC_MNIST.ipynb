{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "====================================================================================================\n",
      "Training procedure for Quantum Computer:\n",
      "\tStart at: 04/27/2020 16:07:01\n",
      "\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\n",
      "\tEnjoy and Good Luck!\n",
      "====================================================================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import functools\n",
    "from collections import Counter\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "# interest_num = [0,1,2,3,4,5,6,7,8,9]\n",
    "interest_num = [3,6]\n",
    "img_size = 32\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "inference_batch_size = 32\n",
    "num_f1 = 32\n",
    "num_f2 = 16\n",
    "num_f3 = len(interest_num)\n",
    "init_lr = 0.01\n",
    "\n",
    "\n",
    "save_to_file = False\n",
    "if save_to_file:\n",
    "    sys.stdout = open(save_path+\"/log\", 'w')\n",
    "save_path = \"./model/\"+os.path.basename(sys.argv[0])+\"_\"+time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "resume_path = \"\"\n",
    "training = True\n",
    "max_epoch = 10\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Training procedure for Quantum Computer:\")\n",
    "print(\"\\tStart at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "print(\"\\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\")\n",
    "print(\"\\tEnjoy and Good Luck!\")\n",
    "print(\"=\"*100)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    \n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "        \n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "        \n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    \n",
    "    # print(dataset.targets.shape)\n",
    "    \n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    # print(dataset.targets.shape)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor()])\n",
    "# transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, save_path, filename):\n",
    "    filename = os.path.join(save_path, filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        bestname = os.path.join(save_path, 'model_best.tar')\n",
    "        shutil.copyfile(filename, bestname)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "0.0 0.0 0.0 0.0 \n",
      "0.9019607843137255 0.09411764705882353 0.9882352941176471 0.0 \n",
      "0.0 0.0 0.5254901960784314 0.0 \n",
      "0.0 0.0 0.5176470588235295 0.0 \n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ],
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# functions to show an image\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    # image = np.asarray(npimg[0])\n",
    "    im = Image.fromarray(image,mode=\"L\")\n",
    "    \n",
    "    im.save(\"32*32.jpg\",cmap=\"gray\") \n",
    "    im = im.resize((4,4))    \n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            print(im.getpixel((i,j))/255,end=\" \")\n",
    "        print()\n",
    "    plt.imshow(im,cmap='gray',)\n",
    "    \n",
    "    plt.show()\n",
    "    im.save(\"4*4.jpg\",cmap=\"gray\") \n",
    "    sys.exit(0)\n",
    "    \n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % filtered_class[labels[j]] for j in range(batch_size)))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "========== Model Info ==========\n",
      "Net(\n",
      "  (fc1): BinaryLinear(in_features=64, out_features=32, bias=False)\n",
      "  (fc2): BinaryLinear(in_features=32, out_features=16, bias=False)\n",
      "  (fc3): BinaryLinear(in_features=16, out_features=10, bias=False)\n",
      "  (qc1): QC_Norm()\n",
      "  (qc2): QC_Norm()\n",
      "  (qc3): QC_Norm()\n",
      "  (qc1a): QC_Norm_Correction()\n",
      "  (qc2a): QC_Norm_Correction()\n",
      "  (qc3a): QC_Norm_Correction()\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    " \n",
    "\n",
    "class BinarizeF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cxt, input):\n",
    "        output = input.new(input.size())\n",
    "        output[input >= 0] = 1\n",
    "        output[input < 0] = -1\n",
    "        \n",
    "              \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(cxt, grad_output):\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input\n",
    "# aliases\n",
    "binarize = BinarizeF.apply\n",
    "\n",
    "\n",
    "class ClipF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = input.clone().detach()\n",
    "        # output = input.new(input.size())\n",
    "        output[input >= 1] = 1\n",
    "        output[input <= 0] = 0\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input >= 1] = 0\n",
    "        grad_input[input <= 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "# aliases\n",
    "clipfunc = ClipF.apply\n",
    "\n",
    "\n",
    "class BinaryLinear(nn.Linear):\n",
    "    \n",
    "    \n",
    "    def do_slp_via_th(self,input_ori,w_ori):\n",
    "        p = input_ori\n",
    "        d = 4*p*(1-p)\n",
    "        e = (2*p-1)\n",
    "        # e_sq = torch.tensor(1)\n",
    "        w = w_ori\n",
    "        \n",
    "        sum_of_sq = (d+e.pow(2)).sum(-1)\n",
    "        sum_of_sq = sum_of_sq.unsqueeze(-1)        \n",
    "        sum_of_sq = sum_of_sq.expand(p.shape[0], w.shape[0])\n",
    "                \n",
    "        diag_p = torch.diag_embed(e)        \n",
    "        \n",
    "        p_w = torch.matmul(w,diag_p)\n",
    "        \n",
    "        z_p_w = torch.zeros_like(p_w)        \n",
    "        shft_p_w = torch.cat((p_w, z_p_w), -1)\n",
    "        \n",
    "        sum_of_cross = torch.zeros_like(p_w)\n",
    "        length = p.shape[1]    \n",
    "        \n",
    "        for shft in range(1,length):    \n",
    "            sum_of_cross += shft_p_w[:,:,0:length]*shft_p_w[:,:,shft:length+shft]\n",
    "\n",
    "        sum_of_cross = sum_of_cross.sum(-1)\n",
    "                \n",
    "        return (sum_of_sq+2*sum_of_cross)/(length**2) \n",
    "    \n",
    "    def forward(self, input):        \n",
    "        binary_weight = binarize(self.weight)        \n",
    "        if self.bias is None:\n",
    "            return self.do_slp_via_th(input,binary_weight)\n",
    "                      \n",
    "        else:   \n",
    "            \n",
    "            bias_one  = torch.ones(input.shape[0],1)            \n",
    "            new_input = torch.cat((input, bias_one), -1)            \n",
    "            bias = clipfunc(self.bias).unsqueeze(1)            \n",
    "            new_weight = binary_weight            \n",
    "            new_weight = torch.cat((new_weight,bias),-1)                        \n",
    "            return self.do_slp_via_th(new_input,new_weight)\n",
    "            \n",
    "            \n",
    "            torch.set_printoptions(edgeitems=64)\n",
    "            # binary_bias = binarize(self.bias)/float(len(input[0].flatten())+1)\n",
    "            binary_bias = binarize(self.bias)/float(len(input[0].flatten())+1)\n",
    "            res = F.linear(input, binary_weight/float(len(input[0].flatten())+1), binary_bias)\n",
    "            return res\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Glorot initialization\n",
    "        in_features, out_features = self.weight.size()\n",
    "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "        self.weight.lr_scale = 1. / stdv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QC_Norm(nn.Module):\n",
    "    def __init__(self, num_features, momentum=0.1):        \n",
    "        super(QC_Norm, self).__init__()\n",
    "        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)        \n",
    "        self.ang_inc = Parameter(torch.ones(1)*10)\n",
    "        \n",
    "        self.momentum = momentum\n",
    "                \n",
    "        self.printed = False\n",
    "        self.x_mean_ancle=0\n",
    "        self.x_mean_rote = 0\n",
    "        self.input = 0\n",
    "        self.output = 0\n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            if not self.printed:\n",
    "                print(\"self.ang_inc\",self.ang_inc)\n",
    "                self.printed = True\n",
    "                    \n",
    "            x = x.transpose(0,1)\n",
    "  \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+self.x_running_rot.unsqueeze(-1)\n",
    "            x_1 = (x_final.cos()+1)/2\n",
    "                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:\n",
    "            self.printed = False\n",
    "            x = x.transpose(0,1)        \n",
    "            x_sum = x.sum(-1).unsqueeze(-1).expand(x.shape)\n",
    "            x_lack_sum = x_sum - x    \n",
    "            x_mean = x_lack_sum/x.shape[-1]\n",
    "            \n",
    "            \n",
    "                    \n",
    "            x_mean_ancle = (x_mean*2-1).acos()  \n",
    "            \n",
    "            ang_inc = self.ang_inc.unsqueeze(-1).expand(x_mean_ancle.shape) \n",
    "            # ang_inc = np.pi/2/(x.max(-1)[0].unsqueeze(-1).expand(x_mean_ancle.shape) -x.min(-1)[0].unsqueeze(-1).expand(x_mean_ancle.shape) )\n",
    "            x_mean_rote = (np.pi/2 - x_mean_ancle)*20 # ang_inc\n",
    "            \n",
    "            x_moving_rot = (x_mean_rote.sum(-1)/x.shape[-1])            \n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot\n",
    "                                                \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+x_mean_rote  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "      \n",
    "        return x_1\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        self.ang_inc.data.zeros_()\n",
    "        \n",
    "def print_degree(x,name=\"x\"):\n",
    "    print(name,x/np.pi*180)\n",
    "    \n",
    "    \n",
    "class QC_Norm_Real(nn.Module):\n",
    "    def __init__(self,num_features,momentum=0.1):        \n",
    "        super(QC_Norm_Real, self).__init__()        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.x_max = 0\n",
    "        self.x_min = 0\n",
    "        # print(\"Using Normal without real\")\n",
    "        \n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            x = x.transpose(0,1)\n",
    "            \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            # x_final = x_ancle+self.x_running_rot.unsqueeze(-1)  \n",
    "            x_final = ((x_ancle-self.x_min)/(self.x_max-self.x_min))*np.pi\n",
    "            \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x = x.transpose(0,1)        \n",
    "            x_ancle = (x*2-1).acos()     \n",
    "            x_rectify_ancle = (x_ancle.max(-1)[0]-x_ancle.min(-1)[0]).unsqueeze(-1).expand(x.shape)                                                                         \n",
    "            x_final = ((x_ancle-x_ancle.min(-1)[0].unsqueeze(-1))/(x_rectify_ancle))*np.pi\n",
    "            \n",
    "            x_moving_rot = x_final - x_ancle\n",
    "            \n",
    "            x_moving_rot_mean = x_moving_rot.sum(-1)/x.shape[-1] \n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot_mean      \n",
    "            \n",
    "            self.x_max = self.momentum * x_ancle.max(-1)[0].unsqueeze(-1) + \\\n",
    "                                    (1 - self.momentum) * self.x_max\n",
    "            self.x_min = self.momentum * x_ancle.min(-1)[0].unsqueeze(-1) + \\\n",
    "                                    (1 - self.momentum) * self.x_min\n",
    "            \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "            \n",
    "        return x_1\n",
    "\n",
    "\n",
    "class QC_Norm_Real_Correction(nn.Module):\n",
    "    def __init__(self,num_features,momentum=0.1):        \n",
    "        super(QC_Norm_Real_Correction, self).__init__()        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            x = x.transpose(0,1)\n",
    "            \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+self.x_running_rot.unsqueeze(-1)  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:            \n",
    "            \n",
    "            x = x.transpose(0,1)                    \n",
    "            x_ancle = (x*2-1).acos()                        \n",
    "            x_moving_rot = -1*(x_ancle.min(-1)[0])\n",
    "            \n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot                                                    \n",
    "            x_final = x_ancle+x_moving_rot.unsqueeze(-1)                                    \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "            \n",
    "        \n",
    "        return x_1\n",
    "\n",
    "class QC_Norm_Correction(nn.Module):\n",
    "    def __init__(self,num_features,momentum=0.1):        \n",
    "        super(QC_Norm_Correction, self).__init__()        \n",
    "        self.x_running_rot = Parameter(torch.zeros(num_features),requires_grad=False)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def forward(self,x,training=True):  \n",
    "        if not training:\n",
    "            x = x.transpose(0,1)\n",
    "            \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+self.x_running_rot.unsqueeze(-1)  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "            \n",
    "        else:\n",
    "            x = x.transpose(0,1)        \n",
    "            x_sum = x.sum(-1).unsqueeze(-1).expand(x.shape)                \n",
    "            x_mean = x_sum/x.shape[-1]\n",
    "                                \n",
    "            x_mean_ancle = (x_mean*2-1).acos()    \n",
    "            x_mean_rote = (np.pi/2 - x_mean_ancle) \n",
    "            \n",
    "            x_moving_rot = (x_mean_rote.sum(-1)/x.shape[-1])\n",
    "            self.x_running_rot[:] = self.momentum * self.x_running_rot + \\\n",
    "                                  (1 - self.momentum) * x_moving_rot                                        \n",
    "            x_ancle = (x*2-1).acos()\n",
    "            x_final = x_ancle+x_mean_rote  \n",
    "            x_1 = (x_final.cos()+1)/2                                \n",
    "            x_1 = x_1.transpose(0,1)\n",
    "        \n",
    "        return x_1\n",
    "\n",
    "## Define the NN architecture\n",
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1 = BinaryLinear(img_size*img_size,num_f1,bias=False)\n",
    "        self.fc2 = BinaryLinear(num_f1,num_f2,bias=False)\n",
    "        self.fc3 = BinaryLinear(num_f2,num_f3,bias=False)\n",
    "        # # \n",
    "        # self.qc1 = QC_Norm(num_features=num_f1)\n",
    "        # self.qc2 = QC_Norm(num_features=num_f2)\n",
    "        # self.qc3 = QC_Norm(num_features=num_f3)\n",
    "\n",
    "        self.qc1a = QC_Norm_Correction(num_features=num_f1)\n",
    "        self.qc2a = QC_Norm_Correction(num_features=num_f2)\n",
    "        self.qc3a = QC_Norm_Correction(num_features=num_f3)\n",
    "        # \n",
    "        # \n",
    "        self.qc1 = QC_Norm_Real(num_features=num_f1)\n",
    "        self.qc2 = QC_Norm_Real(num_features=num_f2)\n",
    "        self.qc3 = QC_Norm_Real(num_features=num_f3)\n",
    "\n",
    "\n",
    "        # self.qc1a = QC_Norm_Real_Correction(num_features=num_f1)\n",
    "        # self.qc2a = QC_Norm_Real_Correction(num_features=num_f2)\n",
    "        # self.qc3a = QC_Norm_Real_Correction(num_features=num_f3)\n",
    "        # \n",
    "    def forward(self, x, training=1):        \n",
    "        x = x.view(-1, img_size * img_size)\n",
    "        \n",
    "        if training == 1:\n",
    "            # x = binarize(x-0.0001)\n",
    "            # x = (x+1)/2\n",
    "            # \n",
    "            \n",
    "            \n",
    "            # x = self.fc1(x)        \n",
    "            # x = self.fc2(x)                           \n",
    "            # x = self.fc3(x)\n",
    "            # \n",
    "            \n",
    "            x = self.qc1(self.qc1a(self.fc1(x)))        \n",
    "            x = self.qc2(self.qc2a(self.fc2(x)))                           \n",
    "            x = self.qc3(self.qc3a(self.fc3(x)))\n",
    "            # \n",
    "            # x = self.qc1((self.fc1(x)))        \n",
    "            # x = self.qc2((self.fc2(x)))                           \n",
    "            # x = self.qc3((self.fc3(x)))\n",
    "            # \n",
    "        elif training == 2:\n",
    "            \n",
    "            # x = binarize(x-0.0001)\n",
    "            # x = (x+1)/2\n",
    "            \n",
    "            torch.set_printoptions(profile=\"full\")\n",
    "            \n",
    "            print(binarize(self.fc1.weight))\n",
    "            \n",
    "            \n",
    "                        \n",
    "            y = x[0]*binarize(self.fc1.weight[0])\n",
    "            print(y.sum()/y.shape[0])\n",
    "            torch.set_printoptions(profile=\"default\")\n",
    "            x = self.fc1(x)            \n",
    "            print(x)\n",
    "        else:\n",
    "            # x = self.qc1(self.fc1(x),training=False)\n",
    "            # x = self.qc2(self.fc2(x),training=False)\n",
    "            # x = self.qc3(self.fc3(x),training=False)\n",
    "            # \n",
    "            \n",
    "            # x = binarize(x-0.0001)\n",
    "            # x = (x+1)/2\n",
    "            # \n",
    "            x = self.qc1(self.qc1a(self.fc1(x),training=False),training=False)                \n",
    "            x = self.qc2(self.qc2a(self.fc2(x),training=False),training=False)            \n",
    "            x = self.qc3(self.qc3a(self.fc3(x),training=False),training=False)\n",
    "            # \n",
    "            # \n",
    "            # x = self.fc1(x)        \n",
    "            # x = self.fc2(x)                           \n",
    "            # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    epoch_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target,new_target = modify_target(target)\n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        # \n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data,True)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()    \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "                \n",
    "        if batch_idx % 100 == 0:        \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}/{} ({:.2f}%)'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss, correct, (batch_idx+1) * len(data),\n",
    "                100. * float(correct) / float(((batch_idx+1) * len(data)) )))                \n",
    "    print(\"-\"*20,\"training done, loss\",\"-\"*20)\n",
    "    print(\"Training Set: Average loss: {}\".format(round(sum(epoch_loss)/len(epoch_loss),6)))\n",
    "    \n",
    "accur=[]\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        target,new_target = modify_target(target)\n",
    "        \n",
    "        # \n",
    "        # data = (data-data.min())/(data.max()-data.min())\n",
    "        # data = (binarize(data-0.5)+1)/2\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # print(\"Debug\")\n",
    "        # output = model(data,2)\n",
    "        # \n",
    "        # sys.exit(0)\n",
    "        # data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data,False)\n",
    "        test_loss += criterion(output, target) # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    a=100.*correct / len(test_loader.dataset)\n",
    "    accur.append(a)  \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * float(correct) / float(len(test_loader.dataset))))\n",
    "    \n",
    "    return float(correct) / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Training\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "print(\"=\"*10,\"Model Info\",\"=\"*10)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "# optimizer = torch.optim.SGD([\n",
    "#                 {'params': model.fc1.parameters()},\n",
    "#                 {'params': model.fc2.parameters()},\n",
    "#                 {'params': model.fc3.parameters()},\n",
    "#                 {'params': model.qc1.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc2.parameters(), 'lr': 1},\n",
    "#                 {'params': model.qc3.parameters(), 'lr': 1},\n",
    "#             ], lr=0.1, momentum=0.9)\n",
    "# \n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \\\n",
    "#         base_lr=[1e-1,1e-1,1e-1,1,1,1], \\\n",
    "#         max_lr=[1e-3,1e-3,1e-3,1e-2,1e-2,1e-2], \\\n",
    "#         step_size_up=100\n",
    "#         )\n",
    "\n",
    "milestones = [3, 5, 8]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)\n",
    "\n",
    "# \n",
    "# \n",
    "# test()\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==================== 0 epoch ====================\n",
      "Epoch Start at: 04/22/2020 01:17:24\n",
      "-------------------- learning rates --------------------\n",
      "0.01,\n",
      "-------------------- training --------------------\n",
      "Trainign Start at: 04/22/2020 01:17:24\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.302133\tAccuracy: 5/32 (15.62%)\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 2.152087\tAccuracy: 915/3232 (28.31%)\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.167706\tAccuracy: 1678/6432 (26.09%)\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 2.175803\tAccuracy: 2520/9632 (26.16%)\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.186147\tAccuracy: 3278/12832 (25.55%)\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 2.207140\tAccuracy: 4008/16032 (25.00%)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if os.path.isfile(resume_path):\n",
    "    print(\"=> loading checkpoint from '{}'<=\".format(resume_path))\n",
    "    checkpoint = torch.load(resume_path, map_location=device)\n",
    "    epoch_init,acc = checkpoint[\"epoch\"],checkpoint[\"acc\"]\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])    \n",
    "    scheduler.milestones = Counter(milestones)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "else:\n",
    "    epoch_init,acc = 0,0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if training:\n",
    "    for epoch in range(epoch_init, max_epoch + 1):\n",
    "        print(\"=\"*20,epoch,\"epoch\",\"=\"*20)  \n",
    "        print(\"Epoch Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "\n",
    "        print(\"-\"*20,\"learning rates\",\"-\"*20)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'],end=\",\")\n",
    "        print()    \n",
    "        \n",
    "        print(\"-\"*20,\"training\",\"-\"*20)\n",
    "        print(\"Trainign Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        train(epoch)\n",
    "        print(\"Trainign End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"-\"*20,\"testing\",\"-\"*20)\n",
    "        print(\"Testing Start at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))        \n",
    "        cur_acc = test()\n",
    "        print(\"Testing End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"-\"*60)\n",
    "        print()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        is_best = False\n",
    "        if cur_acc > acc:\n",
    "            is_best = True\n",
    "            acc=cur_acc\n",
    "        \n",
    "        print(\"Best accuracy: {}; Current accuracy {}. Checkpointing\".format(acc,cur_acc))\n",
    "        save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'acc': acc, \n",
    "          'state_dict': model.state_dict(),      \n",
    "          'optimizer' : optimizer.state_dict(),\n",
    "           'scheduler': scheduler.state_dict(),\n",
    "        }, is_best, save_path, 'checkpoint_{}_{}.pth.tar'.format(epoch,round(cur_acc,4)))\n",
    "        print(\"Epoch End at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "        print(\"=\"*60)\n",
    "        print()        \n",
    "else:    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, \n",
    "        num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "    test()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}