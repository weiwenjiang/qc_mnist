{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "====================================================================================================\n",
      "Demo 3 on MNIST. This script is for batch of data generation.\n",
      "\tStart at: 09/04/2020 01:07:42\n",
      "\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\n",
      "\tEnjoy and Good Luck!\n",
      "====================================================================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"../Revision_Exp2-QF-FB\")\n",
    "from pathlib import Path\n",
    "import functools\n",
    "print = functools.partial(print, flush=True)\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "from qiskit_library import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "import qiskit as qk\n",
    "from qiskit import Aer\n",
    "from qiskit import execute\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from qiskit import IBMQ\n",
    "# IBMQ.delete_accounts()\n",
    "# IBMQ.save_account('62d0e14364f490e45b5b5e0f6eebdbc083270ffffb660c7054219b15c7ce99ab4aa3b321309c0a9d0c3fc20086baece1376297dcdb67c7b715f9de1e4fa79efb')\n",
    "# IBMQ.load_account()\n",
    "\n",
    "\n",
    "\n",
    "interest_num = [3,6]\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 2\n",
    "inference_batch_size = 1\n",
    "\n",
    "\n",
    "img_size = 16\n",
    "layers = [8, 5]\n",
    "resume_path=\"qfnet_p_best_models/mnist_01369_star_0.940916*16\"\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Demo 3 on MNIST. This script is for batch of data generation.\")\n",
    "print(\"\\tStart at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "print(\"\\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\")\n",
    "print(\"\\tEnjoy and Good Luck!\")\n",
    "print(\"=\"*100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=> loading checkpoint from 'qfnet_p_best_models/mnist_01369_star_0.9409'<=\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 104
    }
   ],
   "source": [
    "from lib_qc import * \n",
    "from lib_util import *\n",
    "from lib_net import *\n",
    "\n",
    "# Network Architecture: 2 layers and each layer contains 2 neurons\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = Net(img_size,layers,True,[[1,1,1,1],[1,1]],True,False,False,False,True).to(device)\n",
    "\n",
    "\n",
    "print(\"=> loading checkpoint from '{}'<=\".format(resume_path))\n",
    "checkpoint = torch.load(resume_path, map_location=device)\n",
    "epoch_init, acc = checkpoint[\"epoch\"], checkpoint[\"acc\"]\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "# for name, para in model.named_parameters():\n",
    "#     if \"fc\" in name:\n",
    "#         print(name,binarize(para))\n",
    "#     else:\n",
    "#         print(name, para)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualization of Model\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "51\n",
      "59\n",
      "47\n",
      "47\n",
      "47\n",
      "FFNN: 5030\n",
      "QF-Net+: 135\n",
      "Second layer cost 251\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.extensions import XGate, UnitaryGate\n",
    "import qiskit\n",
    "from math import sqrt \n",
    "import math\n",
    "import copy\n",
    "\n",
    "def get_index_list(input,target):\n",
    "    index_list = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = input.index(target,beg_pos)\n",
    "            index_list.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    return index_list\n",
    "\n",
    "def change_sign(sign,bin):\n",
    "    affect_num = [bin]\n",
    "    one_positions = []\n",
    "    \n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = bin.index(\"1\",beg_pos)\n",
    "            one_positions.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:\n",
    "        # print(\"Not Found\")\n",
    "        pass\n",
    "    \n",
    "    for k,v in sign.items():\n",
    "        change = True\n",
    "        for pos in one_positions:\n",
    "            if k[pos]==\"0\":                \n",
    "                change = False\n",
    "                break\n",
    "        if change:\n",
    "            sign[k] = -1*v\n",
    "    \n",
    "\n",
    "def find_start(affect_count_table,target_num):\n",
    "    for k in list(affect_count_table.keys())[::-1]:\n",
    "        if target_num<=k:\n",
    "            return k\n",
    "\n",
    "\n",
    "def recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates):\n",
    "    \n",
    "    if start_point == target_num:\n",
    "        # print(\"recursive_change: STOP\")\n",
    "        return\n",
    "    \n",
    "    gap = int(math.fabs(start_point-target_num))    \n",
    "    step = find_start(affect_count_table,gap)\n",
    "    change_sign(sign,affect_count_table[step])\n",
    "    quantum_gates.append(affect_count_table[step])\n",
    "    \n",
    "    if direction==\"r\": \n",
    "        # print(\"recursive_change: From\",start_point,\"Right(-):\",step)\n",
    "        start_point = start_point - step\n",
    "        direction = \"l\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    else:        \n",
    "        # print(\"recursive_change: From\",start_point,\"Left(+):\",step)\n",
    "        start_point = start_point + step\n",
    "        direction = \"r\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    \n",
    "\n",
    "def guarntee_upper_bound_algorithm(sign,target_num,total_len,digits):        \n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    pre_num = 0\n",
    "    affect_count_table = {}\n",
    "    quantum_gates = []\n",
    "    for i in range(digits):\n",
    "        cur_num = pre_num + pow(2,i)\n",
    "        pre_num = cur_num\n",
    "        binstr_cur_num = format(cur_num,flag) \n",
    "        affect_count_table[int(pow(2,binstr_cur_num.count(\"0\")))] = binstr_cur_num   \n",
    "        \n",
    "    if target_num in affect_count_table.keys():\n",
    "        quantum_gates.append(affect_count_table[target_num])\n",
    "        change_sign(sign,affect_count_table[target_num])    \n",
    "    else:\n",
    "        direction = \"r\"\n",
    "        start_point = find_start(affect_count_table,target_num)\n",
    "        quantum_gates.append(affect_count_table[start_point])\n",
    "        change_sign(sign,affect_count_table[start_point])\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "    \n",
    "    return quantum_gates\n",
    "\n",
    "def qf_map_extract_from_weight(weights):    \n",
    "    # Find Z control gates according to weights\n",
    "    w = (weights.detach().cpu().numpy())\n",
    "    total_len = len(w)\n",
    "    target_num = np.count_nonzero(w == -1)\n",
    "    if target_num > total_len/2:\n",
    "        w = w*-1\n",
    "    target_num = np.count_nonzero(w == -1)    \n",
    "    digits = int(math.log(total_len,2))\n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    max_num = int(math.pow(2,digits))\n",
    "    sign = {}\n",
    "    for i in range(max_num):        \n",
    "        sign[format(i,flag)] = +1\n",
    "    quantum_gates = guarntee_upper_bound_algorithm(sign,target_num,total_len,digits)\n",
    "    \n",
    "    # for k,v in sign.items():\n",
    "    #     print(k,v)\n",
    "    # print(w)\n",
    "        \n",
    "    # Build the mapping from weight to final negative num \n",
    "    fin_sign = list(sign.values())\n",
    "    fin_weig = [int(x) for x in list(w)]\n",
    "    \n",
    "    # print(fin_sign)\n",
    "    # print(fin_weig)\n",
    "    sign_neg_index = []    \n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_sign.index(-1,beg_pos)            \n",
    "            # qiskit_position = int(format(find_pos,flag)[::-1],2)                            \n",
    "            sign_neg_index.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    \n",
    "\n",
    "    weight_neg_index = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_weig.index(-1,beg_pos)\n",
    "            weight_neg_index.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    map = {}\n",
    "    for i in range(len(sign_neg_index)):\n",
    "        map[sign_neg_index[i]] = weight_neg_index[i]\n",
    "            \n",
    "    # print(fin_sign)\n",
    "    # print(fin_weig)\n",
    "    # print(map)\n",
    "    \n",
    "    ret_index = list([-1 for i in range(len(fin_weig))])\n",
    "    \n",
    "    \n",
    "    for k,v in map.items():\n",
    "        ret_index[k]=v\n",
    "    \n",
    "    \n",
    "    for i in range(len(fin_weig)):\n",
    "        if ret_index[i]!=-1:\n",
    "            continue\n",
    "        for j in range(len(fin_weig)):\n",
    "            if j not in ret_index:\n",
    "                ret_index[i]=j\n",
    "                break\n",
    "    # print(ret_index)\n",
    "    # sys.exit(0)     \n",
    "    # for k,v in map.items():\n",
    "    #     tmp1 = ret_index[k]\n",
    "    #     tmp2 = ret_index[v]\n",
    "    #     ret_index[k] = tmp2\n",
    "    #     ret_index[v] = tmp1\n",
    "    # \n",
    "\n",
    "    return quantum_gates,ret_index\n",
    "    \n",
    "    \n",
    "def extract_model(model):\n",
    "    layer_prop = {}\n",
    "    batch_adj_prop = {}\n",
    "    indiv_adj_prop = {}\n",
    "    for name, para in model.named_parameters():\n",
    "        if \"fc\" in name:\n",
    "            layer_id = int(name.split(\".\")[0].split(\"c\")[1])\n",
    "            layer_prop[layer_id] = [para.shape[1],para.shape[0],binarize(para)]            \n",
    "        elif \"qca\" in name:            \n",
    "            if \"l_0_5\" in name or \"running_rot\" in name:\n",
    "                layer_id = int(name.split(\".\")[0].split(\"a\")[1])\n",
    "                layer_fun = name.split(\".\")[1]\n",
    "                if layer_id not in batch_adj_prop.keys():\n",
    "                    batch_adj_prop[layer_id] = {}\n",
    "                batch_adj_prop[layer_id][layer_fun] = para\n",
    "        else:            \n",
    "            print(name, para)\n",
    "    \n",
    "    # print(layer_prop)\n",
    "    # print(batch_adj_prop)\n",
    "\n",
    "    # First layer\n",
    "    first_layer_num = layer_prop[0][1]\n",
    "    \n",
    "    first_layer_input_q = int(math.log(layer_prop[0][0],2))\n",
    "    first_layer_addition_q = max(first_layer_input_q-2,0)        \n",
    "    first_layer_batch_q = 0    \n",
    "    if 0 in batch_adj_prop.keys():\n",
    "        first_layer_batch_q = 2\n",
    "    \n",
    "    first_layer_q = first_layer_num*(first_layer_input_q+first_layer_batch_q)\n",
    "    \n",
    "    # print(first_layer_q)\n",
    "    \n",
    "    # Second layer    \n",
    "    second_layer_num = layer_prop[1][1]\n",
    "    if layer_prop[1][0]==0:\n",
    "        second_layer_input_q=int(math.log(layer_prop[1][0],2))\n",
    "        second_layer_encode_q = 0\n",
    "        second_layer_output_q = 0\n",
    "    else:\n",
    "        second_layer_input_q = layer_prop[1][0]\n",
    "        second_layer_encode_q = int(math.log(second_layer_input_q,2))    \n",
    "        second_layer_output_q = int(math.log(second_layer_encode_q,2))\n",
    "    \n",
    "    second_layer_addition_q = max(first_layer_input_q-2,0)        \n",
    "    \n",
    "    second_layer_batch_q = 0\n",
    "    if 1 in batch_adj_prop.keys():\n",
    "        second_layer_batch_q = 2\n",
    "\n",
    "    second_layer_q = second_layer_num*(second_layer_input_q+second_layer_output_q+second_layer_batch_q)\n",
    "    # print(second_layer_q)\n",
    "    sec_list = [second_layer_input_q, second_layer_num*second_layer_output_q,\n",
    "                second_layer_num*second_layer_encode_q, second_layer_num*second_layer_batch_q]\n",
    "    return first_layer_q,sec_list,first_layer_input_q,layer_prop,batch_adj_prop,max(first_layer_addition_q,second_layer_addition_q)\n",
    "    \n",
    "# Main part\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def q_map_neural_compute_body(circ,inputs,iq,inference_batch_size,log_batch_size,weights):\n",
    "    \n",
    "    quantum_gates,ret_index = qf_map_extract_from_weight(weights)\n",
    "    # print(ret_index)\n",
    "    # print(quantum_gates)\n",
    "    # \n",
    "    expand_for_batch_index = copy.deepcopy(ret_index)\n",
    "    for b in range(inference_batch_size-1):\n",
    "        start = len(ret_index)*(b+1)\n",
    "        new_batch_index = [x+start for x in ret_index]\n",
    "        expand_for_batch_index += new_batch_index\n",
    "    index = torch.LongTensor(expand_for_batch_index)    \n",
    "    Input0 = copy.deepcopy(Q_InputMatrix)\n",
    "    Input0 = Input0[index]\n",
    "    # print(\"for debug comparison\")\n",
    "    # print(Q_InputMatrix[:,0])\n",
    "    # print(index)\n",
    "    \n",
    "    \n",
    "    # print(Input0[:,0])\n",
    "    circ.append(UnitaryGate(Input0, label=\"Input0\"), inputs[0:iq])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(circ)\n",
    "    # backend = Aer.get_backend('unitary_simulator')\n",
    "    # job = execute(circ, backend)\n",
    "    # result = job.result()\n",
    "    # torch.set_printoptions(threshold=sys.maxsize)\n",
    "    # np.set_printoptions(threshold=sys.maxsize)\n",
    "    # state = result.get_unitary(circ, decimals=4)\n",
    "    # print(state[:,0])\n",
    "    # \n",
    "    \n",
    "    qbits = inputs[0:iq-log_batch_size]\n",
    "    for gate in quantum_gates:\n",
    "        z_count = gate.count(\"1\")\n",
    "        # z_pos = get_index_list(gate,\"1\")\n",
    "        z_pos = get_index_list(gate[::-1],\"1\")\n",
    "        # print(z_pos)\n",
    "        if z_count==1:\n",
    "            circ.z(qbits[z_pos[0]])\n",
    "        elif z_count==2:\n",
    "            circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "        elif z_count==3:\n",
    "            qiskit_library.ccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux_qr[0])\n",
    "        elif z_count==4:\n",
    "            qiskit_library.cccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux_qr[0],aux_qr[1])\n",
    "    \n",
    "    # \n",
    "    # \n",
    "    # print(circ)\n",
    "    # backend = Aer.get_backend('unitary_simulator')\n",
    "    # job = execute(circ, backend)\n",
    "    # result = job.result()\n",
    "    # \n",
    "    # torch.set_printoptions(threshold=sys.maxsize)\n",
    "    # np.set_printoptions(threshold=sys.maxsize)\n",
    "    # state = result.get_unitary(circ, decimals=4)\n",
    "    # print(state[:,0])\n",
    "    # sys.exit(0)\n",
    "\n",
    "\n",
    "def q_map_neural_compute_extract(circ,inputs,iq,outputs,log_batch_size):        \n",
    "    qbits = inputs[0:iq-log_batch_size]\n",
    "    # qbits = inputs[log_batch_size:iq]\n",
    "    for q in qbits:\n",
    "        circ.h(q)\n",
    "    \n",
    "    circ.barrier()\n",
    "    \n",
    "    for q in qbits:\n",
    "        circ.x(q)\n",
    "    \n",
    "    \n",
    "    digits = log_batch_size\n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    # qbits = inputs[0:log_batch_size]\n",
    "    qbits = inputs[iq-log_batch_size:iq]\n",
    "    if log_batch_size!=0:\n",
    "        for i in range(int(math.pow(2,log_batch_size))):        \n",
    "            binstr_cur_num = format(i,flag)[::-1]\n",
    "            \n",
    "            for pos in range(len(binstr_cur_num)):            \n",
    "                if binstr_cur_num[pos]==\"0\":                \n",
    "                    circ.x(qbits[pos])\n",
    "                    \n",
    "            if digits==1:                            \n",
    "                qiskit_library.cccccx(circ, inputs[0:iq], outputs[i],aux_qr)            \n",
    "            elif digits==2:\n",
    "                qiskit_library.ccccccx(circ, inputs[0:iq], outputs[i],aux_qr)\n",
    "            elif digits==3:\n",
    "                qiskit_library.cccccccx(circ, inputs[0:iq], outputs[i],aux_qr)\n",
    "            \n",
    "            \n",
    "            for pos in range(len(binstr_cur_num)):                \n",
    "                if binstr_cur_num[pos]==\"0\":                \n",
    "                    circ.x(qbits[pos])\n",
    "            circ.barrier()\n",
    "            \n",
    "    else:\n",
    "        qiskit_library.ccccx(circ, inputs[0], inputs[1], inputs[2], inputs[3], outputs[0], aux_qr[0], aux_qr[1])\n",
    "    \n",
    "    circ.barrier()\n",
    "    qbits = inputs[log_batch_size:iq]\n",
    "    for q in qbits:    \n",
    "        circ.x(q)\n",
    "    \n",
    "\n",
    "def q_map_q_ori_net(circ, s_qr_in, s_qr_enc, aux_qr, weights):\n",
    "    if len(weights)==4:\n",
    "        for i in range(len(weights)):\n",
    "            if weights[i]==-1:\n",
    "                circ.x(s_qr_in[i])\n",
    "        for i in range(2):\n",
    "            circ.h(s_qr_enc[i])\n",
    "        circ.barrier()\n",
    "        circ.x(s_qr_enc[0])\n",
    "        circ.x(s_qr_enc[1])\n",
    "        ccz(circ,s_qr_in[3],s_qr_enc[0],s_qr_enc[1],aux_qr[0])\n",
    "        circ.x(s_qr_enc[0])\n",
    "        circ.x(s_qr_enc[1])\n",
    "                \n",
    "        circ.x(s_qr_enc[1])\n",
    "        ccz(circ,s_qr_in[2],s_qr_enc[0],s_qr_enc[1],aux_qr[0])\n",
    "        circ.x(s_qr_enc[1])\n",
    "        \n",
    "        circ.x(s_qr_enc[0])\n",
    "        ccz(circ,s_qr_in[1],s_qr_enc[0],s_qr_enc[1],aux_qr[0])\n",
    "        circ.x(s_qr_enc[0])\n",
    "        \n",
    "        \n",
    "        ccz(circ,s_qr_in[0],s_qr_enc[0],s_qr_enc[1],aux_qr[0])\n",
    "        \n",
    "        circ.barrier()\n",
    "        for i in range(len(weights)):\n",
    "            if weights[i]==-1:\n",
    "                circ.x(s_qr_in[i])\n",
    "                \n",
    "    elif len(weights)==8:\n",
    "        print(\"Size\", len(weights),\"in 2nd layer is now not supportted\")\n",
    "        sys.exit(0)\n",
    "    else:\n",
    "        print(\"Size\", len(weights),\"in 2nd layer is now not supportted\")\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "def q_map_bn(circ, s_qr_enc, s_qr_bat, output, aux_qr, enc_len, type, val):\n",
    "    if enc_len!=2:\n",
    "        print(\"Encoder size of \", enc_len,\"is now not supportted\")\n",
    "        sys.exit(0)\n",
    "    else:        \n",
    "        for i in range(enc_len):\n",
    "            circ.h(s_qr_enc[i])\n",
    "            circ.x(s_qr_enc[i])\n",
    "        circ.barrier()\n",
    "        circ.ccx(s_qr_enc[0],s_qr_enc[1],s_qr_bat[0])        \n",
    "        qc_ang = 2*torch.tensor(math.sqrt(val)).asin().item()        \n",
    "        circ.ry(qc_ang,s_qr_bat[1])\n",
    "        if type==1:\n",
    "            circ.ccx(s_qr_bat[0],s_qr_bat[1],output)\n",
    "            \n",
    "\n",
    "def AinB(A,B):\n",
    "    idx_a = []\n",
    "    for i in range(len(A)):\n",
    "        if A[i]==\"1\":\n",
    "            idx_a.append(i)    \n",
    "    flag = True\n",
    "    for j in idx_a:\n",
    "        if B[j]==\"0\":\n",
    "            flag=False\n",
    "            break\n",
    "    return flag\n",
    "            \n",
    "        \n",
    "def FFNN_Create_Weight(weights):        \n",
    "    # Find Z control gates according to weights\n",
    "    w = (weights.detach().cpu().numpy())\n",
    "    total_len = len(w)            \n",
    "    digits = int(math.log(total_len,2))\n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    max_num = int(math.pow(2,digits))\n",
    "    sign = {}\n",
    "    for i in range(max_num):        \n",
    "        sign[format(i,flag)] = +1    \n",
    "    sign_expect = {}\n",
    "    for i in range(max_num):\n",
    "        sign_expect[format(i,flag)] = int(w[i])    \n",
    "    \n",
    "    order_list = []\n",
    "    for i in range(digits+1):\n",
    "        for key in sign.keys():\n",
    "            if key.count(\"1\") == i:\n",
    "                order_list.append(key)    \n",
    "    \n",
    "    gates = []    \n",
    "    sign_cur = copy.deepcopy(sign_expect)\n",
    "    for idx in range(len(order_list)):\n",
    "        key = order_list[idx]\n",
    "        if sign_cur[key] == -1:\n",
    "            gates.append(key)\n",
    "            for cor_idx in range(idx,len((order_list))):\n",
    "                if AinB(key,order_list[cor_idx]):\n",
    "                    sign_cur[order_list[cor_idx]] = (-1)*sign_cur[order_list[cor_idx]]    \n",
    "    return gates\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def gates_to_cost(gates):\n",
    "    cost = 0\n",
    "    for gate in gates:\n",
    "        num_one = gate.count(\"1\")\n",
    "        if num_one==1:\n",
    "            cost += 1\n",
    "        else:\n",
    "            cost += (num_one-1)*2-1\n",
    "    return cost\n",
    "        \n",
    "\n",
    "def prob_extract_weights(weights):\n",
    "    in_size = len(weights)\n",
    "    out_qbit = int(math.log2(in_size))\n",
    "    gates = []\n",
    "    control_gates=\"1\"\n",
    "    \n",
    "    # Encoding inputs\n",
    "    for i in range(out_qbit):\n",
    "        control_gates+=\"1\"\n",
    "    for i in range(in_size):\n",
    "        gates.append(control_gates)\n",
    "    \n",
    "    # Encoding and Deconding weights\n",
    "    for w in weights:\n",
    "        if w==-1:\n",
    "            gates.append(\"1\")\n",
    "            gates.append(\"1\")\n",
    "    \n",
    "    # # H gates\n",
    "    # for i in range(out_qbit):\n",
    "    #     gates.append(\"1\")\n",
    "    # \n",
    "    gates.append(control_gates)\n",
    "    \n",
    "    return gates\n",
    "\n",
    "import qiskit_library\n",
    "f,sec_list,iq,nn_prop,bn_prop,aux = extract_model(model)\n",
    "qf_net_cost = 0\n",
    "ffnn_cost = 0\n",
    "\n",
    "sec_layer_cost = 0\n",
    "\n",
    "# print(nn_prop)\n",
    "for weights in nn_prop[0][2]:        \n",
    "    quantum_gates,ret_index = qf_map_extract_from_weight(weights)    \n",
    "    qf_net_cost += gates_to_cost(quantum_gates)\n",
    "    gates = FFNN_Create_Weight(weights)\n",
    "    ffnn_cost += gates_to_cost(gates)\n",
    "    \n",
    "for weights in nn_prop[1][2]:\n",
    "    gates = prob_extract_weights(weights)\n",
    "    print(gates_to_cost(gates))\n",
    "    sec_layer_cost += gates_to_cost(gates)\n",
    "    \n",
    "print(\"FFNN:\", ffnn_cost)\n",
    "print(\"QF-Net+:\",qf_net_cost)\n",
    "print(\"Second layer cost\",sec_layer_cost)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% QF-Map\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "15\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(int(math.log(img_size*img_size,2))*2-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ],
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error"
    },
    {
     "name": "stderr",
     "text": [
      "/home/weiwen/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "sys.exit(0)\n",
    "\n",
    "QF_Cost={}\n",
    "FFNN_Cost={}\n",
    "MLP_Cost={}\n",
    "\n",
    "qf_net_cost = 0\n",
    "ffnn_cost = 0\n",
    "for e in range(4,12):\n",
    "    QF_Cost[e]=[]\n",
    "    FFNN_Cost[e]=[]\n",
    "    MLP_Cost[e]=[]\n",
    "    for r in range(50):\n",
    "        MLP_Cost[e].append(2**e*2+e)\n",
    "        \n",
    "        x=torch.rand(2**e)-0.5       \n",
    "        x = binarize(x)\n",
    "        \n",
    "        sq_cost = e+e*2-1\n",
    "        \n",
    "        quantum_gates,ret_index = qf_map_extract_from_weight(x)\n",
    "        qf_net_cost = gates_to_cost(quantum_gates)+sq_cost\n",
    "        \n",
    "        gates = FFNN_Create_Weight(x)\n",
    "        ffnn_cost = gates_to_cost(gates)+sq_cost\n",
    "        \n",
    "        QF_Cost[e].append(qf_net_cost)\n",
    "        FFNN_Cost[e].append(ffnn_cost)\n",
    "        \n",
    "        print(e,2**e*2+e,qf_net_cost,ffnn_cost)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for e in range(4,12):\n",
    "    for i in range(50):    \n",
    "        print(e,end=\" \")\n",
    "\n",
    "print()\n",
    "for e in range(4,12):    \n",
    "    for k in MLP_Cost[e]:\n",
    "        print(k,end=\" \")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "for e in range(4,12):\n",
    "    for i in range(50):    \n",
    "        print(e,end=\" \")\n",
    "print()\n",
    "for e in range(4,12):    \n",
    "    for k in FFNN_Cost[e]:\n",
    "        print(k,end=\" \")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "for e in range(4,12):\n",
    "    for i in range(50):    \n",
    "        print(e,end=\" \")\n",
    "print()\n",
    "for e in range(4,12):    \n",
    "    for k in QF_Cost[e]:\n",
    "        print(k,end=\" \")\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for e in range(4,12):        \n",
    "    print(e,end=\" \")\n",
    "\n",
    "print()\n",
    "for e in range(4,12):    \n",
    "    print(float(sum(MLP_Cost[e])/len(MLP_Cost[e])),end=\" \")\n",
    "        \n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "for e in range(4,12):    \n",
    "    print(e,end=\" \")\n",
    "print()\n",
    "for e in range(4,12):    \n",
    "    print(float(sum(FFNN_Cost[e])/len(FFNN_Cost[e])),end=\" \")\n",
    "    \n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "for e in range(4,12):    \n",
    "    print(e,end=\" \")\n",
    "print()\n",
    "for e in range(4,12):    \n",
    "    print(float(sum(QF_Cost[e])/len(QF_Cost[e])),end=\" \")\n",
    "        \n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}