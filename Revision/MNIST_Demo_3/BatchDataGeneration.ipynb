{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "====================================================================================================\n",
      "Demo 3 on MNIST. This script is for batch of data generation.\n",
      "\tStart at: 08/07/2020 17:42:08\n",
      "\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\n",
      "\tEnjoy and Good Luck!\n",
      "====================================================================================================\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import functools\n",
    "print = functools.partial(print, flush=True)\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "interest_num = [3,6]\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 2\n",
    "inference_batch_size = 1\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Demo 3 on MNIST. This script is for batch of data generation.\")\n",
    "print(\"\\tStart at:\",time.strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "print(\"\\tProblems and issues, please contact Dr. Weiwen Jiang (wjiang2@nd.edu)\")\n",
    "print(\"\\tEnjoy and Good Luck!\")\n",
    "print(\"=\"*100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "outputs": [],
   "source": [
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    \n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "        \n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "        \n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    \n",
    "    # print(dataset.targets.shape)\n",
    "    \n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    # print(dataset.targets.shape)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def qc_input_trans(dataset):\n",
    "    dataset.data = dataset.data\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class ToQuantumData(object):\n",
    "    def __call__(self, tensor):        \n",
    "        data = tensor                \n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len,vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = input_matrix.transpose(0,1)        \n",
    "        u,s,v = np.linalg.svd(input_matrix)    \n",
    "        output_matrix = torch.tensor(np.dot(u,v))            \n",
    "        output_data = output_matrix[:,0].view(1,img_size,img_size)    \n",
    "        return output_data\n",
    "    \n",
    "\n",
    "class ToQuantumMatrix(object):\n",
    "    def __call__(self, tensor):        \n",
    "        data = tensor                \n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len,vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))        \n",
    "        u,s,v = np.linalg.svd(input_matrix)    \n",
    "        output_matrix = torch.tensor(np.dot(u,v))                        \n",
    "        return output_matrix\n",
    "\n",
    "\n",
    "class ToQuantumData_Batch(object):\n",
    "    def __call__(self, tensor):\n",
    "        data = tensor\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len,vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = input_matrix.transpose(0,1)\n",
    "        u,s,v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u,v))\n",
    "        output_data = output_matrix[:,0].view(data.shape)\n",
    "        return output_data\n",
    "\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                transforms.ToTensor()])\n",
    "# transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "#                                 transforms.ToTensor(),ToQuantumData()])\n",
    "# transform = transforms.Compose([transforms.Resize((img_size,img_size)),transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# choose the training and test datasets\n",
    "\n",
    "# Path to MNIST Dataset\n",
    "train_data = datasets.MNIST(root='../../pytorch/data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='../../pytorch/data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "# train_data = qc_input_trans(train_data)\n",
    "\n",
    "# imshow(torchvision.utils.make_grid(train_data[0][0]))\n",
    "# \n",
    "# sys.exit(0)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "\n",
    "def save_checkpoint(state, is_best, save_path, filename):\n",
    "    filename = os.path.join(save_path, filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        bestname = os.path.join(save_path, 'model_best.tar')\n",
    "        shutil.copyfile(filename, bestname)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([1, 1, 4, 4])\n",
      "tensor([[[[0.0275, 0.1373, 0.0000, 0.0000],\n",
      "          [0.0706, 0.1882, 0.1804, 0.0667],\n",
      "          [0.0353, 0.3412, 0.2902, 0.1373],\n",
      "          [0.0000, 0.0706, 0.0863, 0.0078]]]]) tensor([1])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# functions to show an image\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    plt.show()\n",
    "    \n",
    "    image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    \n",
    "    im = Image.fromarray(image,mode=\"L\")\n",
    "    im.save(\"32*32.jpg\",cmap=\"gray\") \n",
    "    im = im.resize((4,4),Image.BILINEAR)    \n",
    "    \n",
    "    plt.imshow(im,cmap='gray',)\n",
    "    \n",
    "    trans_to_tensor = transforms.ToTensor()\n",
    "    trans_to_matrix = ToQuantumMatrix()\n",
    "    plt.show()\n",
    "    im.save(\"4*4.jpg\",cmap=\"gray\") \n",
    "    \n",
    "    # print(trans_to_tensor(im))\n",
    "    for row in trans_to_matrix(trans_to_tensor(im)).tolist():\n",
    "        for num in row:\n",
    "            print(num,end=\",\")\n",
    "        print()\n",
    "\n",
    "    \n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    # imshow(torchvision.utils.make_grid(data))\n",
    "    print(data.shape)\n",
    "    print(data,target)\n",
    "    inputs = data.flatten()\n",
    "    \n",
    "    \n",
    "    trans_to_tensor = transforms.ToTensor()\n",
    "    trans_to_matrix = ToQuantumMatrix()\n",
    "    \n",
    "    \n",
    "    # for row in trans_to_matrix((inputs)).tolist():\n",
    "    #     for num in row:\n",
    "    #         print(num,end=\",\")\n",
    "    #     print()\n",
    "    # \n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# functions to show an image\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    plt.show()\n",
    "    \n",
    "    # image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    # \n",
    "    # im = Image.fromarray(image,mode=\"L\")\n",
    "    # im.save(\"32*32.jpg\",cmap=\"gray\") \n",
    "    # im = im.resize((4,4),Image.BILINEAR)    \n",
    "    # \n",
    "    # plt.imshow(im,cmap='gray',)\n",
    "    # \n",
    "    # trans_to_tensor = transforms.ToTensor()\n",
    "    # trans_to_matrix = ToQuantumMatrix()\n",
    "    # plt.show()\n",
    "    # im.save(\"4*4.jpg\",cmap=\"gray\") \n",
    "    \n",
    "    # print(trans_to_tensor(im))\n",
    "    # for row in trans_to_matrix(trans_to_tensor(im)).tolist():\n",
    "    #     for num in row:\n",
    "    #         print(num,end=\",\")\n",
    "    #     print()\n",
    "\n",
    "#     \n",
    "# for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#     torch.set_printoptions(threshold=sys.maxsize)\n",
    "#     imshow(torchvision.utils.make_grid(data))\n",
    "#     break\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=> loading checkpoint from 'checkpoint_0_0.6997.pth.tar'<=\n",
      "fc0.weight tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
      "         -1., -1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "          1.,  1.]], grad_fn=<BinarizeFBackward>)\n",
      "fc1.weight tensor([[ 1., -1.],\n",
      "        [ 1.,  1.]], grad_fn=<BinarizeFBackward>)\n",
      "qca1.x_running_rot Parameter containing:\n",
      "tensor([0.4383, 0.5617])\n",
      "qca1.x_l_0_5 Parameter containing:\n",
      "tensor([1., 0.])\n",
      "qca1.x_g_0_5 Parameter containing:\n",
      "tensor([0., 1.])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from lib_qc import * \n",
    "from lib_util import *\n",
    "from lib_net import *\n",
    "\n",
    "# Network Architecture: 2 layers and each layer contains 2 neurons\n",
    "\n",
    "img_size = 4\n",
    "device = torch.device(\"cpu\")\n",
    "layers = [2, 2]\n",
    "\n",
    "model = Net(img_size,layers,True,[[1,1,1,1],[1,1]],True,False,False,False,True).to(device)\n",
    "\n",
    "resume_path=\"checkpoint_0_0.6997.pth.tar\"\n",
    "print(\"=> loading checkpoint from '{}'<=\".format(resume_path))\n",
    "checkpoint = torch.load(resume_path, map_location=device)\n",
    "epoch_init, acc = checkpoint[\"epoch\"], checkpoint[\"acc\"]\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "for name, para in model.named_parameters():\n",
    "    if \"fc\" in name:\n",
    "        print(name,binarize(para))\n",
    "    else:\n",
    "        print(name, para)\n",
    "\n",
    "\n",
    "# for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#     torch.set_printoptions(threshold=sys.maxsize)\n",
    "#     # imshow(torchvision.utils.make_grid(data))\n",
    "#     # print(data)\n",
    "#     \n",
    "#     Q_InputMatrix = ToQuantumMatrix()(data.flatten())\n",
    "#     break\n",
    "# \n",
    "# print(\"=\"*10)\n",
    "# print(Q_InputMatrix.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualization of Model\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([16, 16])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.extensions import XGate, UnitaryGate\n",
    "import qiskit\n",
    "from math import sqrt \n",
    "import math\n",
    "import copy\n",
    "\n",
    "def get_index_list(input,target):\n",
    "    index_list = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = input.index(target,beg_pos)\n",
    "            index_list.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    return index_list\n",
    "\n",
    "def change_sign(sign,bin):\n",
    "    affect_num = [bin]\n",
    "    one_positions = []\n",
    "    \n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = bin.index(\"1\",beg_pos)\n",
    "            one_positions.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:\n",
    "        # print(\"Not Found\")\n",
    "        pass\n",
    "    \n",
    "    for k,v in sign.items():\n",
    "        change = True\n",
    "        for pos in one_positions:\n",
    "            if k[pos]==\"0\":                \n",
    "                change = False\n",
    "                break\n",
    "        if change:\n",
    "            sign[k] = -1*v\n",
    "    \n",
    "\n",
    "def find_start(affect_count_table,target_num):\n",
    "    for k in list(affect_count_table.keys())[::-1]:\n",
    "        if target_num<=k:\n",
    "            return k\n",
    "\n",
    "\n",
    "def recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates):\n",
    "    \n",
    "    if start_point == target_num:\n",
    "        # print(\"recursive_change: STOP\")\n",
    "        return\n",
    "    \n",
    "    gap = int(math.fabs(start_point-target_num))    \n",
    "    step = find_start(affect_count_table,gap)\n",
    "    change_sign(sign,affect_count_table[step])\n",
    "    quantum_gates.append(affect_count_table[step])\n",
    "    \n",
    "    if direction==\"r\": \n",
    "        # print(\"recursive_change: From\",start_point,\"Right(-):\",step)\n",
    "        start_point = start_point - step\n",
    "        direction = \"l\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    else:        \n",
    "        # print(\"recursive_change: From\",start_point,\"Left(+):\",step)\n",
    "        start_point = start_point + step\n",
    "        direction = \"r\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    \n",
    "\n",
    "def guarntee_upper_bound_algorithm(sign,target_num,total_len,digits):        \n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    pre_num = 0\n",
    "    affect_count_table = {}\n",
    "    quantum_gates = []\n",
    "    for i in range(digits):\n",
    "        cur_num = pre_num + pow(2,i)\n",
    "        pre_num = cur_num\n",
    "        binstr_cur_num = format(cur_num,flag) \n",
    "        affect_count_table[int(pow(2,binstr_cur_num.count(\"0\")))] = binstr_cur_num   \n",
    "        \n",
    "    if target_num in affect_count_table.keys():\n",
    "        quantum_gates.append(affect_count_table[target_num])\n",
    "        change_sign(sign,affect_count_table[target_num])    \n",
    "    else:\n",
    "        direction = \"r\"\n",
    "        start_point = find_start(affect_count_table,target_num)\n",
    "        quantum_gates.append(affect_count_table[start_point])\n",
    "        change_sign(sign,affect_count_table[start_point])\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "    \n",
    "    return quantum_gates\n",
    "\n",
    "def qf_map_extract_from_weight(weights):    \n",
    "    # Find Z control gates according to weights\n",
    "    w = (weights.detach().cpu().numpy())\n",
    "    total_len = len(w)\n",
    "    target_num = np.count_nonzero(w == -1)\n",
    "    if target_num > total_len/2:\n",
    "        w = w*-1\n",
    "    target_num = np.count_nonzero(w == -1)    \n",
    "    digits = int(math.log(total_len,2))\n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    max_num = int(math.pow(2,digits))\n",
    "    sign = {}\n",
    "    for i in range(max_num):        \n",
    "        sign[format(i,flag)] = +1\n",
    "    quantum_gates = guarntee_upper_bound_algorithm(sign,target_num,total_len,digits)\n",
    "    \n",
    "    # for k,v in sign.items():\n",
    "    #     print(k,v)\n",
    "    # print(w)\n",
    "        \n",
    "    # Build the mapping from weight to final negative num \n",
    "    fin_sign = list(sign.values())\n",
    "    fin_weig = [int(x) for x in list(w)]\n",
    "    \n",
    "    # print(fin_sign)\n",
    "    # print(fin_weig)\n",
    "    sign_neg_index = []    \n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_sign.index(-1,beg_pos)            \n",
    "            qiskit_position = int(format(find_pos,flag)[::-1],2)                            \n",
    "            sign_neg_index.append(qiskit_position)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    \n",
    "\n",
    "    weight_neg_index = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_weig.index(-1,beg_pos)\n",
    "            weight_neg_index.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    map = {}\n",
    "    for i in range(len(sign_neg_index)):\n",
    "        map[sign_neg_index[i]] = weight_neg_index[i]\n",
    "            \n",
    "    # print(map)\n",
    "    \n",
    "    ret_index = list(range(len(fin_weig)))\n",
    "    \n",
    "    for k,v in map.items():\n",
    "        old_val = ret_index[k] \n",
    "        ret_index[k] = v\n",
    "        ret_index[v] = old_val\n",
    "    \n",
    "\n",
    "    return quantum_gates,ret_index\n",
    "    \n",
    "    \n",
    "def extract_model(model):\n",
    "    layer_prop = {}\n",
    "    batch_adj_prop = {}\n",
    "    indiv_adj_prop = {}\n",
    "    for name, para in model.named_parameters():\n",
    "        if \"fc\" in name:\n",
    "            layer_id = int(name.split(\".\")[0].split(\"c\")[1])\n",
    "            layer_prop[layer_id] = [para.shape[1],para.shape[0],binarize(para)]            \n",
    "        elif \"qca\" in name:            \n",
    "            if \"l_0_5\" in name or \"running_rot\" in name:\n",
    "                layer_id = int(name.split(\".\")[0].split(\"a\")[1])\n",
    "                layer_fun = name.split(\".\")[1]\n",
    "                if layer_id not in batch_adj_prop.keys():\n",
    "                    batch_adj_prop[layer_id] = {}\n",
    "                batch_adj_prop[layer_id][layer_fun] = para\n",
    "        else:            \n",
    "            print(name, para)\n",
    "    \n",
    "    # print(layer_prop)\n",
    "    # print(batch_adj_prop)\n",
    "\n",
    "    # First layer\n",
    "    first_layer_num = layer_prop[0][1]\n",
    "    \n",
    "    first_layer_input_q = int(math.log(layer_prop[0][0],2))\n",
    "    first_layer_addition_q = max(first_layer_input_q-2,0)        \n",
    "    first_layer_batch_q = 0    \n",
    "    if 0 in batch_adj_prop.keys():\n",
    "        first_layer_batch_q = 2\n",
    "    \n",
    "    first_layer_q = first_layer_num*(first_layer_input_q+first_layer_batch_q)\n",
    "    \n",
    "    # print(first_layer_q)\n",
    "    \n",
    "    # Second layer\n",
    "    second_layer_num = layer_prop[1][1]\n",
    "    second_layer_input_q = int(math.log(layer_prop[1][0],2))\n",
    "    second_layer_addition_q = max(first_layer_input_q-2,0)        \n",
    "    second_layer_batch_q = 0\n",
    "    if 1 in batch_adj_prop.keys():\n",
    "        second_layer_batch_q = 2\n",
    "\n",
    "    second_layer_q = second_layer_num*(second_layer_input_q+second_layer_batch_q)\n",
    "    # print(second_layer_q)\n",
    "    \n",
    "    return first_layer_q,second_layer_q,first_layer_input_q,layer_prop,batch_adj_prop,max(first_layer_addition_q,second_layer_addition_q)\n",
    "    \n",
    "# Main part\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    # imshow(torchvision.utils.make_grid(data))\n",
    "    # print(data,target)\n",
    "    Q_InputMatrix = ToQuantumMatrix()(data.flatten())\n",
    "    break\n",
    "print(Q_InputMatrix.shape)\n",
    "\n",
    "\n",
    "\n",
    "def q_map_neural_compute_body(circ,inputs,iq,inference_batch_size,log_batch_size):\n",
    "        \n",
    "    quantum_gates,ret_index = qf_map_extract_from_weight(nn_prop[0][2][0])\n",
    "    # print(ret_index)\n",
    "    # print(quantum_gates)\n",
    "    # \n",
    "    expand_for_batch_index = copy.deepcopy(ret_index)\n",
    "    for b in range(inference_batch_size-1):\n",
    "        start = len(ret_index)*(b+1)\n",
    "        new_batch_index = [x+start for x in ret_index]\n",
    "        expand_for_batch_index += new_batch_index\n",
    "    index = torch.LongTensor(expand_for_batch_index)    \n",
    "    Input0 = copy.deepcopy(Q_InputMatrix)\n",
    "    Input0 = Input0[index]\n",
    "    # print(\"for debug comparison\")\n",
    "    # print(Q_InputMatrix[:,0])\n",
    "    \n",
    "    print(Input0[:,0])\n",
    "    circ.append(UnitaryGate(Input0, label=\"Input0\"), inputs[0:iq])\n",
    "    qbits = inputs[log_batch_size:iq]\n",
    "    \n",
    "    for gate in quantum_gates:\n",
    "        z_count = gate.count(\"1\")\n",
    "        # z_pos = get_index_list(gate,\"1\")\n",
    "        z_pos = get_index_list(gate[::-1],\"1\")    \n",
    "        if z_count==1:\n",
    "            circ.z(qbits[z_pos[0]])\n",
    "        elif z_count==2:\n",
    "            circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "        elif z_count==3:\n",
    "            qiskit_library.ccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux_qr[0])\n",
    "        elif z_count==4:\n",
    "            qiskit_library.cccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux_qr[0],aux_qr[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(circ)\n",
    "    # backend = Aer.get_backend('unitary_simulator')\n",
    "    # job = execute(circ, backend)\n",
    "    # result = job.result()\n",
    "    #     \n",
    "    # torch.set_printoptions(threshold=sys.maxsize)\n",
    "    # np.set_printoptions(threshold=sys.maxsize)\n",
    "    # state = result.get_unitary(circ, decimals=4)\n",
    "    # print(state[:,0])\n",
    "    # sys.exit(0)\n",
    "\n",
    "\n",
    "def q_map_neural_compute_extract(circ,inputs,iq,outputs,log_batch_size):        \n",
    "    qbits = inputs[0:iq-log_batch_size]\n",
    "    # qbits = inputs[log_batch_size:iq]\n",
    "    for q in qbits:\n",
    "        circ.h(q)\n",
    "    \n",
    "    circ.barrier()\n",
    "    \n",
    "    for q in qbits:\n",
    "        circ.x(q)\n",
    "    \n",
    "    \n",
    "    digits = log_batch_size\n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    # qbits = inputs[0:log_batch_size]\n",
    "    qbits = inputs[iq-log_batch_size:iq]\n",
    "    if log_batch_size!=0:\n",
    "        for i in range(int(math.pow(2,log_batch_size))):        \n",
    "            binstr_cur_num = format(i,flag)\n",
    "            \n",
    "            for pos in range(len(binstr_cur_num)):            \n",
    "                if binstr_cur_num[pos]==\"0\":                \n",
    "                    circ.x(qbits[pos])\n",
    "                    \n",
    "            if digits==1:                            \n",
    "                qiskit_library.cccccx(circ, inputs[0:iq], outputs[i],aux_qr)            \n",
    "            elif digits==2:\n",
    "                qiskit_library.ccccccx(circ, inputs[0:iq], outputs[i],aux_qr)\n",
    "            \n",
    "            \n",
    "            for pos in range(len(binstr_cur_num)):                \n",
    "                if binstr_cur_num[pos]==\"0\":                \n",
    "                    circ.x(qbits[pos])\n",
    "            circ.barrier()\n",
    "            \n",
    "    else:\n",
    "        qiskit_library.ccccx(circ, inputs[0], inputs[1], inputs[2], inputs[3], outputs[0], aux_qr[0], aux_qr[1])\n",
    "    \n",
    "    circ.barrier()\n",
    "    qbits = inputs[log_batch_size:iq]\n",
    "    for q in qbits:    \n",
    "        circ.x(q)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% QF-Map\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([0.0049, 0.1849, 0.2725, 0.0097, 0.0876, 0.3796, 0.2530, 0.0827, 0.0925,\n",
      "        0.2384, 0.5596, 0.0341, 0.0049, 0.1655, 0.4623, 0.2190],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.0049, 0.1849, 0.2725, 0.0097, 0.0876, 0.3796, 0.2530, 0.0827, 0.0925,\n",
      "        0.2384, 0.5596, 0.0341, 0.0049, 0.1655, 0.4623, 0.2190],\n",
      "       dtype=torch.float64)\n",
      "             ┌──────────┐              ░                           ░ ┌───┐ ░ »\n",
      "fLayer_0: |0>┤0         ├──■───────■───░───────────────────────────░─┤ H ├─░─»\n",
      "             │          │  │       │   ░                           ░ ├───┤ ░ »\n",
      "fLayer_1: |0>┤1         ├──■───────■───░───────────────────────────░─┤ H ├─░─»\n",
      "             │  unitary │  │       │   ░                           ░ ├───┤ ░ »\n",
      "fLayer_2: |0>┤2         ├──┼───■───┼───░───────────────────────────░─┤ H ├─░─»\n",
      "             │          │  │   │   │   ░                           ░ ├───┤ ░ »\n",
      "fLayer_3: |0>┤3         ├──┼───┼───┼───░───────────────────────────░─┤ H ├─░─»\n",
      "             └──────────┘  │   │   │   ░ ┌──────────┐              ░ └───┘ ░ »\n",
      "fLayer_4: |0>──────────────┼───┼───┼───░─┤0         ├──■───────■───░───────░─»\n",
      "                           │   │   │   ░ │          │  │       │   ░       ░ »\n",
      "fLayer_5: |0>──────────────┼───┼───┼───░─┤1         ├──■───────■───░───────░─»\n",
      "                           │   │   │   ░ │  unitary │  │       │   ░       ░ »\n",
      "fLayer_6: |0>──────────────┼───┼───┼───░─┤2         ├──┼───■───┼───░───────░─»\n",
      "                           │   │   │   ░ │          │  │   │   │   ░       ░ »\n",
      "fLayer_7: |0>──────────────┼───┼───┼───░─┤3         ├──┼───┼───┼───░───────░─»\n",
      "                           │   │   │   ░ └──────────┘  │   │   │   ░       ░ »\n",
      "sLayer_0: |0>──────────────┼───┼───┼───░───────────────┼───┼───┼───░───────░─»\n",
      "                           │   │   │   ░               │   │   │   ░       ░ »\n",
      "sLayer_1: |0>──────────────┼───┼───┼───░───────────────┼───┼───┼───░───────░─»\n",
      "                         ┌─┴─┐ │ ┌─┴─┐ ░             ┌─┴─┐ │ ┌─┴─┐ ░       ░ »\n",
      "   aux_0: |0>────────────┤ X ├─■─┤ X ├─░─────────────┤ X ├─■─┤ X ├─░───────░─»\n",
      "                         └───┘   └───┘ ░             └───┘   └───┘ ░       ░ »\n",
      "   aux_1: |0>──────────────────────────░───────────────────────────░───────░─»\n",
      "                                       ░                           ░       ░ »\n",
      "    reg_0: 0 ════════════════════════════════════════════════════════════════»\n",
      "                                                                             »\n",
      "    reg_1: 0 ════════════════════════════════════════════════════════════════»\n",
      "                                                                             »\n",
      "«          ┌───┐                          ░ ┌───┐ ░       ░                »\n",
      "«fLayer_0: ┤ X ├──■───────────────────■───░─┤ X ├─░───────░────────────────»\n",
      "«          ├───┤  │                   │   ░ ├───┤ ░       ░                »\n",
      "«fLayer_1: ┤ X ├──■───────────────────■───░─┤ X ├─░───────░────────────────»\n",
      "«          ├───┤  │                   │   ░ ├───┤ ░       ░                »\n",
      "«fLayer_2: ┤ X ├──┼────■─────────■────┼───░─┤ X ├─░───────░────────────────»\n",
      "«          ├───┤  │    │         │    │   ░ ├───┤ ░       ░                »\n",
      "«fLayer_3: ┤ X ├──┼────■─────────■────┼───░─┤ X ├─░───────░────────────────»\n",
      "«          └───┘  │    │         │    │   ░ └───┘ ░ ┌───┐ ░ ┌───┐          »\n",
      "«fLayer_4: ───────┼────┼─────────┼────┼───░───────░─┤ H ├─░─┤ X ├──■───────»\n",
      "«                 │    │         │    │   ░       ░ ├───┤ ░ ├───┤  │       »\n",
      "«fLayer_5: ───────┼────┼─────────┼────┼───░───────░─┤ H ├─░─┤ X ├──■───────»\n",
      "«                 │    │         │    │   ░       ░ ├───┤ ░ ├───┤  │       »\n",
      "«fLayer_6: ───────┼────┼─────────┼────┼───░───────░─┤ H ├─░─┤ X ├──┼────■──»\n",
      "«                 │    │         │    │   ░       ░ ├───┤ ░ ├───┤  │    │  »\n",
      "«fLayer_7: ───────┼────┼─────────┼────┼───░───────░─┤ H ├─░─┤ X ├──┼────■──»\n",
      "«                 │    │  ┌───┐  │    │   ░       ░ └───┘ ░ └───┘  │    │  »\n",
      "«sLayer_0: ───────┼────┼──┤ X ├──┼────┼───░───────░───────░────────┼────┼──»\n",
      "«                 │    │  └─┬─┘  │    │   ░       ░       ░        │    │  »\n",
      "«sLayer_1: ───────┼────┼────┼────┼────┼───░───────░───────░────────┼────┼──»\n",
      "«               ┌─┴─┐  │    │    │  ┌─┴─┐ ░       ░       ░      ┌─┴─┐  │  »\n",
      "«   aux_0: ─────┤ X ├──┼────■────┼──┤ X ├─░───────░───────░──────┤ X ├──┼──»\n",
      "«               └───┘┌─┴─┐  │  ┌─┴─┐└───┘ ░       ░       ░      └───┘┌─┴─┐»\n",
      "«   aux_1: ──────────┤ X ├──■──┤ X ├──────░───────░───────░───────────┤ X ├»\n",
      "«                    └───┘     └───┘      ░       ░       ░           └───┘»\n",
      "«   reg_0: ════════════════════════════════════════════════════════════════»\n",
      "«                                                                          »\n",
      "«   reg_1: ════════════════════════════════════════════════════════════════»\n",
      "«                                                                          »\n",
      "«                          ░       ░       \n",
      "«fLayer_0: ────────────────░───────░───────\n",
      "«                          ░       ░       \n",
      "«fLayer_1: ────────────────░───────░───────\n",
      "«                          ░       ░       \n",
      "«fLayer_2: ────────────────░───────░───────\n",
      "«                          ░       ░       \n",
      "«fLayer_3: ────────────────░───────░───────\n",
      "«                          ░ ┌───┐ ░       \n",
      "«fLayer_4: ────────────■───░─┤ X ├─░───────\n",
      "«                      │   ░ ├───┤ ░       \n",
      "«fLayer_5: ────────────■───░─┤ X ├─░───────\n",
      "«                      │   ░ ├───┤ ░       \n",
      "«fLayer_6: ───────■────┼───░─┤ X ├─░───────\n",
      "«                 │    │   ░ ├───┤ ░       \n",
      "«fLayer_7: ───────■────┼───░─┤ X ├─░───────\n",
      "«                 │    │   ░ └───┘ ░ ┌─┐   \n",
      "«sLayer_0: ───────┼────┼───░───────░─┤M├───\n",
      "«          ┌───┐  │    │   ░       ░ └╥┘┌─┐\n",
      "«sLayer_1: ┤ X ├──┼────┼───░───────░──╫─┤M├\n",
      "«          └─┬─┘  │  ┌─┴─┐ ░       ░  ║ └╥┘\n",
      "«   aux_0: ──■────┼──┤ X ├─░───────░──╫──╫─\n",
      "«            │  ┌─┴─┐└───┘ ░       ░  ║  ║ \n",
      "«   aux_1: ──■──┤ X ├──────░───────░──╫──╫─\n",
      "«               └───┘      ░       ░  ║  ║ \n",
      "«   reg_0: ═══════════════════════════╩══╬═\n",
      "«                                        ║ \n",
      "«   reg_1: ══════════════════════════════╩═\n",
      "«                                          \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import qiskit_library\n",
    "\n",
    "f,s,iq,nn_prop,bn_prop,aux = extract_model(model)\n",
    "\n",
    "\n",
    "log_batch_size = int(math.log(inference_batch_size,2))\n",
    "\n",
    "f = f+(log_batch_size)*nn_prop[0][1]\n",
    "iq = iq+log_batch_size\n",
    "aux = aux+inference_batch_size-1\n",
    "\n",
    "s = (inference_batch_size)*s\n",
    "s = inference_batch_size*2\n",
    "\n",
    "# f=5\n",
    "# aux=1\n",
    "\n",
    "\n",
    "f_qr = QuantumRegister(f,\"fLayer\")\n",
    "s_qr = QuantumRegister(s,\"sLayer\")\n",
    "aux_qr = QuantumRegister(aux,\"aux\")\n",
    "c = ClassicalRegister(s,\"reg\")\n",
    "\n",
    "\n",
    "\n",
    "circ = QuantumCircuit(f_qr,s_qr,aux_qr,c)\n",
    "\n",
    "# circ = QuantumCircuit(f_qr,aux_qr)\n",
    "\n",
    "# Build Inputs and Computation\n",
    "q_map_neural_compute_body(circ,f_qr[0:iq],iq,inference_batch_size,log_batch_size)\n",
    "circ.barrier()\n",
    "q_map_neural_compute_body(circ,f_qr[iq:iq*2],iq,inference_batch_size,log_batch_size)\n",
    "circ.barrier()\n",
    "\n",
    "# Build the extraction of results\n",
    "q_map_neural_compute_extract(circ,f_qr[0:iq],iq,s_qr[0:inference_batch_size],log_batch_size)\n",
    "circ.barrier()\n",
    "q_map_neural_compute_extract(circ,f_qr[iq:2*iq],iq,s_qr[inference_batch_size:2*inference_batch_size],log_batch_size)\n",
    "circ.barrier()\n",
    "\n",
    "for i in range(s):\n",
    "    circ.measure(s_qr[i],c[i])\n",
    "\n",
    "print(circ)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==================================================\n",
      "Start simulation:\n",
      "Job Status: job has successfully run\n",
      "Simulation time: 5.079354524612427\n",
      "0 0.373811\n",
      "1 0.374672\n",
      "From QC: [{'00': 392048, '11': 140531, '10': 234141, '01': 233280}]\n",
      "Simulation elasped time: 5.0824432373046875\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from qiskit_library import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "import qiskit as qk\n",
    "from qiskit import Aer\n",
    "from qiskit import execute\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from qiskit import IBMQ\n",
    "# IBMQ.delete_accounts()\n",
    "IBMQ.save_account('62d0e14364f490e45b5b5e0f6eebdbc083270ffffb660c7054219b15c7ce99ab4aa3b321309c0a9d0c3fc20086baece1376297dcdb67c7b715f9de1e4fa79efb')\n",
    "IBMQ.load_account()\n",
    "\n",
    "num_c_reg=2\n",
    "\n",
    "def analyze(counts):\n",
    "    mycount = {}\n",
    "    for i in range(num_c_reg):\n",
    "        mycount[i] = 0\n",
    "    for k,v in counts.items():\n",
    "        bits = len(k) \n",
    "        for i in range(bits):            \n",
    "            if k[bits-1-i] == \"1\":\n",
    "                if i in mycount.keys():\n",
    "                    mycount[i] += v\n",
    "                else:\n",
    "                    mycount[i] = v\n",
    "    return mycount,bits\n",
    "\n",
    "def fire_ibmq(circuit,shots,iter,Simulation = False, printable=True,backend_name='ibmq_essex'):\n",
    "    if printable:\n",
    "        print(circuit)\n",
    "    \n",
    "    count_set = []\n",
    "    start = time.time()\n",
    "    for it in range(iter):\n",
    "        if not Simulation:\n",
    "            provider = IBMQ.get_provider('ibm-q-academic')\n",
    "            # ibm-q-academic backends: \n",
    "            #  5 qubits: ibmq_valencia\n",
    "            # 20 qubits: ibmq_poughkeepsie, ibmq_johannesburg,ibmq_boeblingen, ibmq_20_tokyo\n",
    "            # 53 qubits: ibmq_rochester\n",
    "            \n",
    "            # To get a specific qubit backend: \n",
    "            backend = provider.get_backend(backend_name)\n",
    "        else:\n",
    "            backend = Aer.get_backend('qasm_simulator')\n",
    "        job_ibm_q = execute(circuit, backend, shots=shots)\n",
    "        job_monitor(job_ibm_q)\n",
    "        result_ibm_q = job_ibm_q.result()\n",
    "        counts = result_ibm_q.get_counts()\n",
    "        count_set.append(counts)\n",
    "    end = time.time()\n",
    "    print(\"Simulation time:\", end - start)\n",
    "\n",
    "    return count_set\n",
    "\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Start simulation:\")\n",
    "start = time.time()        \n",
    "iters = 1\n",
    "qc_shots=1000000\n",
    "counts = fire_ibmq(circ,qc_shots,iters,True,False)\n",
    "end = time.time()\n",
    "qc_time = end - start\n",
    "\n",
    "(mycount,bits) = analyze(counts[0])\n",
    "for b in range(bits):\n",
    "    print (b,float(mycount[b])/qc_shots)\n",
    "    \n",
    "print(\"From QC:\",counts)\n",
    "print(\"Simulation elasped time:\",qc_time)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\t tensor([[0.0049, 0.1849, 0.2725, 0.0097, 0.0876, 0.3796, 0.2530, 0.0827, 0.0925,\n",
      "         0.4623, 0.5596, 0.2190, 0.0049, 0.1655, 0.2384, 0.0341]])\n",
      "\t tensor([[0.1782, 0.1782]], grad_fn=<PowBackward0>)\n",
      "\t tensor([[0.1782, 0.1782]], grad_fn=<PowBackward0>)\n",
      "\t tensor([[0.2929, 0.7071]], grad_fn=<DivBackward0>)\n",
      "\t tensor([[0.6028, 0.3972]], grad_fn=<AddBackward0>)\n",
      "tensor([[0.6028, 0.3972]], grad_fn=<AddBackward0>)\n",
      "Input\n",
      "tensor([[0.0049, 0.1849, 0.2725, 0.0097, 0.0876, 0.3796, 0.2530, 0.0827],\n",
      "        [0.0925, 0.4623, 0.5596, 0.2190, 0.0049, 0.1655, 0.2384, 0.0341]])\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-429-0de65615093d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantum_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mweighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquantum_data\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 1"
     ],
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 1",
     "output_type": "error"
    }
   ],
   "source": [
    "# model.eval()\n",
    "quantum_data = ToQuantumData_Batch()(data)\n",
    "output = model(quantum_data, False)\n",
    "\n",
    "print(output)\n",
    "\n",
    "w = torch.tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., 1.,  1.])\n",
    "quantum_data=quantum_data.view(2,-1)\n",
    "print(\"Input\")\n",
    "# print(quantum_data)\n",
    "# weighted = (quantum_data*w)\n",
    "# print((weighted[0].sum()/4).pow(2))\n",
    "# print((weighted[1].sum()/4).pow(2))\n",
    "\n",
    "# tensor([0.0108, 0.1053, 0.1674, 0.0432, 0.0162, 0.1809, 0.3646, 0.1053, 0.0729,\n",
    "#         0.0702, 0.2674, 0.0216, 0.1242, 0.2107, 0.1809, 0.0648, 0.0000, 0.0297,\n",
    "#         0.2053, 0.0243, 0.0135, 0.2620, 0.2296, 0.4321, 0.0486, 0.0189, 0.4699,\n",
    "#         0.0108, 0.0054, 0.0891, 0.0999, 0.0972], dtype=torch.float64)\n",
    "# tensor([0.0108, 0.1053, 0.1674, 0.0432, 0.0162, 0.1809, 0.3646, 0.1053, 0.0729,\n",
    "#         0.0702, 0.2674, 0.0216, 0.1242, 0.2107, 0.1809, 0.0648, 0.0000, 0.0297,\n",
    "#         0.2053, 0.0243, 0.0135, 0.2620, 0.2296, 0.4321, 0.0486, 0.0189, 0.4699,\n",
    "#         0.0108, 0.0054, 0.0891, 0.0999, 0.0972], dtype=torch.float64)\n",
    "\n",
    "# Q_InputMatrix = ToQuantumMatrix()(data.flatten())\n",
    "\n",
    "# \n",
    "# print(Q_InputMatrix[:,0])\n",
    "# Q_InputMatrix = ToQuantumMatrix()(data[0].flatten())\n",
    "# print(Q_InputMatrix[:,0])\n",
    "# Q_InputMatrix = ToQuantumMatrix()(data[1].flatten())\n",
    "# print(Q_InputMatrix[:,0])\n",
    "# \n",
    "# mydata = [0.0000, 0.2344, 0.0732, 0.0000, 0.0146, 0.4345, 0.3027, 0.0439, 0.0146,\n",
    "#         0.5273, 0.5908, 0.1123, 0.0000, 0.0586, 0.1172, 0.0098, 0.0000, 0.0185, 0.3193, 0.0787, 0.0046, 0.2823, 0.4026, 0.0278, 0.0972,\n",
    "#         0.6154, 0.4720, 0.0370, 0.0324, 0.1805, 0.0555, 0.0000]\n",
    "# Q_InputMatrix = ToQuantumMatrix()(torch.tensor(mydata))\n",
    "# print(Q_InputMatrix[:,0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# circ.append(UnitaryGate(Q_InputMatrix, label=\"iswap\"), f_qr[iq:iq*2])\n",
    "\n",
    "# quantum_gates,ret_index = qf_map_extract_from_weight(nn_prop[0][2][0])\n",
    "# expand_for_batch_index = copy.deepcopy(ret_index)\n",
    "# for b in range(inference_batch_size-1):\n",
    "#     start = len(ret_index)*(b+1)\n",
    "#     new_batch_index = [x+start for x in ret_index]\n",
    "#     expand_for_batch_index += new_batch_index\n",
    "# index = torch.LongTensor(expand_for_batch_index)\n",
    "# Input0 = copy.deepcopy(Q_InputMatrix)\n",
    "# Input0 = Input0[index]\n",
    "# circ.append(UnitaryGate(Input0, label=\"Input0\"), f_qr[0:iq])\n",
    "# qbits = f_qr[inference_batch_size-1:iq]\n",
    "# \n",
    "# \n",
    "# for gate in quantum_gates:\n",
    "#     z_count = gate.count(\"1\")    \n",
    "#     z_pos = get_index_list(gate[::-1],\"1\")    \n",
    "#     if z_count==1:\n",
    "#         circ.z(qbits[z_pos[0]])\n",
    "#     elif z_count==2:\n",
    "#         circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "#     elif z_count==3:\n",
    "#         qiskit_library.ccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux_qr[0])\n",
    "#     elif z_count==4:\n",
    "#         qiskit_library.cccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux_qr[0],aux_qr[1])\n",
    "    \n",
    "\n",
    "# quantum_gates,ret_index = qf_map_extract_from_weight(nn_prop[0][2][1])\n",
    "# expand_for_batch_index = copy.deepcopy(ret_index)\n",
    "# for b in range(inference_batch_size-1):\n",
    "#     start = len(ret_index)*(b+1)\n",
    "#     new_batch_index = [x+start for x in ret_index]\n",
    "#     expand_for_batch_index += new_batch_index\n",
    "# index = torch.LongTensor(expand_for_batch_index)\n",
    "# Input1 = copy.deepcopy(Q_InputMatrix)\n",
    "# Input1 = Input1[index]\n",
    "# circ.append(UnitaryGate(Input1, label=\"Input1\"), f_qr[iq:iq*2])\n",
    "# qbits = f_qr[iq+inference_batch_size-1:iq*2]\n",
    "# for gate in quantum_gates:\n",
    "#     z_count = gate.count(\"1\")\n",
    "#     z_pos = get_index_list(gate[::-1],\"1\")\n",
    "#     if z_count==1:\n",
    "#         circ.z(qbits[z_pos[0]])\n",
    "#     elif z_count==2:\n",
    "#         circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "#     elif z_count==3:\n",
    "#         qiskit_library.ccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux_qr[0])\n",
    "#     elif z_count==4:\n",
    "#         qiskit_library.cccz(circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux_qr[0],aux_qr[1])\n",
    "# \n",
    "# circ.barrier()\n",
    "\n",
    "# \n",
    "# qbits = f_qr[inference_batch_size-1:iq]\n",
    "# for q in qbits:\n",
    "#     circ.h(q)\n",
    "# \n",
    "# circ.barrier()\n",
    "# \n",
    "# for q in qbits:\n",
    "#     circ.x(q)\n",
    "# \n",
    "# \n",
    "# digits = int(math.log(inference_batch_size,2))\n",
    "# flag = \"0\"+str(digits)+\"b\"\n",
    "# qbits = f_qr[0:inference_batch_size-1]\n",
    "# if inference_batch_size!=1:\n",
    "#     for i in range(inference_batch_size):        \n",
    "#         binstr_cur_num = format(i,flag)\n",
    "#         for pos in range(len(binstr_cur_num)):            \n",
    "#             if binstr_cur_num[pos]==\"0\":                \n",
    "#                 circ.x(qbits[pos])\n",
    "#             if digits==1:                            \n",
    "#                 qiskit_library.cccccx(circ, f_qr[0:iq], s_qr[i*2],aux_qr)\n",
    "#             if binstr_cur_num[pos]==\"0\":                \n",
    "#                 circ.x(qbits[pos])            \n",
    "# else:\n",
    "#     qiskit_library.ccccx(circ, f_qr[0], f_qr[1], f_qr[2], f_qr[3], s_qr[0], aux_qr[0], aux_qr[1])\n",
    "#         \n",
    "# # qbits = f_qr[inference_batch_size-1:iq]\n",
    "# # for q in qbits:    \n",
    "# #     circ.x(q)\n",
    "# \n",
    "# print(circ)\n",
    "# circ.barrier()\n",
    "# print(circ)\n",
    "# sys.exit(0)\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# qbits = f_qr[iq+inference_batch_size-1:iq*2]\n",
    "# for q in qbits:\n",
    "#     circ.h(q)\n",
    "#     circ.x(q)\n",
    "# qiskit_library.ccccx(circ, f_qr[4], f_qr[5], f_qr[6], f_qr[7], s_qr[1], aux_qr[0], aux_qr[1])\n",
    "# qbits = f_qr[iq+inference_batch_size-1:iq*2]\n",
    "# for q in qbits:\n",
    "#     circ.x(q)\n",
    "# circ.barrier()\n",
    "# \n",
    "# \n",
    "# circ.measure(s_qr[0],c[0])\n",
    "# circ.measure(s_qr[1],c[1])\n",
    "# print(circ)\n",
    "# \n",
    "# sys.exit(0)\n",
    "\n",
    "# \n",
    "# print(Q_InputMatrix.flatten())\n",
    "# print(\"==\"*10)\n",
    "# print(Input0.flatten())\n",
    "# print(\"==\"*10)\n",
    "# print(Input1.flatten())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}