{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import qiskit \n",
    "from qiskit import transpile, assemble,IBMQ\n",
    "from qiskit.visualization import *\n",
    "\n",
    "\n",
    "#IBMQ.delete_accounts()\n",
    "#IBMQ.save_account('2d7fb4a2d08cbb349872fe2229939996c6b01d6e420a129f9a63a5c8bb7c615394c422b44240dc09c275e506c6bad13d80776785cbfb36ef2e6ac297c9b85715')\n",
    "#IBMQ.load_account()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from qiskit.extensions import  UnitaryGate\n",
    "from torch.nn.parameter import Parameter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#set parameter\n",
    "interest_num = [3,6]\n",
    "ori_img_size = 28\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "inference_batch_size = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Weiwen: modify the target classes starting from 0. Say, [3,6] -> [0,1]\n",
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "# Weiwen: select sub-set from MNIST\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Using torch to load MNIST data\n",
    "######################################################\n",
    "\n",
    "# convert data to torch.float64Tensor\n",
    "transform = transforms.Compose([transforms.Resize((ori_img_size,ori_img_size)),\n",
    "                                transforms.ToTensor()])\n",
    "# Path to MNIST Dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/hzr/anaconda3/envs/qf/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448216815/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum data\n",
    "######################################################\n",
    "class ToQuantumData(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v),)\n",
    "        output_data = output_matrix[:, 0].view(1, img_size,img_size)\n",
    "        return output_data\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum matrix\n",
    "######################################################\n",
    "class ToQuantumMatrix(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v), dtype=torch.float64)\n",
    "        return output_matrix   \n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# T1: Downsample the image from 28*28 to 4*4\n",
    "# T2: Convert classical data to quantum data which \n",
    "#     can be encoded to the quantum states (amplitude)\n",
    "######################################################\n",
    "\n",
    "# Process data by hand, we can also integrate ToQuantumData into transform\n",
    "def data_pre_pro(img):\n",
    "    # Print original figure\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    #plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    #plt.show()\n",
    "    # Print resized figure\n",
    "    image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    im = Image.fromarray(image,mode=\"L\")\n",
    "    im = im.resize((4,4),Image.BILINEAR)    \n",
    "    #plt.imshow(im,cmap='gray',)\n",
    "    #plt.show()\n",
    "    # Converting classical data to quantum data\n",
    "    trans_to_tensor = transforms.ToTensor()\n",
    "    trans_to_vector = ToQuantumData()\n",
    "    trans_to_matrix = ToQuantumMatrix()    \n",
    "    #print(\"Classical Data: {}\".format(trans_to_tensor(im).flatten()))\n",
    "    #print(\"Quantum Data: {}\".format(trans_to_vector(trans_to_tensor(im)).flatten()))\n",
    "    return trans_to_matrix(trans_to_tensor(im)),trans_to_vector(trans_to_tensor(im))\n",
    "\n",
    "# Use the first image from test loader as example\n",
    "global g_quantum_matrix\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    g_quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "    break\n",
    "  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch Id: 0, Target: tensor([1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#draft \n",
    "a = {\"1\":3,\"2\":6}\n",
    "def func(l):\n",
    "    b = l\n",
    "    b[\"2\"] = 7\n",
    "\n",
    "func(a)\n",
    "print (a)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'1': 3, '2': 7}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "################ zhirui on 12-30-2020 ################\n",
    "# this block is for buding variant circuit\n",
    "######################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import qiskit\n",
    "from qiskit import transpile, assemble\n",
    "from qiskit.visualization import *\n",
    "\n",
    "class VQuantumCircuit:    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- parameter definition ---\n",
    "        #self._circuit = circuit\n",
    "        self.n_qubits = n_qubits\n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta = qiskit.circuit.ParameterVector('theta',n_qubits*2)\n",
    "        self.theta = list(self.theta)\n",
    "        # ---------------------------\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "    \n",
    "    #define the circuit\n",
    "    def vqc_10(self,circuit):\n",
    "\n",
    "        #head ry part \n",
    "        for i in range(0,self.n_qubits):\n",
    "            circuit.ry(self.theta[i], i)\n",
    "        circuit.barrier()\n",
    "        \n",
    "        #cz part\n",
    "        for i in range(self.n_qubits-1):\n",
    "            circuit.cz(self.n_qubits-2-i,self.n_qubits-1-i)\n",
    "        circuit.cz(0,self.n_qubits-1)\n",
    "        circuit.barrier()\n",
    "\n",
    "        #tail ry part\n",
    "        for i in range(0,self.n_qubits):\n",
    "            circuit.ry(self.theta[i+self.n_qubits], i)     \n",
    "\n",
    "\n",
    "    \n",
    "    def build(self,circuit):\n",
    "        self.vqc_10(circuit)\n",
    "    \n",
    "    def run(self,circuit, thetas):\n",
    "    #define the whole circuit\n",
    "        circuit.measure_all()\n",
    "\n",
    "        t_qc = transpile(circuit,\n",
    "                         self.backend)\n",
    "        binds = {}\n",
    "        for i in range(0,len(thetas)):#\n",
    "            binds[self.theta[i]]= thetas[i]\n",
    "\n",
    "        \n",
    "\n",
    "        qobj = assemble(t_qc,\n",
    "                        shots=self.shots,\n",
    "                        parameter_binds = [binds]\n",
    "                        )\n",
    "        job = self.backend.run(qobj)\n",
    "\n",
    "        result = job.result().get_counts()\n",
    "        # print(\"result:\",result)\n",
    "\n",
    "        #counts = np.array(list(result.values()))\n",
    "        #states = np.array(list(result.keys())).astype(float)\n",
    "        # Compute probabilities for each state\n",
    "        output = np.zeros(4)\n",
    "        for key in result.keys():\n",
    "          result[key] =  result[key] / self.shots\n",
    "          i=0\n",
    "          for c in key:\n",
    "              if c == '1':\n",
    "                  output[i] =output[i]+ result[key]\n",
    "              i = i+1\n",
    "        return output\n",
    "\n",
    "\n",
    "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
    "vqc = VQuantumCircuit(4, simulator, 10000)\n",
    "\n",
    "# print(\"g_quantum_matrix:\",g_quantum_matrix)\n",
    "circuit = qiskit.QuantumCircuit(4)\n",
    "circuit.append(UnitaryGate(g_quantum_matrix, label=\"Input\"),range(0,4))\n",
    "vqc.build(circuit)\n",
    "print('probabilities :{}'.format(vqc.run(circuit,[np.pi/3,np.pi/4,np.pi/3,np.pi/9,np.pi,np.pi/4,np.pi/10,np.pi/2])))\n",
    "circuit.draw()\n",
    "\n",
    "circuit = qiskit.QuantumCircuit(4)\n",
    "circuit.append(UnitaryGate(g_quantum_matrix, label=\"Input\"),range(0,4))\n",
    "vqc.build(circuit)\n",
    "print('probabilities :{}'.format(vqc.run(circuit,[np.pi/3,np.pi/4,np.pi/3,np.pi/9,np.pi,np.pi/4,np.pi/10,np.pi/2])))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "probabilities :[0.6001 0.6916 0.69   0.3783]\n",
      "probabilities :[0.6037 0.7001 0.6946 0.3744]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "identity = torch.tensor([[1,0],[0,1]])\n",
    "mat2 = torch.tensor([[1,2],[3,4]])\n",
    "print(torch.kron(identity,mat2))\n",
    "print(torch.kron(mat2,identity))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 0, 0],\n",
      "        [3, 4, 0, 0],\n",
      "        [0, 0, 1, 2],\n",
      "        [0, 0, 3, 4]])\n",
      "tensor([[1, 0, 2, 0],\n",
      "        [0, 1, 0, 2],\n",
      "        [3, 0, 4, 0],\n",
      "        [0, 3, 0, 4]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "################ zhirui on 12-30-2020 ################\n",
    "# this block is for buding the matrix of variant circuit\n",
    "######################################################\n",
    "import math\n",
    "class VClassicCircuitMatrix:\n",
    "    def __init__(self, n_qubits):\n",
    "        # --- parameter definition ---\n",
    "        self._n_qubits = n_qubits\n",
    "        #state = state\n",
    "        #constant matrix\n",
    "        self.mat_cz = torch.tensor([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,-1]])\n",
    "        self.mat_identity = torch.tensor([[1,0],[0,1]])\n",
    "        self.mat_swap = torch.tensor([[1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]])\n",
    "\n",
    "    def set_value(self,mm,col,row,val):\n",
    "        index = (torch.LongTensor([col]),torch.LongTensor([row]))#生成索引\n",
    "        #value = torch.Tensor(val) #生成要填充的值\n",
    "        mm = mm.index_put(index ,val)\n",
    "        return mm\n",
    "\n",
    "    def get_ry_matrix(self,theta):\n",
    "        mm = torch.zeros(2,2,dtype=torch.float64)\n",
    "        mm = self.set_value(mm,0,0,torch.cos(theta/2))\n",
    "        mm = self.set_value(mm,0,1,-torch.sin(theta/2))\n",
    "        mm = self.set_value(mm,1,0,torch.cos(theta/2))\n",
    "        mm = self.set_value(mm,1,1,torch.sin(theta/2))\n",
    "        return mm\n",
    "\n",
    "    #swap (index) and (index-1)        \n",
    "    def qf_swap_dec(self,state,index):\n",
    "        #generate the matrix\n",
    "        temp_mat = torch.ones(1,dtype=torch.float64)\n",
    "        for i in range(0,index-1):\n",
    "            temp_mat = torch.kron(self.mat_identity,temp_mat)\n",
    "        temp_mat =torch.kron(self.mat_swap,temp_mat)\n",
    "        for i in range(0,self._n_qubits-1-index):\n",
    "            temp_mat = torch.kron(self.mat_identity,temp_mat)\n",
    "        #change state\n",
    "        state = torch.mm(temp_mat,state) \n",
    "        return state \n",
    "\n",
    "\n",
    "    def qf_ry(self,state,theta,index):\n",
    "        # print(\"theta 01 :\", theta)\n",
    "        # print(\"index 01 :\",index)\n",
    "        # print(\"01:\",theta.requires_grad)\n",
    "        temp_mat = torch.ones(1,dtype=torch.float64)\n",
    "        if isinstance(index,int): \n",
    "            for i in range(0,self._n_qubits):\n",
    "                if i == index:\n",
    "                    mm = self.get_ry_matrix(theta)\n",
    "                    temp_mat = torch.kron(mm,temp_mat) \n",
    "                    # print(\"temp_mat 04 :\", temp_mat)  \n",
    "                else:\n",
    "                    temp_mat = torch.kron(self.mat_identity,temp_mat) \n",
    "                    # print(\"temp_mat 05 :\", temp_mat)\n",
    "        else:\n",
    "            for i in range(0,self._n_qubits):\n",
    "                if i in index:\n",
    "                    select_theta = torch.index_select(theta,0,torch.tensor([i]))\n",
    "                    select_mm = self.get_ry_matrix(select_theta)\n",
    "                    temp_mat = torch.kron(select_mm,temp_mat)\n",
    "                    # print(\"02:\",temp_mat.requires_grad)\n",
    "                    # print(\"temp_mat 02 :\", temp_mat)\n",
    "                else:\n",
    "                    temp_mat = torch.kron(self.mat_identity,temp_mat) \n",
    "                    # print(\"temp_mat 03 :\", temp_mat)\n",
    "        #change state\n",
    "        #print('shape :',temp_mat.shape,' ',state.shape)\n",
    "        # print(\"temp_mat 01 :\", temp_mat)\n",
    "        # print(\"03:\",temp_mat.requires_grad)\n",
    "        state = torch.mm(temp_mat,state)   \n",
    "        # print(\"04:\",state.requires_grad)\n",
    "        # print(\"state 06 :\", state)\n",
    "        return state\n",
    "     \n",
    "            \n",
    "    def qf_cz(self,state,index1,index2):\n",
    "\n",
    "        #generate the matrix\n",
    "        \n",
    "        #swap the bottom one next to the up one\n",
    "        for i in range(index2,index1+1,-1):\n",
    "            state = self.qf_swap_dec(state,i)\n",
    "        \n",
    "        #generate cz matrix\n",
    "        temp_mat = torch.ones(1,dtype=torch.float64)\n",
    "        for i in range(0,index1):\n",
    "            temp_mat = torch.kron(self.mat_identity,temp_mat)\n",
    "\n",
    "        temp_mat =torch.kron(self.mat_cz,temp_mat)\n",
    "\n",
    "        for i in range(0,self._n_qubits-2-index1):\n",
    "            temp_mat = torch.kron(self.mat_identity,temp_mat)\n",
    "\n",
    "        #change state\n",
    "        state = torch.mm(temp_mat,state)   \n",
    "\n",
    "        #swap back\n",
    "        for i in range(index1+2,index2+1):\n",
    "            state = self.qf_swap_dec(state,i)\n",
    "\n",
    "        return state\n",
    "\n",
    "    #get the matrix transforming 16 output to 4 output.     \n",
    "    def qf_sum(self):\n",
    "        sum_mat = []\n",
    "        flag = \"0\"+str(self._n_qubits)+\"b\"\n",
    "        for i in range(0,int(math.pow(2,self._n_qubits))):\n",
    "            bit_str = format(i,flag)\n",
    "            row = []\n",
    "            for c in bit_str:\n",
    "                row.append(float(c))\n",
    "            sum_mat.append(row)\n",
    "        return sum_mat\n",
    "\n",
    "\n",
    "    #the code is similar to the VQuantumCircuit::vqc_10\n",
    "    def vqc_10(self,state,thetas):\n",
    "        \n",
    "        #head ry part \n",
    "        # print(\"05:\",state.requires_grad)\n",
    "        state = self.qf_ry(state,thetas[0:self._n_qubits],range(0,self._n_qubits))\n",
    "        # print(\"06:\",state.requires_grad)\n",
    "\n",
    "        #cz part\n",
    "\n",
    "        for i in range(self._n_qubits-1):\n",
    "            state = self.qf_cz(state,self._n_qubits-2-i,self._n_qubits-1-i)\n",
    "        state = self.qf_cz(state,0,self._n_qubits-1)\n",
    "        # print(\"07:\",state.requires_grad)\n",
    "\n",
    "        # print(\"state 04 :\", state)\n",
    "\n",
    "        #tail ry part\n",
    "\n",
    "        state = self.qf_ry(state,thetas[self._n_qubits:2*self._n_qubits],range(0,self._n_qubits))\n",
    "        # print(\"08:\",state.requires_grad)\n",
    "\n",
    "        # print(\"state 05 :\", state)\n",
    "\n",
    "        return state \n",
    "        \n",
    "    def run(self,state, thetas):\n",
    "        # print(\"state 01 :\", state)\n",
    "        state =self.vqc_10(state,thetas)\n",
    "        #print(\"state 02 :\", state)\n",
    "\n",
    "        sum_mat = torch.tensor(self.qf_sum(),dtype=torch.float64) \n",
    "        sum_mat = sum_mat.t()\n",
    "        # print(\"sum_mat:\",sum_mat)\n",
    "\n",
    "        state = state * state\n",
    "        # print(\"state2:\",state)\n",
    "\n",
    "        state = torch.mm(sum_mat,state)\n",
    "        \n",
    "        return state \n",
    "\n",
    "vcm = VClassicCircuitMatrix(4)\n",
    "\n",
    "test_state = torch.zeros(int(math.pow(2,4)),1,dtype=torch.float64)\n",
    "test_state =test_state.scatter(0,torch.tensor([[0]]),1.0)\n",
    "print(\"test_state:\",test_state)\n",
    "# print('g_quantum_matrix :',g_quantum_matrix)\n",
    "test_state = torch.mm(g_quantum_matrix,test_state)\n",
    "test_theta = torch.tensor( [np.pi/3,np.pi/4,np.pi/3,np.pi/9,np.pi,np.pi/4,np.pi/10,np.pi/2],dtype= torch.float64,requires_grad= True)\n",
    "#------------------------------------test grad--------------------------------------------#\n",
    "test_select = torch.index_select(test_theta,0,torch.tensor([0]))\n",
    "print(\"test_select.requires_grad:\",test_select.requires_grad)\n",
    "test_cos = torch.cos(test_select/2)\n",
    "print(\"test_cos.requires_grad:\",test_cos.requires_grad)\n",
    "\n",
    "# index = (torch.LongTensor([0]),torch.LongTensor([0]))#生成索引\n",
    "# value = torch.Tensor([test_select]) #生成要填充的值\n",
    "# mm = mm.index_put(index ,value)\n",
    "\n",
    "\n",
    "mm = vcm.get_ry_matrix(test_select)\n",
    "print(\"mm:\",mm)\n",
    "print(\"mm.requires_grad:\",mm.requires_grad)\n",
    "test_kron = torch.kron(mm, torch.tensor([[1,0],[0,1]])) \n",
    "print(\"test_kron.requires_grad:\",test_kron.requires_grad)\n",
    "#------------------------------------test grad--------------------------------------------#\n",
    "\n",
    "result = vcm.run(test_state,test_theta)\n",
    "print('probabilities :',result.t())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_state: tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], dtype=torch.float64)\n",
      "test_select.requires_grad: True\n",
      "test_cos.requires_grad: True\n",
      "mm: tensor([[ 0.8660, -0.5000],\n",
      "        [ 0.8660,  0.5000]], dtype=torch.float64, grad_fn=<IndexPutBackward>)\n",
      "mm.requires_grad: True\n",
      "test_kron.requires_grad: True\n",
      "probabilities : tensor([[0.0157, 0.0197, 0.0186, 0.0125]], dtype=torch.float64,\n",
      "       grad_fn=<TBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "xx= torch.tensor(10,  dtype=torch.float64,requires_grad=True)\n",
    "print(xx.grad)\n",
    "\n",
    "def func(ii):\n",
    "    print(\"1:\",ii.grad)\n",
    "    yy = torch.pow(ii,2)\n",
    "    yy.backward()\n",
    "    print(\"2:\",ii.grad)\n",
    "    print(\"3:\",yy.grad)\n",
    "\n",
    "    return yy\n",
    "\n",
    "\n",
    "zz = func(xx)\n",
    "\n",
    "print(\"9:\",xx.requires_grad)\n",
    "print(\"10:\",zz.requires_grad)\n",
    "\n",
    "print(\"4:\",zz)\n",
    "print(\"5:\",xx.grad)\n",
    "print(\"6:\",zz.grad)\n",
    "tt = torch.pow(xx,2)\n",
    "print(\"11:\",tt.requires_grad)\n",
    "\n",
    "tt.backward()\n",
    "print(\"7:\",xx.grad)\n",
    "print(\"8:\",tt.grad)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "1: None\n",
      "2: tensor(20., dtype=torch.float64)\n",
      "3: None\n",
      "9: True\n",
      "10: True\n",
      "4: tensor(100., dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "5: tensor(20., dtype=torch.float64)\n",
      "6: None\n",
      "11: True\n",
      "7: tensor(40., dtype=torch.float64)\n",
      "8: None\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-10-ee12d13594d8>:9: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(\"3:\",yy.grad)\n",
      "<ipython-input-10-ee12d13594d8>:21: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(\"6:\",zz.grad)\n",
      "<ipython-input-10-ee12d13594d8>:27: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(\"8:\",tt.grad)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "################ hzr on 12-30-2020 ###################\n",
    "#This block is for building the main net,including init and forward.\n",
    "######################################################\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,num_qubit,init_para):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        #init parameter\n",
    "        self.num_qubit = num_qubit\n",
    "        self.theta= Parameter(torch.tensor(init_para,  dtype=torch.float64,requires_grad=True))\n",
    "\n",
    "        #init  VClassicCircuitMatrix\n",
    "        self.vcm = VClassicCircuitMatrix(num_qubit)\n",
    "\n",
    "\n",
    "        #init circuit\n",
    "        self.simulator = qiskit.Aer.get_backend('aer_simulator')\n",
    "        self.shots = 10000\n",
    "        self.vqc = VQuantumCircuit(num_qubit, self.simulator,self.shots )\n",
    "\n",
    "\n",
    "\n",
    "        #init FC\n",
    "        self.fc = nn.Linear(num_qubit, 2)\n",
    "\n",
    "    def forward(self, x ,training=True,classic = True):\n",
    "        \n",
    "        if classic:\n",
    "            if not training: #test on classic \n",
    "                mstate = torch.zeros(int(math.pow(2,self.num_qubit )),1, dtype=torch.float64)\n",
    "                mstate = mstate.scatter(0,torch.tensor([[0]]),1.0)\n",
    "\n",
    "                # u matrix\n",
    "                mstate = torch.mm(x,mstate)\n",
    "                # variance circuit matrix\n",
    "                mstate = vcm.run(mstate,self.theta)\n",
    "                # FC \n",
    "                # mstate = self.fc(mstate.t().float())\n",
    "                #softmax\n",
    "                mstate = mstate.view(1,-1)\n",
    "                mstate = F.log_softmax(mstate,dim=-1)\n",
    "                return mstate\n",
    "\n",
    "            else: #train on classic\n",
    "                mstate = torch.zeros(int(math.pow(2,self.num_qubit )),1, dtype=torch.float64)\n",
    "                mstate = mstate.scatter(0,torch.tensor([[0]]),1.0)\n",
    "                # u matrix\n",
    "                mstate = torch.mm(x,mstate)\n",
    "                # variance circuit matrix\n",
    "                mstate = vcm.run(mstate,self.theta)\n",
    "\n",
    "                # FC \n",
    "                mstate = self.fc(mstate.t().float())\n",
    "                #softmax\n",
    "                mstate = mstate.view(1,-1)\n",
    "                mstate = F.log_softmax(mstate,dim=-1)\n",
    "\n",
    "                return mstate\n",
    "                \n",
    "        else:#only test on qubit\n",
    "            #init circuit\n",
    "            mcircuit = qiskit.QuantumCircuit(self.num_qubit)\n",
    "            # print('x 01:' ,x[0] )\n",
    "            mcircuit.append(UnitaryGate(x, label=\"Input\"),range(0,4))\n",
    "            self.vqc.build(mcircuit)\n",
    "            np_theta =  self.theta.detach().numpy()\n",
    "            mstate = self.vqc.run(mcircuit,np_theta)\n",
    "\n",
    "            mstate = torch.tensor(mstate)\n",
    "            # FC \n",
    "            mstate = self.fc(mstate.float())\n",
    "            #softmax\n",
    "            mstate = mstate.view(1,-1)\n",
    "            mstate = F.log_softmax(mstate,dim=-1)\n",
    "            return  mstate\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "################ hzr on 12-30-2020 ###################\n",
    "#This block is for training on classical computer\n",
    "######################################################\n",
    "model = Net(4,[np.pi/3,np.pi/4,np.pi/3,np.pi/9,np.pi,np.pi/4,np.pi/10,np.pi/2])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "for itor in model.parameters():\n",
    "    print(itor)\n",
    "loss_func = nn.NLLLoss() #\n",
    "\n",
    "epochs = 10\n",
    "loss_list = []\n",
    "#active batch_normal and drop out.\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Data prepare  \n",
    "        quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "        # Forward pass\n",
    "        output = model(quantum_matrix)\n",
    "        target = target.view(-1)\n",
    "        #print(\"output 01:\",output)\n",
    "        #print('target 01:',target)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # print(model.theta.grad)\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([1.0472, 0.7854, 1.0472, 0.3491, 3.1416, 0.7854, 0.3142, 1.5708],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0520,  0.0792, -0.4099, -0.3775],\n",
      "        [-0.2914,  0.3524, -0.1415,  0.3132]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3509,  0.1902], requires_grad=True)\n",
      "Training [10%]\tLoss: 0.7697\n",
      "Training [20%]\tLoss: 0.7548\n",
      "Training [30%]\tLoss: 0.7537\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a5a8daeb4980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mquantum_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqantum_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pre_pro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantum_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(\"output 01:\",output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qf/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c00672546798>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, training, classic)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mmstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# variance circuit matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mmstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# FC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c2f3095652fa>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state, thetas)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# print(\"state 01 :\", state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvqc_10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;31m#print(\"state 02 :\", state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c2f3095652fa>\u001b[0m in \u001b[0;36mvqc_10\u001b[0;34m(self, state, thetas)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#tail ry part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqf_ry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_qubits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_qubits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;31m# print(\"08:\",state.requires_grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c2f3095652fa>\u001b[0m in \u001b[0;36mqf_ry\u001b[0;34m(self, state, theta, index)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mselect_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mselect_mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ry_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                     \u001b[0mtemp_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;31m# print(\"02:\",temp_mat.requires_grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c2f3095652fa>\u001b[0m in \u001b[0;36mget_ry_matrix\u001b[0;34m(self, theta)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c2f3095652fa>\u001b[0m in \u001b[0;36mset_value\u001b[0;34m(self, mm, col, row, val)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#生成索引\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m#value = torch.Tensor(val) #生成要填充的值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "################ hzr on 12-30-2020 ###################\n",
    "#This block is for testing on classical computer\n",
    "######################################################\n",
    "model.eval()\n",
    "# 下面的代码不会更新梯度\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "        output = model(quantum_matrix,False,True)\n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100)\n",
    "        )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performance on test data:\n",
      "\tLoss: 0.7953\n",
      "\tAccuracy: 67.5%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "################ hzr on 12-30-2020 ###################\n",
    "#This block is for testing on quantum computer.\n",
    "######################################################\n",
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "        output = model(quantum_matrix,False,False)        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        print (\"model.theta:\",model.theta)\n",
    "\n",
    "        # output = model(quantum_matrix,False,True)        \n",
    "        # pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x216 with 6 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABxCAYAAAA6YcICAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABKq0lEQVR4nO29WWxcaZbn97+x7/tKBoMUd4qSUsrUUpWVldXZVZ01he5BuY3pfpgHT2OABgwYHsAPBmzDwMDw2B7ABho2DHsAA4YbaNgYGzBcXV1wd5Wrsiq7WqkspZSphRSTezBIxr7d2Hc/SOfoRoiblKKCYnw/gNBCMhg8997vO99Z/kfqdrsQCAQCgUAgGBZUg34DAoFAIBAIBG8S4fwIBAKBQCAYKoTzIxAIBAKBYKgQzo9AIBAIBIKhQjg/AoFAIBAIhgrh/AgEAoFAIBgq3grnR5Kk/02SpH/17O/flSTp6zf0c7uSJE2/iZ91VhG2HyzC/oNF2H9wCNsPlvNu/9fm/EiStC1JUlWSpJIkSYlnhrO8rtcnut3u33e73bkTvJ8/kyTpt6/75yte/7+TJGlNkqSiJEkrkiT9e6f1s07wXoTtB4iwv7B/3/sZGvsL24t7v+/9vDX2f92Rn3/c7XYtAN4FcB3Af97/BZIkaV7zzxwUZQD/GIAdwD8D8N9LkvT+AN+PsP1gEfYfLML+g0PYfrAI+78Cp5L26na7ewD+XwCXAA5j/QeSJK0BWHv2f38kSdJXkiTlJUm6LUnSFfp+SZKuSZJ0/5l3928BGBSf+z1JknYV/x6TJOn/liQpJUlSRpKk/1GSpAUA/wbAt595xPlnX6t/5jnuPPOS/40kSUbFa/3HkiTFJEnalyTpnx/zO/7Lbre70u12O91u93MAfw/g29/YeN8QYfvBIuw/WIT9B4ew/WAR9n95g72WDwDbAH7w7O9jAJYA/JfP/t0F8AsALgBGANcAJAHcAqDGUw9uG4AegA5ABMB/BEAL4J8AaAL4V89e6/cA7D77uxrAAwB/AcCMpxfrg2ef+zMAv+17j38B4K+fvQ8rgJ8C+G+efe4fAUjg6Y1jBvC/P3vf0yf43Y0AYgD+0euyp7D922F7YX9h/2G2v7C9uPffVvu/7otQApB/ZsT/CYBRcRF+X/G1/zNdIMX/fQ3gewA+BLAPQFJ87vYhF+HbAFIANAe8n56LAEDC05DZlOL/vg1g69nf/1cA/1rxudmXuAh/CeBvle95AA+AsP0AbC/sL+w/zPYXthf3/ttq/9edB/x3ut3u/3fI56KKv48D+GeSJP2Hiv/TARh59ovvdZ/9ds+IHPKaYwAi3W63dYL35gVgAnBPkiT6PwlPvVg8+9n3TvAze5Ak6b/FU6/1o773/KYRth8swv6DRdh/cAjbDxZh/1fgTba6K99gFMB/1e12HYoPU7fb/T/wNIw1KiksBSB8yGtGAYSlg4u5+g2SBlAFsKj4mfbu00IxPPu5Yyf4mYwkSf8FgB8B+Ljb7crHff0AEbYfLML+g0XYf3AI2w8WYf9DGJTOz/8C4N+XJOmW9BSzJEl/KEmSFcBnAFoA/oUkSVpJkv5dADcPeZ3f4anx/vWz1zBIkvSdZ59LAAhJkqQDgG6323n2c/9CkiQfAEiSNCpJ0g+fff3/CeDPJEm6KEmSCcC/POoXkCTpPwXwT/E035p5RTsMAmH7wSLsP1iE/QeHsP1gEfZX8iq5soM+oCi8OuBzL+Tw8LTQ6S6e5ipjAP4vANZnn7sO4EsARQD/9tnHC7nHZ/8OA/h/AGTw1Mv8H579vw7AzwBkAaSf/Z8BwH8NYBOADOAJgH+heK3/BEAcT3Of//yg9933O9XxNN9KH//Z67KnsP3bYXthf2H/Yba/sL24999W+0vPXlAgEAgEAoFgKHgrxlsIBAKBQCAQvC6E8yMQCAQCgWCoEM6PQCAQCASCoUI4PwKBQCAQCIYK4fwIBAKBQCAYKl5K4VmSJNEa9g3odrvS8V91MML235h0t9v1vuo3C/t/Y4T9B4hYewaKuPcHy4H2f+vG3BsMBkxNTSEYDEKlUkGtfqqSncvlsLm5iXw+j06ng3a7DdHGL1BwItl0wakh7C8YVsS9P1gOtP9b5/zY7XZ8/PHH+IM/+ANoNBro9XqoVCosLy/jL//yL7G8vIxms4lqtSqcH4FAIBAIBC/w1jk/Wq0WwWAQMzMz0Gq1MBgM0Gq1KJfLsFgs0Gg0aLfbkKRXjvIKBG8FKtXTkr3+e12hhioOAAKBQHAAb4XzI0kSTCYTDAYD3G437HY7rFYrNBoNtFotVCoVdDodtFotNBoNWq2WcH4E5xK1Wg2VSgWr1YqZmRn4fD5oNBpYrVZotVoUCgXE43FUq1VkMhns7e2h2WwO+m0LBALBmeKtcH5UKhVsNhvcbjcCgQA8Hg8cDgfUajUkSYIkSTAajewACedHcB6RJAkajQYajQY+nw8ff/wx3n33XVgsFoyMjMBsNmNrawuff/450uk0Hj9+jEwmI5wfgUAg6OOtcH4kSeIUFzk5Go0GKpXqhbC+cHrONsoNnP4NAJ1OB61WC51OpydtI+hFpVJBo9FwFDQYDMJmsyEUCsFisaDRaMDn80GSJFitVm4IEAgEAsFz3grnR61Ww+PxYGpqCoFAADabDZIkodlsIp/Po1KpYH9/H/l8HqVSCY1GA51OZ9BvW6CAHB6j0YirV69icXGR05QqlQr5fB4PHjzA7u4u6vU6CoUCGo3GoN/2mUKj0cDtdsPhcGB8fBwjIyMIBALQ6/XQarUAnjYELCwsYHR0FOl0GiaTCeVymTsgBQKBQPCWOT8zMzPwer3s/DQaDSQSCa5tyOVyKBaL6Ha7wvk5Y1C0wm6346OPPsKf/MmfwGg08sa9tbWFv/qrvwIAFItF1Go14fz0odFo4PF4EA6HMT4+jlAoxJIPVPzsdDpx6dIlNJtNbG5uwmQyQavVotlsCudHIBAInnHmnR+q6dHpdFz0TCmTbreLWq2GUqmESqUi0iZnELp+BoMBNpsNDocDTqcTLperx/nJ5XJ8bel7BE8he2i1WlgsFjidTtjt9p5nARCdXQKB4PVB+65Wq+VyBTpkHUe/1h7tye12m/9/0Fp8Z9r5UavVHDFwOp3w+/28aQJArVZDNBrF+vo6tre3USqVRMTnDKFWq6HVaqHVarG4uIirV6/C5XJhYWGBa7foYaKHodVqCedVgbLT0ePx4MaNG/jWt77Fz0M/hUKBn4VIJIJqtcqHAoFAIDgOOmzp9XrMzc1henoaRqMRIyMjcLvdx35/t9tFPp9HOp1Gs9ns+YjFYkilUmg0GsjlciiVSm/gNzqYM+/8aLVa6PV62O12+Hw+2O12GI1GSJKEer2Ovb09rK6uYn9/XwgbnjHUajV0Oh2MRiNmZ2fxwx/+EE6nE+FwGEajsecUoXR+Bn0iOEtQ1Mxut8Pr9eLatWv4/ve/zw0A/ciyjPX1daTTaezu7qJWq7FDKRAIBMchSRJUKhU7Px9++CGcTicuX76MyclJjsoftqZ0Oh3s7+9jdXUVtVoNtVoN1WoV1WoVjx8/xurqKsrlMur1unB+DoLa1x0OB+v6mM1mGAwGtFotlEolFItFFAoFFAoFTnsJBoskSSxBYLVa4XQ6YbFY4PF4YLPZYLFYoNPpIEkSut0uGo0Gms0mSqUS1/k0m82hj1TQ6Uuj0cBiscDlcsHlcsFsNkOv1/eEoFutFiqVCprNJjKZDNLpNDKZDEqlEjuSwvl5OXQ6HUcm9Xo99Ho9X5OjUrIHCU4CQLPZRKPRQLvdRrVaRa1WO9X3f56h50KtVkOtVnP6lzIFkiRx2qXT6aBSqaBSqYiSiBNC+nlGo5HXcIfDAavVyoEH4HDnp9vtwmQyweFwsPNDndp+vx/FYhHlchnVapXTYPRsUNfvm7hGZ9b5UavVmJmZwXvvvQen04lbt25hamoKwNM5Xjs7O9jd3cWjR4/w8OFDVKtVVCqVAb9rgV6vh9VqhU6nw8WLF/Gtb30LDocDCwsLuHDhAoxGY0/kLhKJIJFIYHt7G1tbW9jf3+eNYpihBchkMuHixYu4evUqFzuT8wg8PWWl02l89dVXSKVSiEajePDgAXK5HGKxGGq1mljsXxKVSoVAIICxsTGYzWbMzMxgYmKCo206ne7Y1yDnHgDa7Tb29/cRjUZRKpXw6NEjrKysiAL0V0Sn08Hj8cBiscDtdmNubg4ulwtWqxV+vx96vR6lUgmFQgG1Wg3379/H3bt3+YAgdK8OR5Ik2Gw21tKbn5/H5cuXudbwpK/hcDgwOTnJkXyK6k9MTODWrVsolUpYWlriFH00GkUul0OtVkM2m30jh4Mz6/yoVCqMjo7ixo0bcLvdmJ+fx+joKKrVKnZ2drC5ucl/bm1todPpDH204Cyg0WhgNpthNpsxPT2Njz76CF6vF263Gx6Pp0d3ptlsIpFIYGNjAzs7O4jFYkin0wN892cHShmaTCZMTEzgvffe49QvRdboJFsoFLC0tMTO49LSEmRZRrVaHXon8lVQqVRwOp2YmpqC0+nEd77zHbz33nswGAx8+j2Mg6JCzWYTy8vLePjwIUfmVldXhfPzimg0GjidTrjdboyNjeH9999HKBSC1+vF9PQ0zGYzMpkM4vE4isUi6vU6lpeXObIgnJ/DkSQJZrMZHo8HXq8XY2NjmJ6e7jlwAcc3V9Ae0P+1U1NTaLfbKBaLcDgc8Pl8yGazHM0rFouQZfl0frk+zpzzQ2FlZb2I0WjkivNOp4NyuYxMJsOevQhnnh20Wi2nt+x2O0wmU8/1A8Bt1+VyGdlsFvF4HOl0WqQCniFJEqcK7XY7/0kjLCRJQqvV4oU9nU4jnU4jlUohn8+jVquxjcUzcTQkGknpLbPZDJ1Oh7GxMYyOjnLI32AwcLrxKOHIg9JedCBwu91Qq9WYmJhAMplEpVJBoVBgeQ6R7n0K7QEqlQpGoxEGgwFqtZpTviaTCaFQCA6HA8FgkEcemc1maLVaqNVq/rpOp8PzH2k0jOBwyAmhJgtab5T3NaUUlc7kQfctfY8ybaxSqbiLjNY2rVaLcDgMvV6PTCYDWZb59ZvN5qmtYWfO+aEiZ6PRCLvdzh1eJpOJtX22t7dx7949ZLNZ5PN5dn4Eg8dms2F2dhZutxtTU1MIBoNwOBxcP9HpdCDLMncD3Lt3D3fu3EGhUBBRn2eo1WpMTU3h5s2bcDqduHHjBubn53lzBoByuYzl5WXs7+/zSIvt7W3UajUUi0VROH5C9Ho935/j4+NYWFiA1WrFwsICFhcXYTKZ4HQ6YbPZepTJD+Mge1MazWQyoV6vIxQK4aOPPkI2m8WvfvUrPHz4ELVaDblcTqTu8TSyo9PpoNfrMTk5ibGxMdhsNly8eBHhcBharRZWq5UdHJ/PB5PJxG3ZALi+xGq1cq1co9FAo9HoSUkKeqGDVyAQgNvthtlsfsGhb7VakGWZC5kzmQyq1eoLr0P6Y6OjowiFQj1TGYxGI6anpxEIBFCr1bC4uIhSqYSNjQ2o1WpsbW2hWCwinU6fWvT6zDk/KpUKWq2Woz5Wq5WLZIGnhs9kMohEIqzvI27ks4PRaITX60UgEGBBSovFwp/vdDqoVqsoFArIZDLY2dnB6uoq6vU6yuXyAN/52UGlUsHj8WB+fh4ulwsTExPw+/09EYd6vY54PI6NjQ1sb29je3sbkUhkgO/67YROuUajEaOjo7h06RJcLhfm5uZw8eLFF8L9wKvpKVmtVlitVnS7XV7w4/E4otEoIpEIh/wFzw/ABoMBfr8fMzMzcLvdeP/993H58mWoVCqO4lDkrj8lQxIbFHXT6/XQ6XRi3MsJ0Ov1sNlssNlsHLFR0ul0+JBVKpUQi8Ve6Nqi7A0NXVZGhkizzOPxwOPxoN1uIxQKodFowGQy4f79+8jn8+h2u8jlcqf2e54558flciEcDsNms2FsbAwWiwUGg4HzhLIsQ5ZllEollEolkb89A9AGQgM3x8bGOBzdf1Jut9uIxWJYWVnhVE29XhcjSfD8xEuCkC6XC06ns6fDgqI5tVoN6XSa66REbc/JUalUHIn0+XyYn5+HzWbD9PQ0RkZG+MBFIXolpJlEHXb1ep1TBaSNYjabj9xkaXPX6XQwm82w2WwAcGxU6TxAawWlU8jGRqMRFouFdd1o3Z+fn8eFCxdgs9lgt9vZ6aG6N3oWKBVTr9c5pS7LMsrlMhfVkuyD4HC63S5KpRLi8ThqtRq2t7fh9XqhVqtRr9fRbDZRrVaRTqc5+JBMJl8oWaBrq1arUSqVkMlkoNPp4HK5YLPZoNPpYLFYeG1TOrx2ux0OhwONRuNUndUz9bSpVCrMzs7ixz/+MXw+H2ZmZjA6Ogq1Wo18Po9EIoFYLIadnR3s7OzwhRAMFpPJxA7r1atX8b3vfQ+hUIhPXErq9Tru3r2Ln/zkJ5BlGXt7e+zlD/vCRHUhJpMJk5OTmJubg91uh9Pp5IWeFqBMJoPl5WXcuXMHxWJRRA1eAp1OB6fTCb1ejytXruDHP/4x1/f4/X6OOvc7IxS1JFX5ra0tZDKZHuff6/ViamqK05P90KlXrVbDYrHwYSGdTiORSLyJX3+gmEwmXLhwgevXyBZjY2OYnZ2FyWSC1WqFw+GAXq/nWXZUS6iUHACAarWKfD7PmjHpdBrVahWbm5t4+PAhZFnG1tYWYrEYp71EpuBwSKOnUqnwXMC9vT10Oh2kUikUCgVUq1WkUilOrx/kVJJTSyKtJpMJZrMZN27cwDvvvAObzYa5uTmEw2Gut9NqtXA4HAiHw2i321Cr1dje3j613/VMOT+SJMHpdGJ2dhYjIyPw+XywWCy8MZZKJciyzIs9FVwJBotGo4HNZoPb7YbX68Xo6CjGxsb488rFptVqIZlM4smTJ6z1IKIWT6FN1GKxwGaz9YyxoGJ/KjCkXHs8HufImeBkKIubPR4PZmdnMTExwdGHw4piaR2q1+uoVCoceaOxI1SncpwTT+ka6uazWCyo1WpDEfmheh0qdKUi8vHxcVy8eJEdH4oaG41GmEymI1+Trocsy0in0yiXy9ja2sKDBw+Qz+c5AiRq4I6HIj/1eh0GgwEul4szL9FoFJlMBrVaDclk8kRzNJXaWBaLBVarFT6fD7VaDeFwGN1ut6c+iKRSHA7HsRHUb8qZeNqouNlgMHChlcPh4JbSVquFeDyO5eVlJBIJ5HI5UeQ8YJSzXqhGIhQKYWpqikOZdH0kSerRelCr1TAajdzhUq/XB/zbDB4ShRwbG4PD4YDX6+VuC6WYYSaTQSaTwf7+PvL5PKrVqugSeknIWadUCs2YU9aOtFotTsXSBlqr1RCLxVhAMhKJcOTHaDRCrVZjZ2cH8XgcJpMJHo8HwWCQ01sHFY+eN6joWHmapwgOacVMT0/D6XRyR69arebDLjmger2ea0aAp5syjWqh0QiUdqTIT7FYRCqVYs03SqFQKg0A1yCSRAQdvuhZEjxX2280Gkin09Dr9Wi325zqIiHak3RYKz+v7PCl5qWDvp7Syqe9x58J58dut2N+fp5FlcbGxlgThsTwVlZW8Itf/AK5XA67u7vC+Rkw1IZKbcEfffQRFhcX4XA4uIZB6QDRibler0Or1cLlckGj0aBarYpCZzy1ld/vx/Xr1+HxeDA5Ocl1D7RhUqfj6uoqdnd3EYvFUCgUjj19CXrR6/Xw+/3weDwIBAKw2+09NT7KgcnVahVLS0tYW1uDLMt49OgRIpEIGo0GSw0oDwK04ep0Oly7dg0fffQRXC4XRkdHEQ6Hz3V0R6VScQ0TPePUbXX9+nWEw2FYLBaEQiG2N9mNat2oToTWfnL82+0213vm83k8evQI+/v7HAmla1YoFNBut1Gr1ViVmOqB9Ho9FhYWMD09jUajgfX1dU67Ly8vC+fnGUqlZXLmKepJ6ssvMy+QnKRWq8X792GjLZQ/57SVns/Ek0g9/xTmJ40BpRcoyzLi8ThkWRYdXmcAWrjoVOvz+TA6OsonaII2E1qkms0mbxYvMyV4GNDr9Tzxnoo/lfZpt9solUos8SAKOF8N5War0+l6tHvoUNVsNlGr1VCpVFgtO5/PIxKJYGNjg515sj99PxVtUjdLPp+HVqsdCqVt0m+hSBpF1jweD8bGxrgWKhAIcBSMnJzjUF4T0nmLx+M9X0PpL7om/fWGRqMRwWAQExMTvPlSsfRJVLuHCXJYaDTIN4VSX/TcHBat7o/8nCZnwvmxWq3caTEyMgKtVotOp4N4PI69vT3kcjmsr68jHo+LuTgDhIZs0tiFUCgEp9OJyclJFoJTpmmA5yHU/f19bG5uIpfLYW1tjTsEhj3lpZzhRbPsXC5XT4cXOY3FYhF7e3tYW1vjELTg5anVatjb20O5XIbVasXy8jJyuRynVFqtFhKJBBd+bm5uIhKJ8KZL6TDl4tzpdDi9S58noclhicpptVrMzMzg6tWrMBqN7MTb7XZcuHABHo+HW86VBbEnhdJkFD2iFJvZbIZGo+GN9TDlbNJyGh0d5VlSDocDsViMo6itVotnTgm+GRS5c7lcnPa8fv06rly5wql94Llj2263USgUsLOzg42NDezv759qLeOZcH6cTieuXr2KyclJ+Hw+zjFubm7i9u3byGaz+PLLLxGNRtFsNsVpd0CQyqrFYoHD4cDly5cRCoUQDofh8/n4NNc/+K7dbmNrawu/+tWvkM1m8ejRI+zt7bEQ3zCjjIJZLBZ4vV74fD5YrVYWBKvX66hWq8jlctjY2MCXX37Js4sELw8VxNIhy+PxwOfzoVqtck3D2toaVlZWUK1WWc+EFGdJXkMZyaGTMoXt1Wo1R+bexCn2LKDX63H9+nX86Z/+Kae/TCYTKy5TJPOk0R4lJCNAtVXT09MYHR2F2WxGMBiE2WzmqMFhETaKTGm1WrTbbXg8Hr4X1tfXWWVerEvfHHJ8NBoNRkdHceXKFTidTnzwwQe4efMmyxnQgYGGWqfTaaysrODBgweoVCqnGugYqPNDGyXNzLHZbD2dLdVqFdlslgsMa7WauCkHCLXp0o1rt9vhcrlgt9s54qN0fOhDWeimLJoT17JXDIyKQ6nYE3geBqaNt1wuo1gscvGn4OUhkbZGowFZlpHNZqFWq1GpVFAsFtFoNFhWg6ZSnzRCqdQ3UQrxHbTZKzfr85ASU6lU3M1jsVhgNpuP7dQ6KUq7KqM9ys6gl6HVavFhjSQ5yDk770XpbwLlumaxWOByuTgC5HK5WOKA9gc64JXLZdbwO23tt4E5P1TnQ8WHbrcbbrcbWq2WO1gSiQS2tra4xuE8LBBvMzqdDuFwGBMTE/B4PLh27RrGx8e5YLQfUm2uVqtIJBI8uZdaJAVgeX5SGKYhsGazmSM/tDhQDUqhUOD0jODlIZt2Oh0kk0ncv38fZrOZa0parRbS6TRPAT/OSacTrlqths1mg9/vh8lkwuLiIiYnJ+F2u+F0OjkdrJQsKJVKyOfzKBaLb71gK0VWLBYLCxm+ztfW6/VQqVRot9vcfk3prlKpxDWIR9URUtdpvV5HKpVCOp1GNBpFIpFANpsVz9Vrwmaz8diRd955B++//z7sdjvGxsb4oEzPVjabxRdffIFIJILt7W0+dJx2xHRgzo9er+fwfjAYhNfrhcvlYg+wUqnwxO9cLsddLYLBQTnzd999F16vF9evX8fExASPJOmnVqshm82iVCphf38fOzs7vNCLa/kUqp2ihYG6kOgESsV/jUYD9XodsixzbYKw4auhFNSkTa8/YkmbJP3fUVBbt0ajgd/vx5UrV+ByuXDlyhVMT0/3zLYD0HNNy+Uy8vk8CoXCuXB+SD/pdUV8COWQU+D5NSEHslwuszDlcTpNpJNFB7KdnR0kk0lkMhnROfkakCQJdruda0Hfe+89fO9734PFYuGRIxTJJvmITz75BL/73e9Y+LZarZ76+jYw54e0Xmw2W8803k6ng0qlgnK5zDk/ZVfFaUIL4EGzfIZ5o6HwPS1sdrud8/m0GBFkJ6pVofbUYrHIqQYhNvYcihrQ/X/Q1HBlCpE25pPYTzk+gNIwh0EbA234w7IBKJ2cl4XWCbVazZ1jyhA/pfGVM6Uo5Uat9LTGnYc0MD3z5XL50NobZfu6sqWdNMAAHFm3o3wd6h6iCMFx96xSpLJarUKWZT5YH1UoLTgYuv+V15PWMereJukTmp+nTONTiiufz/MHRVvfxP4wMOfHZrPh8uXLGBsbw9zcHOdfk8kkHjx4gFwuh6+//pojB/V6/dQMQg8gdRNoNJoXChipJXLYUKvVXNfj9/tx8eJFvPPOO1zz0w+FlFutFlZXV/Hpp58im83i4cOH3J4t1IjfDOSokuYKaWcdRKVSwe7uLvL5PJrNZk/LsOBFKMWjVqvhcDh4/tTMzAy++93vchE11aYo15Hl5WWsrq4ik8ngq6++wvb2Nm/IbzONRgOPHz/GX//1X0On0x24XpODSKMMgsEgDAYD0uk09vb2OL171HpLUgU0tHRkZIQP0Af9THJwm80m4vE4EokE8vk8fvvb3+LRo0coFApDMVrkdUG1nxTxp4ib1+vFhQsXYLFYMD4+jvn5eVitVkxNTfH9QNdWlmV88cUXWF1dRTKZ5FmP5My+CQbm/FitVp6cHAgEYDKZIEkS0uk0Hjx4gFQqxSmv03R8lIV0ygnAdJIgZdFhHbypUqk4JRMIBDA7O4vFxUWOVvRDraL1eh0bGxv49a9/jUQigXQ6DVmWxYb6BjEajfB6vTCZTBgfH8fU1NShdRi5XK6nvuhNRVvfVmgDpjlhU1NT8Pv9WFhYwK1bt+D3+/lABTyXK6hWq/j666/x61//Gvl8HktLS4hGo+dCtLXRaGBlZYW73Q7CZDLxPTk6OspF0pubm3jw4AF3MRYKhUPXW+o61Wq1GBkZ4fb5w1LBVF9Vr9e5jjSZTOLzzz/HnTt3vlH0bxihDlVqfqE5edPT0/jggw9Y12lubq5HPZ2cn2KxiGQyibt37+LTTz9FqVRisUng+DTz62Jgzg91eZlMJh5WB4CnJZfLZXY4TsMY1IWhVqthtVq5QI/GapDz0+l0uMZCOT34vKPsPnK5XPD5fPB6vXySPaxdtVarIZFI8OwjahMeVufxVVDalZxvqgs5ruuIpPw1Gg3cbje3AQcCAZ6ndNj3BQIB1tqgzkpyiIYZSrHQSZc+aK3w+/3wer3weDw8pkcp9KlMAReLReRyOb6e56mDVXmvHub8kCI2DYLd29uDxWJBPB5HKpXi+h1Zllk7iT6UgpSkNWY0GnsGpB5UskBzv2gaeTKZ5J8lBp0ejVKPSTmTjjSc9Ho9a7wFAgG4XC5W1jYYDNy5SqlNEitOJpOc1XmTqS4lAy14drlc8Pv9LIcOgCfGJhIJlEqlUzEIPXxGoxFmsxnvvPMOjxMYGxuD0+nsUZlcWlrCz3/+cyQSCW41Pi8L1kGoVCqW/rdYLLhx4wauXr0Ku92O8fHxI1tCt7e38ZOf/AR7e3vY2trCzs4OKpWKWGRekVarhfX1ddy7dw/JZBKxWOxIO7rdbszPz8Nms2F2dhbvvvsuD0p1OByHFoNWKhXMzMwgn89ja2sLv/zlLxGJRFgJd1ijQLTpkiI0deSRfWn9Gh8fZxv3t113Oh3s7OywmOK9e/ewtLSEarV6rrSa2u02kskkqtXqoe3iSufcZDLhzp070Gq1KBQKyGazaDabPDsKABfIku2phmR2dhY+nw9Op5Pn4R1UL9dut7GxsYH79+9DlmUsLy9jY2MD5XIZ0WhUrElHQAEK5fUyGAzweDz44IMPOJJsNpuh0+m409FgMMBsNrMmE605tVoNv/vd7/DJJ58gn89jZWUFsVhsYPMdB+b8kEYDTY2lnn8aVEeD604jWqDsSvB4PLh06RKuX78Oh8OBubk5+P3+HoVWl8uFpaUlTr+dd2VdSZJgs9lYwfny5cu4desWKxAfVTgbj8fxm9/8Bl9//TUqlQqLwwmO5yCHstVqYW9vj+vgKD11GHa7HTMzM/B6vbh27Ro+/PBD2Gy2niGRB9FsNjE5OYlqtYpHjx5hZWUF2WwWKpXqtcjbv81QeN9qtbLUg9frxc2bNzExMcHTr2kQc/81pJb6x48fI5vN4uuvv0YkEnnru7v6oSGwlL44iH7b9Ec5+z9Hmy9FL2kINl0HWsOVDqfydTqdDvb39/HFF18gm81iaWmJx5MIx+doyPGnFKPT6YTVasXExAR+7/d+Dzdu3OBif1pbDmsaAp6uMSsrK/j5z3/OQYRBri0DFzlU/gmcbr6Pugs0Gg2cTid8Ph/rC1GoTim93u12oVKpYLFYEAwG0Wg0IEkSstnsuT8JK4XaKP2lbNc9TLTNYrFgYmKCpyan02kW5yuXy2LBeUUOE8Oj/DulEbxeLwKBAPx+P7dY90fq6HRNaRz6PCkek9CiwWDgWWzDAKV6qa2abEq6NWazGWNjYxgdHYXT6eRurv6J8AdBJ+NWq8VpdroO530tUdJ//yr/reweoi5ISieazWaEw2GMjIzwDEiqJznqMEY/g7qM6BqTjMRh86WGcZ2i9JbJZOIyENId02q1PHdzdHSUszW0n77MjMazsp6cifEWp43yoprNZpjNZly7dg2XL1+Gw+HAtWvXMD09zV4ufQ9t/mNjY/j444+RyWRw+/Zt7O3tnfv5YiRJTydeh8MBvV7PC8dBSJKE2dlZ/Pmf/zmKxSI2Nzfx6NEjyLKMJ0+e4PHjx6LT6wgOqm87aiGmTcLhcGBmZgZOpxOXLl3C97//fQQCAW4xVTo+7XabI0gajQYejwc2mw0qlYrr7xwOBzweD/x+P1QqFdLp9FDMYLNYLPD5fDAYDJiamsLs7CwMBgOnWgwGA0ZGRuB2u9lONL7hqKiaSqWCz+fD4uIiR7ULhQLK5TKSySRyudwb/C3PJuTs9Ed7PvzwQ9y8eRNmsxmjo6PweDxcZE5plePEFGkt12q1PEKGis/7m2moK0/pMA0DyoPu9PQ0d2rNz89jenoaWq2WR4OYTCaEw2GexnBSZ0Y5+Lbdbg88ojwUzg/QG8KzWq0IhUK4ePEi17FQd4YS8madTicWFhZQKpUQjUaHYgKwcsHQ6/UnVmz1+/2cNnz8+DG63S4ymQwymcyxJzTBU15Gw4eiFCMjIwgEApiamsLc3BwCgcALr0eLOU0q12q1sFqt/HpUOGo0GmGxWGC1WlEqlV7qVPc2Q50rJpMJ09PTuH79OsxmMxdxUqEn2eykSJLEYq4mk4mFLHU63bmq+fkmKLtuaYMk6YD333+f01s2m+2F7zvJa9N6Rvc2TRXvT8lTkf9JdIPOE8r13uv1YnZ2Fk6nkweR0qFXOYj5VSI4dFB42WjRaXDunR+TyQSbzQadToeRkRGEw2FYrVZMTk5yOFXZbXYQJExGYzfOe0hUOZdFWbCmRDmXiBaRTqfDGyg9IGazGbVajaXpKZ0oeAqlrCwWS88kd+UIBFJ3VgqxabVaHoMxOjqKqakpBINBBAIBds5JzZYk5ElHg4T1DAbDUEbi6P6mlDbVHQYCAYyPj8NsNvMIF4p8UlfRQQ68sjlCCW0myoMXAITDYciyjHw+z7ompK103uqATorT6cTo6Cj0ej3sdjscDgc3oJjNZq4LfVlUKhWcTidmZmZQKpXg8/mQz+fRaDRQrVZfiODX63XuqpRlGclk8txGPSnVrVaruTPUZDJhfn6eC/jtdntP2rx/aLWyNpZkTtrtNqeNlTPu1Go1y0HQuCrqdhyE8O25dn4kSYLP58PCwgLsdjuuX7+OW7du8VRyq9UKjUbDhYqH0Wg0UCgUkM/nUSqVhuJEQB0Why065BDS4k2ieGazGU6nk+3q9Xqh1Wp7csTDdqo6Cr1ez511dru9RxeG1HJpo6Shm8BTnax33nkHExMTGB0dxYcffshTrikyUavVkM/nUa1W8dlnn+E3v/kNWq0WQqEQgsEgHA4HAoEAut3umcnDvwmUOjHT09P48MMP4fF4EAwGMTExwVEHKu6nkyo59P20Wi3IsvyCI0nXgpwsvV6PVqsFu92Oa9euIZPJ4O/+7u9w9+5dFItFbG9vI5vNvikznBlUKhWmp6fxox/9CC6XCyMjI6zf4/F44HQ6j00tHoZarcbCwgICgQA7mcqoT/86lMlksL6+jlwuh5WVFXzyySdIpVKv61c9U5Cjqdfr8e677+Ljjz9m+5MjarFYoNPpXnB86OCrdBbz+Tz29/dRq9UQDAYxOTnJewjVxl27dg0OhwPJZBI//elP+bkZhON/rp0fABxmdrvd3Pr7snNnSONnWCI/QG/NEw3Y7M+Nk2oq5c+bzSY0Gg0vKBTVaDQaPYXkgudQdKxf74pOUuQEHRT58Xq9CIfDGBsbw4ULFzA6OtpjX7pvqa334cOHvPDTqWwYIz904lUKFNKGe+HCBXb4T7rZdjodNBqNnigCpRE7nU6PPhAAViWmDrCNjQ3WTxlWKDoTCAQQCoVYUuObIkkSnE4nnE7nib4+lUpBq9UilUpBluVzfU2ortNoNCIQCODixYvw+Xw8ff2otBQ5QMq9sVAoIB6Po1KpQK/XY2RkpKcmS61Ww+fzcfG/2+1m5edBpMDOlPNDGy51m7xqXtFgMMBms0Gv12NychKLi4usKUQnawq1KUPg/ZB3Wy6XEYvFWJjpvHZnKGt8RkZGcPHiRTidTh60qaRer2N/f5+ntO/t7aFUKmFychLf/va3+aGiG9zn83ExqSzLovPrGQaDAT6fjzVMSPJBKfZJ828oukbXicZXmM1mvq9pdlG320UqlcL29jaKxSLi8TjXl1CKhwp2hw0q5HS73Zibm8PY2Bi8Xi+sViu63S6azSaKxSKq1SparRYLdR52v9IA337nx+/3c2Go2WyGxWLpSR9QfQvN/xp0DcRZ4aAuYJoFRWmSWq2GZrPJBbg00V3p1NNzoFTrpwMFSa3QZAFCr9ezVk0+n8e7776LYDCIdDqN/f39c3VY0Ov1fN97vV7Y7XaOUPZD4qeUMk+lUtyqnkqleFZaLBZDo9FAo9GA1Wrl6e6U0ieJGWqicbvdqFQqfLh7k5wp5wcAL+p0EV7F+aFCOZvNhlu3buGHP/wht6bS/Bd6OKi7gDx8Zc0F5fEzmQweP36Mvb09bG9vn6sHQAmFOS0WCxYXF/Hxxx+zaFt/6qtcLmN5eRnr6+uIxWL44osvkEgk8IMf/ABzc3M9gx2r1SpmZ2cxOzuLbDaLSCSCSqUinB881eWZnp7G1NRUjwJzrVZDLpdDNptlcUNazDUaDfR6PdxuNwKBADuYADj83Gg0sLGxgXv37iGbzWJ5eRnJZBJ6vR42mw1zc3O8AA1bNM7r9fJ96vf7ea2gVEitVsPu7i4LdG5sbCASiRyaqj3I+VGpVJibm8P169d5PMz4+Dg7O3S4MxqNsFqtqNVqryXS8TajTK0cpHdFyswkhFssFlmGhEoZRkdHoVar+Zo0m012eDqdDorFIsrlMgwGA2ZmZtj5p59nsVgwPT2NdrsNp9MJs9mMTCaDu3fv4uc///m5WvutVisuXLgAj8eDCxcuwO/3c4qx3xFvNBqIRqPY3d1FJpPBvXv3EI1GOTBAtT5kn/39fQCAy+XCpUuX4PV6eX+hAaehUAgTExOc0i8Wi2/09z9zTxudamlo4KsszNTFomzZdbvd3FFAixxpmFDo7SBxMjpJ0wTg0xJePAso5xXRIFPl8FKls9JsNpHP55FIJBCLxbC1tYX9/X1cunSJPXil7Dx1D1EKTPAU0pGx2WwwGo2cYqRaKjpF1et1NBoN1uXR6XQcXaNicuDpPUtDMovFItLpNEfn6vU6P19Wq5UHTB6EcrDveYMcx5GREXbSjUYj27jRaKBcLrP8Ph16DhPrJEe1P/JDAx5brRacTieazSavP8ruJnpOhjnyQ/c8ReRbrVbPekwF4RR9SKfTPCjZZDKh2+1Cp9NxVIeuoTJ1TKOKisUiTCYTb9h0Laimy2KxAAA8Hg9CoRDMZjM2Nze5eP28PBOUcrdardz4Q+uBco9TRkOz2SxSqRSi0SjW19dRqVQ41UWoVCqMjIwgk8lAkiRUq1W2GZVS0NplMplQq9UG0gl8ppwfChXfvHkT2WwWWq0WmUyGw2In9brpotKiRk4U1ac0m00kEgmkUinodDpudVfSbDYhyzLq9TpSqRT29/d5+Np5VSw2mUzw+Xyw2+2w2WwHOoM0lT2dTmNrawsrKyvI5XJHTqSm6JrL5UKn0+npahK8iCRJrGTb6XQ4LdZut+HxeFiqYXp6moucyaFMJpO4ffs20uk0dnZ28OTJE5TLZeTzeW4hJuFDZVpZmUqgaFM8HueOpPNEqVTC2toa2u02LBYLNjY2oNPpuD6q2WwiGo1ie3sbtVoNsVgM8Xj80E3voE4tSZIQjUZx7949WCwW1Ot1brP2+/08Cdvn82FqagoGgwGPHz9+UyY4U3S7Xezv7+P27duw2+1cc6LcEBuNBk9jr9frfBA1mUzY2NiAwWBgnSa9Xo9yuYxCodDjTLXbbVSrVVSrVej1eqytrXHaZ3Jyske/iTbnYDAIm82G6elpLCwsIJ1OI5PJIJ1On6t9gNJXJEZLQ6hp1lqpVML6+jr29vYgyzK2t7f5WvSvD91ulwvGnU4nQqHQC7ZSpn2P0o47Tc6c80MtdsViEa1WC5ubmyyZftJiY+oucjqdsFgsvMhTBKdWq2FtbQ3r6+uwWCwwm80v6Pw0Gg1kMhkUi0Xs7u5ia2uLT3/nbTMAnmuRhMNhLhDs98YpbCzLMnZ3d7G0tIQvvviCFZyPe22fzweNRoPNzU3h/BwBCXJSVCAcDmN6ehoqlQqzs7MIhULweDzc7UUFtQCws7ODn/70p1hfX0exWEQmk0Gr1eLuPZppp1R+Bp7n9MvlMhKJBHZ3dxGJRNghOk/k83ncv38fkUiEo2hqtRrVapXnmCUSCSQSCY4cHDUOQdn9oqRcLmN7exsGgwH1ep03doo86XQ6hEIhbgz4h3/4hzfx6585ut0uNjY2kE6nWYG5PyJJnUXUVk3XhKII9AxQqQRFTvsjmOQMkT4WXYM//MM/xKVLl1jPSafTsVPUbrdRKpV4+Orjx4/P1SG42+3yPqfT6fjZr1ar2N3d5Q6u/f19ZDIZPiiRffvt0O12kUgkUKvVuL6uf8+khgCaHDBUkR8KpTUaDR53DzwXGiMPnASpKpUKh4yPc4CU6sTK061Sk4ZCodSRoXxf9N4qlQoXOx6kCXHe6C8274dC01ScRvNZjpt0rxQY6594PeyQ7ehkSlC3EUVryIl3uVzwer08VdlgMPS8Xr1eRyaT4dqIarXK+ks0yJcWG2VamfQ66vU6d2+Q43Pe0rwUwgee25nC8+T8ZDIZZLPZb7TBkf11Oh2KxSJqtRoX7FKHC0UsqGh3WKHNVCneqYQ2WbId/UlrC30fXUtlkTN9P/1JaUdKyatUKhQKBVSrVRgMBv4+uj6dTofTQ/V6nZWN33aUBeC1Wg2FQgFarZZTW5TSisViXOR83GxBotFooFgsotvtcnrxrElqDOxpy+fzuHfvHmRZxvj4ON577z3udiFdgcXFRfzRH/0RcrkcHjx4gCdPnqBerx87EM1oNGJ0dBRjY2PcskeV5lSEOzMzw16+1+vltJgsy+zx/va3v8Xe3h42NjbO/TDTk0DqwJQ3p5DnSWpDTCYTXC4Xut3uuVk8XgfFYhEbGxtoNBqYmJjg6dTKk6zb7UY4HIZer8fs7CwmJydhMpmOVRp2uVwIh8Ms8BkKhWC1WrG4uMjCnwBY8C2bzSKbzfakmgchPnbaNBoNLphVFtlSjVWn00G5XD51p49GipDm2EkU1M8rygPUYSMTlPPtDnJm+v+/X5qj/086cDQajQM1f5TQezrIMXtbyefzePLkCcxmMzY2NrC0tAS1Wo1sNotcLodGo4FsNsspsFqtduK1gOplSQalWCxyo4Zer0en00GpVOLarUEUkg/M+cnlcvj888+xubmJGzduYG5ujp0fKry9fPkyRkZGkM/nodfrOeVCbcCHYbFYEA6HMTk5Cb/fz4sKhdgA8DwkAPz5ZrPJBaJPnjzBL37xC6ysrHAb37BD81jy+TwKhQKf1o6D0jhutxsAXmgvHWZkWcbq6iqfumZnZwE8n9tFzvmFCxdgNBoxPz+P2dlZjtwcBC1QHo8Hs7OzHHq+fPkyT8d2OBwAng85rVQqyGQyiMfjSCaTKJVKL7XYvU3U63UkEomee7B/8zxJhPmbolKpuJOSOlGHFXJGXoVXdVLp+yhFdtjwYOD5AOFXbcI5i1AjBK01FCQgR7R/zMfL2JmcH1pbCoUC1Go17HY7dDodpxIzmcyBAqFvgoE5P61WC+VyGVqtlkPCNGmaFnWK1ABPRbBcLhe0Wm2P2OBBJ1NKr/QP4lSeKMgJopudTgDFYhG5XI43eFmWOc8sAKcMT3JS6j95HVYbMcxQ/rxSqaDRaLxgG7Va3TNigbq7DluAqVtFqaNhtVrhdrt5GGR/V5myOyyfz6NcLh/4Xs4LB9UpnAbKVIzygyIHSqHQ8xhhe1s4KEI0DJA452mgjJQdFsmjNOag9oSBOT+1Wg3xeByyLMPv92NlZQWVSgV2ux1ut5u9bAoH37hxA06nk1tPU6kU1zf0dxotLi7C5/PB4XDwQt8PebQknkXV7n//93+PtbW1nlznsC1M/Xobyt+dPHkS3Dvudeh7S6USF8wdJRg3bFCqVavVHiijoNFoWGpeo9GwZMNhhEIh/OhHP0IqlWKRPaPRCI/Hw6NGqNuu2WwilUohnU4jHo/j008/xerqKrLZLPL5/Cn/5ucfqtUymUwIBoMIhUJcxyhJEhqNBvb39xGPx7G5ufnGdU4EgtNCq9VyM5HdbuePV9XuOw0G5vxQ3p0krzc3N9FoNDAyMsKRGxIEM5lMuHr1Kubm5lCr1RCNRjlnf9A8nJmZGW4JPsr5oVNXoVBAoVBAJBLB559/ji+++IJrIM57kXM/B92YypQA1YdQbcRJXq/b7aJUKiGZTArnp49ms4lSqcQRzYOGYwYCAZZiOK7eIBgM4vd///dRq9VY54pq6Oh7lTUu6XQakUgEkUgEd+7cwZdffvnGIiPnHb1ez4Xpfr8fwWCQVXTJ+Uwmk1hbW0M0GhV1hYJzAw3yJZVnm83G9/1ZYaDdXrTAUtSFuluUCz1JbZMyM7VNk7R5uVx+oUuCdBoOEw6jbi7qbEmn00gkEjwCgFIQw7YBUC2VXq/vaW9Wpgap/qlUKnHLKCnVkmS88nooW0xJq0mkvp6jnAtFXXQkhkfp35cpsKS2abomer3+hdogKvSk+i0a2zLMU8VPAxocSQs/aZpQ3QgdJijlf9666s46yui2co7hQRu0Unh02PaFl4HsZzab4fV6uZhfec8rO/fInkOV9qKCqHa7jZ2dHfzt3/4trFYr3nvvPajVarhcLgSDQW6NVnbAjIyMwOl0otVqIRwOvxCdsdls8Hq9PKCwf/Not9tIp9NIJpPI5XL49NNP8fDhQ8iyjM3NTciyzBdnWOh2u8jn81hdXeWp08qiN9osaWQCTQunye2XLl2Cx+PBu+++ywqpyuLRarXK4xqOKlYfNmq1GpLJJCqVCmKxGBKJBDqdDqxWK08EfxloWCe1tx9071M3RyaTwWeffcbXM5lMvs5fbaiRJAmBQAA3b97kGWJutxtGo7FHRbdYLCKVSiGbzZ6r0QlnHSpgJv0rUhs2GAw9zwytf7VaDbIsc6OHOLy9CHVzabVaXLx4ET/4wQ/g8Xhw6dIlnqLQaDRYF65YLLLEwCAOXQMVlqCTDs1sIe97enoa9XodZrMZwWAQwHNZbK1Wy9omR92AR4XXSOY8FoshFovhs88+w69//esjq/2HAdI4KRQKyOfzPVX+VJgbj8exurrKp1Vqxb58+TLGx8cxMTHBcvMECZTR/JaTilUOA41GgxdUckpohAU5kS8DjYYBXmzvBZ5vuCTit7y8jLt37/I4AMHrgaaJz8/Pw+fzYWxsDFartWe0Cx0K8vk8SqWSiLq9YUhQkdqvDxow26/7RgrgYv16EaVO3MTEBD744ANO9ZLDTy3z1ORRLpdZUuNNc2ZUtcjDpgnhJCZFA06pFU+tVrOHTm15FEaj+S3HQTcvefzk9VPnyzBFfJRQNI5uUKpFIdtrNBrYbDZ4PB4WiKzVavB6vfB4PPB4PLDZbC+kvZRdLSJs3AuJC6pUKuTzeUSjUZ6FYzab2RE6qmviuNenTZa0e2hoZzqdRqFQOFbBWHA8dH1oyrhWq+XiZpPJxHVXwPNnotVqoVqtcsOFeC5OH4r2aLVauN1u2O12hMNhuFyuFyI/yjWL2rUp4j1szwopYlPaVilWS7agZgqdTgeXy9UzL4z2alKdT6VS7PCTzMCb5sw4P8DThXpraws/+9nPYDKZcPHiRVy6dIkLoE0mE8xmM+bn5xEOh3mII7XN7+/vH3t6pQ3EZDJxF83k5CT29vZ4Qu2wavpQu79KpUIqlcLm5maPojDZnhxNGhUSCoVw8+ZNhEIhXkCA3o46ivyIE24vpDZcqVTw4MED7nj8zne+A5VKBYvFwl0T5ICeNBVGi3ez2cT6+jq+/vprFItFLC0tYXV1FaVSCZFIBKVS6ViVbsHh0ImXmjempqZgs9lw5coVjI+Pw26396QwacGnkQmbm5solUoiHXzKqFQqvhYOhwO3bt3C/Pw8XC4X3nnnHR41QnWm9Xqd51dFIhE8fvwYiUSCB6aeBw6SgTkIg8GAiYkJ+Hw+1tGjWY3kvChb269evYpAIAC73c6q281mE2tra3jw4AHS6TQ2Nzd5/tog7HmmnB8ArPio1WpZa8RkMnHRoN1ux8jISM/pqdFocDfRcS26dDobHx+Hw+HgYZFerxc6ne6FzrFhQil3TgJUAHjh1uv1CAQCXJhL+kyjo6OYmJjAyMjIgcNQlWqfVEg+bCenwyAHHgBisRjK5TILEV65cgWdTocXZKUY2UlQXs9UKoW1tTVWS19aWmL1VVFr8s2g+hGtVgu73Y7x8XG4XC6EQiG4XC7uOqWCT4r2ka4Y1cGJ63C60IBlh8MBr9eLhYUF3Lp1CxaLBaOjo7Db7T1fTw0elUoFuVwO8Xgc8Xh8QO/+9CDH5ygHSKvVwul0IhwOw+FwYHFxEcFg8AXdNzpAhcNhvu+JdruNZDKJ1dVVHg47yPqpM+f8AM9rTGRZRiwWg8FgQC6XY90MvV6PTCaDbrfLKsOULjtKK4MurEajQSaTQTQa5Qm1uVyOxd2GnW63C1mWeaCdzWaD2+1Gq9VizZhWqwWLxYJGowGv18unJSU0K6lcLiOXy0GW5YGpeb4NKCNvu7u7ePDgATv8pABMw3op/UtzuijyQBPcScKBdLC+/vprbG9vo1Qq9aS6hrHDSHlCfdnvo7A/1WRRrQhpigWDQUxPT8Nut8Pv98NkMrG2CXV0UYFzIpFAOp1GpVJhPbG3HaVS8EnUkOn+O83TP2nG6XQ6eDwehEIhuN1uuN3uF+aqkWNKTTFra2soFArY29s78xFrcu5oLaamHboW/YcmKitRzg887GBlMBgwNTWFkZERWCwWBAKBFyI/5NgD4DWK9hL62NvbQyKR4ELnQR6Cz5zzozTi7u4ucrlcT7hfo9Hgl7/8JUwmE389XYCTjlugKIZWq0Wr1eL5JeTpDzudTgd7e3u4c+cOT3cnWXKv14tAIMBRhU6nA71e/8KcKeoe29jYQKFQwNraGnZ2dlAsFs+1evA3QTlX6vbt21hZWeFNVpnyHRsb6wk9m81m+Hw+mEwmpFIp3L17F9lsFhsbG3j06BE7PDQahlIsysVqmKDnnzbnkzpBJLpqNBpht9sxOzsLn88Hu92OiYkJdlL9fj/XE9KGQlGearWKr776Co8fP0Y2m8XS0hKSySSfoN9mJEniiehUF6Is8O6HHB7qpqL06+t+T6SQTqUU77zzDhejj42N8eEBeJqSzOfzqNVqePz4Mf7mb/4Ge3t7iEajZ74hQK1Ww+PxwO/3o9vt8mGeZshR0THd74FAAPPz87DZbAgGg5icnDz0emk0Gq7hITkN6uDqn6lGczQ1Gg2azSa2trbw6NEj5HI53L59G/fv30etVhu4kOqZc36A5wWBpVJJCH8NgE6nA1mWEY/HUavVkMvlUKlUWGPpuIGaBH0vjQspFotnfgEZJEq5+f39fezv70OSJK55I7t3Oh0Wy6NiQooaUO1bPB7HysoKvvjiC8iyLGp6FCjbnF/G+SHtJJvNBqfTiVAohLGxMbhcLszNzcHlcrFj1F/0T2muarWKZDKJra0t5PN55HK5gZ+AXyfUkUsOBdX/HQTd73R4PS0BPEobG41GuN1uTnGRAKXy51JXa7VaRSaTwfr6OkdMz7pzSmsFpe/UajUqlUpPlJK+DgD8fj+mpqbgcrkwMTHB9bWvA+VcsEKhgJ2dHWSzWezv7yOZTKLRaAy8bupMOj+CwVOtVpFKpVCtVvHkyRNotVrYbDYsLCxgYmKCF7n+MGmtVuPozsbGBh4+fIhsNou9vT2x+b4ilA4jLSAAMJvNKBQKnG4hXavd3V08fPgQ+Xwe8Xh86EUlaaE3GAzwer094ybMZvOJ0zPA083EYrGwIzo5OQmPx8OpSep0odoeSkE2Gg0el1MqlbC8vIydnR1OCZ+Xa0MFxR6PB0ajESMjI/B6vT1pMCXNZpPTffl8HqlUqsfBoMnfFBEieY3DoBl25HBRCs7r9cLv98NoNGJxcZEbM4xGI8twZLNZlMtlyLKMSCQCWZaxvLyMbDbLdXFn/TopFfj1ej2mpqbgcDh6OhCVBc4ejwcTExOwWCwc4X8VaH2h+ltKGcZiMVQqFTx+/BgrKysoFotIp9M9abJBIpwfwQt0Oh1ks1ludc9ms3j48CF8Ph/++I//mGe0WK3WF2p9ZFnGxsYGZFnGnTt38LOf/YxnRYlan5eHFjSSYVhaWsL6+npP6kbpiNbrde5GoRPsMDudtPGScOfExAT8fj+uXbsGn8/HqfSTLPzK2glK6yijHMo0WrfbRSqVwpMnT3gjffToEcrlMtc90DU6L2g0GgSDQczOzsLtduPWrVtYWFhg+/Qr8dfrddYWSyQSiEQiXPwPPE0Db21tYWdnB/V6naUZDts0L1y4gFu3bsHlcvE10mg0CIfDuHDhAtdm2Ww2Fsyl2tLHjx8jGo0ikUjg4cOHXJcViUR45t5ZTxFTDWyhUIDP58P777+P7373uy/YX1n7ajKZuB6K0mIvA9VIdTodLgyv1Wr48ssv8cknnyCXy2Fvbw97e3vsmNXr9TOhpyecH8GBUIs0LSIkTEU3N+kk9Yf36eEjxeBYLIZMJjO0xbWvA6UcPLXGC04GFTeT8nUwGMTIyAimpqYQDAZ54f+mKZf+ugfaDMjx39/fRyQSQblcRiaTQT6fH/ji/7qh+hqbzQa73Y5AIIBwONwz/kaZZiTnp9lswmg09nQ+Kj8vy3KPTtVhdqOfqXRqNRoNJiYmMDk5Cb1e37PJk+ZYvV5HLpdj4c9oNIp4PM4/86ynu5Qoa8conUX3+MvWuAGHCwkrxxaRHWu1GsrlMmcNtra2uKsrlUqduUOYcH4ER0IOjSRJSKVSuH37NgqFAp8a+k8LhUIB+/v7qFQqWF1dRblc5jZIgeBNQoWelBacnJzEwsICd8y9jGYSoVz0KSKnTBErW3/X1tbw1VdfoVAoIBqNIpvN8ny78+b4AE9tkkgkoNVqEYvFoFarEYvFoNfr4XQ6uQA8EAjAbDaj2+2yiKfb7eYoAtFqtWC1WjE+Po5GowFZlg9MEyoLeOfm5jiyQx9utxsajQbdbpejOKRWn8lkkMlkcPfuXU53kQDf2zZvjVJ41OCQTCYRjUZZ9Z0iQA6H48hCdDrokgNPNWkkDtxoNFjskZyedrvNo1poDFI8HkepVDqzNW3C+REcSbfbRbVa5dk22WwWv/rVrwDgwHZhWvzpFEeTys/izS8436jVathsNjgcDoRCIVy6dAk3btzgidPKGoiTQlEd2oxpNtvDhw+RTqe5NqvVarHzQ1035PS8TRvqy9BsNjlqotfrEYlE4PF4YDabMTY2xpG3mzdvIhAIcOqcDlIej6fn9WjDJfXxow5RFOkhPSzguVOknDFIkSRZlnH37l2srKwgl8vh0aNHXJeo1CJ7m64VKbm3Wi1otVrs7OxgbW2NR3hoNBouWTjM+SEHkRz1VCqFdDrNTg51LW5sbCCVSrH6NUWkU6kUD2mmtf+sHn6F8yM4FqUWR6PRQC6XG/A7EgiOh1JeJEBIKvH9E6bpa4+b7UdFnfQc0KmW9JRSqRTq9To7P+l0eugG+ZIAKm2czWaTtWRarRZ0Oh2KxSKsViu63S6LPwLgKLJSyPM457Q/jaNsvSYHht4PyTzQgNJ0Oo1EIoF8Po9sNotCoXBKVnlzKAVlqeBe6fxIkoRSqfRC/RVBXdbFYpEVrnO5HEc4yemPx+NIJpM8XYFsS51cbwPC+REIBOcSKmYlQc5oNIqtrS2e5K0sFpckiZ2Yw2o8Go0GEokET2AnobZiscg6MNTx0ul0jnyt8w5FWdrtNkqlEmq1GkwmE/b29lAqleByueB0OjE2NtbTXq1SqeByueDxeDgidFS7/GGkUins7u6iWq0iFovxvEhZltlp3d7eZjmP8yLBQU5fqVTCw4cPUSgUuLib5nN5vd5DW9op8kP3Mo0kotoeKtKn1KBSFPJtm4spnB+BQHAuIeenWCzCYDBge3sbbrebW381Gg10Oh1MJhMkSUI0GsXq6uqhkRpq293a2uITMIX2KTXTX/Q8aC2TQUE1IOVyGZIkIR6PQ5IkmM1mrK+vw2w2IxgMYn5+vkc3TKPRYHp6GnNzcxwVIoXsk9LtdpFMJnH//n1OaX355Zdcv0L1LBTFO08aWBSlLxaL+PLLL/Ho0aMe251kRI4yAqosWVBG1ZTdb/33/NuCcH4EAsG5hRZjclay2Sw0Gg2q1So7P5VKBSqVqmfe0EGUy2Vks1nkcjl+PWV3kqAXikIokSQJxWIRzWYTBoPhheiYSqWC0+lEJpNhHZ5Wq3XkZq2UF6ANmAqZKaVFYpLUan3eUab7BAcjnB+BQHDukWUZn3/+OSKRSE8agLRgJEmCLMssy3AQjUYDqVSKR+EMa1Tnm9BqtSDLMg9yLZfLPVphkiRhZWUFn332WU/a6yS1P8oIRCqVQjQaRb1eRzKZRLFY5LSNQAAI50cgEAwBxWIRX3311YE6J8quoKPC9sqwv+hefDWoMBZ4Lotx0PVQFjy/igYTpWX6UzQCASGcH4FAcO6h9Ilg8CgjNALBoHg5hS+BQCAQCASCtxzh/AgEAoFAIBgqhPMjEAgEAoFgqBDOj0AgEAgEgqFCOD8CgUAgEAiGCuH8CAQCgUAgGCpettU9DSByGm9kCBj/ht8vbP/NEPYfLML+g0PYfrAI+w+WA+0vCa0FgUAgEAgEw4RIewkEAoFAIBgqhPMjEAgEAoFgqBDOj0AgEAgEgqFCOD8CgUAgEAiGCuH8CAQCgUAgGCqE8yMQCAQCgWCoEM6PQCAQCASCoUI4PwKBQCAQCIYK4fwIBAKBQCAYKv5/xuoYm9NUeD4AAAAASUVORK5CYII="
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('qf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "interpreter": {
   "hash": "f24048f0d5bdb0ff49c5e7c8a9899a65bc3ab13b0f32660a2227453ca6b95fd8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}